<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Predictive Soil Mapping with R</title>
  <meta name="description" content="Predictive Soil Mapping aims at producing most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement various soil mapping procedures in R.">
  <meta name="generator" content="bookdown 0.7.12 and GitBook 2.6.7">

  <meta property="og:title" content="Predictive Soil Mapping with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://soilmapper.org" />
  <meta property="og:image" content="http://soilmapper.orgfigures/f0_web.png" />
  <meta property="og:description" content="Predictive Soil Mapping aims at producing most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement various soil mapping procedures in R." />
  <meta name="github-repo" content="envirometrix/PredictiveSoilMapping" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Predictive Soil Mapping with R" />
  <meta name="twitter:site" content="@tom_hengl" />
  <meta name="twitter:description" content="Predictive Soil Mapping aims at producing most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement various soil mapping procedures in R." />
  <meta name="twitter:image" content="http://soilmapper.orgfigures/f0_web.png" />

<meta name="author" content="Tomislav Hengl">


<meta name="date" content="2018-06-06">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="soil-covs-chapter.html">
<link rel="next" href="soilmapping-using-mla.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Soil Mapping with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Predictive Soil Mapping for advanced R users</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#editors"><i class="fa fa-check"></i>Editors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#connected-publications"><i class="fa fa-check"></i>Connected publications</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#contributions"><i class="fa fa-check"></i>Contributions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#reproducibility"><i class="fa fa-check"></i>Reproducibility</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html"><i class="fa fa-check"></i><b>1</b> Soil resource inventories and soil maps</a><ul>
<li class="chapter" data-level="1.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#introduction"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soils-and-soil-inventories"><i class="fa fa-check"></i><b>1.2</b> Soils and soil inventories</a><ul>
<li class="chapter" data-level="1.2.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-a-definition"><i class="fa fa-check"></i><b>1.2.1</b> Soil: a definition</a></li>
<li class="chapter" data-level="1.2.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-variables"><i class="fa fa-check"></i><b>1.2.2</b> Soil variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#primary-and-secondary-soil-variables"><i class="fa fa-check"></i><b>1.2.3</b> Primary and secondary soil variables</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-mapping"><i class="fa fa-check"></i><b>1.3</b> Soil mapping</a><ul>
<li class="chapter" data-level="1.3.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#what-are-soil-resource-inventories"><i class="fa fa-check"></i><b>1.3.1</b> What are soil resource inventories?</a></li>
<li class="chapter" data-level="1.3.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-mapping-approaches-and-concepts"><i class="fa fa-check"></i><b>1.3.2</b> Soil mapping approaches and concepts</a></li>
<li class="chapter" data-level="1.3.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-mapping-theory"><i class="fa fa-check"></i><b>1.3.3</b> Theoretical basis of soil mapping: in context of the universal model of spatial variation</a></li>
<li class="chapter" data-level="1.3.4" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#conventional-mapping"><i class="fa fa-check"></i><b>1.3.4</b> Traditional (conventional) soil mapping</a></li>
<li class="chapter" data-level="1.3.5" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#variants-of-soil-maps"><i class="fa fa-check"></i><b>1.3.5</b> Variants of soil maps</a></li>
<li class="chapter" data-level="1.3.6" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#pedometric-mapping"><i class="fa fa-check"></i><b>1.3.6</b> Predictive and Automated soil mapping</a></li>
<li class="chapter" data-level="1.3.7" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#comparison-conventional-pm"><i class="fa fa-check"></i><b>1.3.7</b> Comparison of conventional and pedometric soil mapping</a></li>
<li class="chapter" data-level="1.3.8" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#top-down"><i class="fa fa-check"></i><b>1.3.8</b> Top-down versus bottom-up approaches: subdivision versus agglomeration</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#sources-of-soil-data-for-soil-mapping"><i class="fa fa-check"></i><b>1.4</b> Sources of soil data for soil mapping</a><ul>
<li class="chapter" data-level="1.4.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-data-sources-targeted-by-psm"><i class="fa fa-check"></i><b>1.4.1</b> Soil data sources targeted by PSM</a></li>
<li class="chapter" data-level="1.4.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#field-observations"><i class="fa fa-check"></i><b>1.4.2</b> Field observations of soil properties</a></li>
<li class="chapter" data-level="1.4.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#legacy-soil-profile-data"><i class="fa fa-check"></i><b>1.4.3</b> Legacy soil profile data</a></li>
<li class="chapter" data-level="1.4.4" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-covariates"><i class="fa fa-check"></i><b>1.4.4</b> Soil covariates</a></li>
<li class="chapter" data-level="1.4.5" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-delineations"><i class="fa fa-check"></i><b>1.4.5</b> Soil delineations</a></li>
<li class="chapter" data-level="1.4.6" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#advantages-and-disadvantages-of-using-soil-delineations"><i class="fa fa-check"></i><b>1.4.6</b> Advantages and disadvantages of using soil delineations</a></li>
<li class="chapter" data-level="1.4.7" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#accuracy-of-conventional-soil-polygon-maps"><i class="fa fa-check"></i><b>1.4.7</b> Accuracy of conventional soil polygon maps</a></li>
<li class="chapter" data-level="1.4.8" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#tacit-knowledge"><i class="fa fa-check"></i><b>1.4.8</b> Legacy soil expertise (tacit knowledge)</a></li>
<li class="chapter" data-level="1.4.9" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#pseudo-observations"><i class="fa fa-check"></i><b>1.4.9</b> Pseudo-observations</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-databases"><i class="fa fa-check"></i><b>1.5</b> Soil databases and soil information systems</a><ul>
<li class="chapter" data-level="1.5.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-databases"><i class="fa fa-check"></i><b>1.5.1</b> Soil databases</a></li>
<li class="chapter" data-level="1.5.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-information-system"><i class="fa fa-check"></i><b>1.5.2</b> Soil Information System</a></li>
<li class="chapter" data-level="1.5.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-information-users"><i class="fa fa-check"></i><b>1.5.3</b> Soil information users</a></li>
<li class="chapter" data-level="1.5.4" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#usability-of-soil-geographical-database"><i class="fa fa-check"></i><b>1.5.4</b> Usability of soil geographical database</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#uncertainty-soil-variables"><i class="fa fa-check"></i><b>1.6</b> Uncertainty of soil variables</a><ul>
<li class="chapter" data-level="1.6.1" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#basic-concepts"><i class="fa fa-check"></i><b>1.6.1</b> Basic concepts</a></li>
<li class="chapter" data-level="1.6.2" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#sources-uncertainty"><i class="fa fa-check"></i><b>1.6.2</b> Sources of uncertainty</a></li>
<li class="chapter" data-level="1.6.3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#quantifying-the-uncertainty-in-soil-data-products"><i class="fa fa-check"></i><b>1.6.3</b> Quantifying the uncertainty in soil data products</a></li>
<li class="chapter" data-level="1.6.4" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#common-uncertainty-levels-in-soil-maps"><i class="fa fa-check"></i><b>1.6.4</b> Common uncertainty levels in soil maps</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.7</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>2</b> Software installation and first steps</a><ul>
<li class="chapter" data-level="2.1" data-path="software.html"><a href="software.html#list-of-software-in-use"><i class="fa fa-check"></i><b>2.1</b> List of software in use</a></li>
<li class="chapter" data-level="2.2" data-path="software.html"><a href="software.html#installing-software-on-ubuntu-os"><i class="fa fa-check"></i><b>2.2</b> Installing software on Ubuntu OS</a></li>
<li class="chapter" data-level="2.3" data-path="software.html"><a href="software.html#Rstudio"><i class="fa fa-check"></i><b>2.3</b> RStudio</a></li>
<li class="chapter" data-level="2.4" data-path="software.html"><a href="software.html#plotkml-and-gsif-packages"><i class="fa fa-check"></i><b>2.4</b> plotKML and GSIF packages</a></li>
<li class="chapter" data-level="2.5" data-path="software.html"><a href="software.html#connecting-r-and-saga-gis"><i class="fa fa-check"></i><b>2.5</b> Connecting R and SAGA GIS</a></li>
<li class="chapter" data-level="2.6" data-path="software.html"><a href="software.html#connecting-r-and-gdal"><i class="fa fa-check"></i><b>2.6</b> Connecting R and GDAL</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="soil-resource-inventories-and-soil-maps.html"><a href="soil-resource-inventories-and-soil-maps.html#soil-variables"><i class="fa fa-check"></i><b>3</b> Soil observations and variables</a><ul>
<li class="chapter" data-level="3.0.1" data-path="soil-variables.html"><a href="soil-variables.html"><i class="fa fa-check"></i><b>3.0.1</b> Types of soil observations</a></li>
<li class="chapter" data-level="3.0.2" data-path="soil-variables.html"><a href="soil-variables.html#soil-properties-of-interest-for-global-soil-mapping"><i class="fa fa-check"></i><b>3.0.2</b> Soil properties of interest for global soil mapping</a></li>
<li class="chapter" data-level="3.0.3" data-path="soil-variables.html"><a href="soil-variables.html#reference-methods"><i class="fa fa-check"></i><b>3.0.3</b> Reference methods</a></li>
<li class="chapter" data-level="3.0.4" data-path="soil-variables.html"><a href="soil-variables.html#standard-soil-variables-of-interest-for-soil-mapping"><i class="fa fa-check"></i><b>3.0.4</b> Standard soil variables of interest for soil mapping</a></li>
<li class="chapter" data-level="3.1" data-path="soil-variables.html"><a href="soil-variables.html#descriptive-soil-profile-observations"><i class="fa fa-check"></i><b>3.1</b> Descriptive soil profile observations</a><ul>
<li class="chapter" data-level="3.1.1" data-path="soil-variables.html"><a href="soil-variables.html#depth-to-bedrock"><i class="fa fa-check"></i><b>3.1.1</b> Depth to bedrock</a></li>
<li class="chapter" data-level="3.1.2" data-path="soil-variables.html"><a href="soil-variables.html#effective-soil-depth-and-rooting-depth"><i class="fa fa-check"></i><b>3.1.2</b> Effective soil depth and rooting depth</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="soil-variables.html"><a href="soil-variables.html#chemical-soil-properties"><i class="fa fa-check"></i><b>3.2</b> Chemical soil properties</a><ul>
<li class="chapter" data-level="3.2.1" data-path="soil-variables.html"><a href="soil-variables.html#soil-organic-carbon"><i class="fa fa-check"></i><b>3.2.1</b> Soil organic carbon</a></li>
<li class="chapter" data-level="3.2.2" data-path="soil-variables.html"><a href="soil-variables.html#soil-ph"><i class="fa fa-check"></i><b>3.2.2</b> Soil pH</a></li>
<li class="chapter" data-level="3.2.3" data-path="soil-variables.html"><a href="soil-variables.html#soil-nutrients"><i class="fa fa-check"></i><b>3.2.3</b> Soil nutrients</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="soil-variables.html"><a href="soil-variables.html#physical-and-hydrological-soil-properties"><i class="fa fa-check"></i><b>3.3</b> Physical and hydrological soil properties</a><ul>
<li class="chapter" data-level="3.3.1" data-path="soil-variables.html"><a href="soil-variables.html#coarse-fragments"><i class="fa fa-check"></i><b>3.3.1</b> Coarse fragments</a></li>
<li class="chapter" data-level="3.3.2" data-path="soil-variables.html"><a href="soil-variables.html#particle-size-class-distribution-sand-silt-and-clay"><i class="fa fa-check"></i><b>3.3.2</b> Particle size class distribution: sand, silt and clay</a></li>
<li class="chapter" data-level="3.3.3" data-path="soil-variables.html"><a href="soil-variables.html#bulk-density"><i class="fa fa-check"></i><b>3.3.3</b> Bulk density</a></li>
<li class="chapter" data-level="3.3.4" data-path="soil-variables.html"><a href="soil-variables.html#soil-organic-carbon-stock"><i class="fa fa-check"></i><b>3.3.4</b> Soil organic carbon stock</a></li>
<li class="chapter" data-level="3.3.5" data-path="soil-variables.html"><a href="soil-variables.html#available-water-capacity"><i class="fa fa-check"></i><b>3.3.5</b> Available Water Capacity</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="soil-variables.html"><a href="soil-variables.html#harmonisation-of-soil-data-and-pedo-transfer-functions"><i class="fa fa-check"></i><b>3.4</b> Harmonisation of soil data and pedo-transfer functions</a><ul>
<li class="chapter" data-level="3.4.1" data-path="soil-variables.html"><a href="soil-variables.html#basic-concepts-of-harmonisation-of-soil-property-values"><i class="fa fa-check"></i><b>3.4.1</b> Basic concepts of harmonisation of soil property values</a></li>
<li class="chapter" data-level="3.4.2" data-path="soil-variables.html"><a href="soil-variables.html#example-of-harmonization-using-texture-by-hand-classes"><i class="fa fa-check"></i><b>3.4.2</b> Example of harmonization using texture-by-hand classes</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="soil-variables.html"><a href="soil-variables.html#soil-class-data"><i class="fa fa-check"></i><b>3.5</b> Soil class data</a><ul>
<li class="chapter" data-level="3.5.1" data-path="soil-variables.html"><a href="soil-variables.html#soil-types"><i class="fa fa-check"></i><b>3.5.1</b> Soil types</a></li>
<li class="chapter" data-level="3.5.2" data-path="soil-variables.html"><a href="soil-variables.html#other-factor-type-variables"><i class="fa fa-check"></i><b>3.5.2</b> Other factor-type variables</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="soil-variables.html"><a href="soil-variables.html#importing-and-formatting-soil-data-in-r"><i class="fa fa-check"></i><b>3.6</b> Importing and formatting soil data in R</a><ul>
<li class="chapter" data-level="3.6.1" data-path="soil-variables.html"><a href="soil-variables.html#converting-texture-by-hand-classes-to-fractions"><i class="fa fa-check"></i><b>3.6.1</b> Converting texture-by-hand classes to fractions</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="soil-variables.html"><a href="soil-variables.html#converting-munsell-color-codes-to-other-color-systems"><i class="fa fa-check"></i><b>3.7</b> Converting Munsell color codes to other color systems</a></li>
<li class="chapter" data-level="3.8" data-path="soil-variables.html"><a href="soil-variables.html#mla-ptfs"><i class="fa fa-check"></i><b>3.8</b> Using Machine Learning to build Pedo-Transfer-Functions</a><ul>
<li class="chapter" data-level="3.8.1" data-path="soil-variables.html"><a href="soil-variables.html#ptf-for-bulk-density"><i class="fa fa-check"></i><b>3.8.1</b> PTF for Bulk Density</a></li>
<li class="chapter" data-level="3.8.2" data-path="soil-variables.html"><a href="soil-variables.html#ptf-for-correlating-classification-systems"><i class="fa fa-check"></i><b>3.8.2</b> PTF for correlating classification systems</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="soil-variables.html"><a href="soil-variables.html#summary-points"><i class="fa fa-check"></i><b>3.9</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html"><i class="fa fa-check"></i><b>4</b> Preparation of soil covariates for soil mapping</a><ul>
<li class="chapter" data-level="4.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covariate-data-sources"><i class="fa fa-check"></i><b>4.1</b> Soil covariate data sources</a><ul>
<li class="chapter" data-level="4.1.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covs-30m"><i class="fa fa-check"></i><b>4.1.1</b> Soil covariate data sources (30–100 m resolution)</a></li>
<li class="chapter" data-level="4.1.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covs-250m"><i class="fa fa-check"></i><b>4.1.2</b> Soil covariate data sources (250 m resolution or coarser)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#preparing-soil-covariate-layers"><i class="fa fa-check"></i><b>4.2</b> Preparing soil covariate layers</a><ul>
<li class="chapter" data-level="4.2.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#converting-polygon-maps-to-rasters"><i class="fa fa-check"></i><b>4.2.1</b> Converting polygon maps to rasters</a></li>
<li class="chapter" data-level="4.2.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#downscaling-upscaling"><i class="fa fa-check"></i><b>4.2.2</b> Downscaling or upscaling (aggregating) rasters</a></li>
<li class="chapter" data-level="4.2.3" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#deriving-dem-parameters-using-saga-gis"><i class="fa fa-check"></i><b>4.2.3</b> Deriving DEM parameters using SAGA GIS</a></li>
<li class="chapter" data-level="4.2.4" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#filtering-out-missing-pixels-and-artifacts"><i class="fa fa-check"></i><b>4.2.4</b> Filtering out missing pixels and artifacts</a></li>
<li class="chapter" data-level="4.2.5" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#overlaying-and-subsetting-raster-stacks-and-points"><i class="fa fa-check"></i><b>4.2.5</b> Overlaying and subsetting raster stacks and points</a></li>
<li class="chapter" data-level="4.2.6" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#working-with-larger-rasters"><i class="fa fa-check"></i><b>4.2.6</b> Working with large(r) rasters</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#summary-points-1"><i class="fa fa-check"></i><b>4.3</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistical-theory.html"><a href="statistical-theory.html"><i class="fa fa-check"></i><b>5</b> Statistical theory for predictive soil mapping</a><ul>
<li class="chapter" data-level="5.1" data-path="statistical-theory.html"><a href="statistical-theory.html#aspects-variability"><i class="fa fa-check"></i><b>5.1</b> Aspects of spatial variability of soil variables</a><ul>
<li class="chapter" data-level="5.1.1" data-path="statistical-theory.html"><a href="statistical-theory.html#modelling-soil-variability"><i class="fa fa-check"></i><b>5.1.1</b> Modelling soil variability</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistical-theory.html"><a href="statistical-theory.html#umsv"><i class="fa fa-check"></i><b>5.1.2</b> Universal model of soil variation</a></li>
<li class="chapter" data-level="5.1.3" data-path="statistical-theory.html"><a href="statistical-theory.html#soil-depth-models"><i class="fa fa-check"></i><b>5.1.3</b> Modelling the variation of soil with depth</a></li>
<li class="chapter" data-level="5.1.4" data-path="statistical-theory.html"><a href="statistical-theory.html#vertical-aggregation"><i class="fa fa-check"></i><b>5.1.4</b> Vertical aggregation of soil properties</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistical-theory.html"><a href="statistical-theory.html#spatial-prediction-of-soil-variables"><i class="fa fa-check"></i><b>5.2</b> Spatial prediction of soil variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="statistical-theory.html"><a href="statistical-theory.html#main-principles"><i class="fa fa-check"></i><b>5.2.1</b> Main principles</a></li>
<li class="chapter" data-level="5.2.2" data-path="statistical-theory.html"><a href="statistical-theory.html#soil-sampling"><i class="fa fa-check"></i><b>5.2.2</b> Soil sampling</a></li>
<li class="chapter" data-level="5.2.3" data-path="statistical-theory.html"><a href="statistical-theory.html#sec:expertsystems"><i class="fa fa-check"></i><b>5.2.3</b> Knowledge-driven soil mapping</a></li>
<li class="chapter" data-level="5.2.4" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging"><i class="fa fa-check"></i><b>5.2.4</b> Geostatistics-driven soil mapping (pedometric mapping)</a></li>
<li class="chapter" data-level="5.2.5" data-path="statistical-theory.html"><a href="statistical-theory.html#RK-generic"><i class="fa fa-check"></i><b>5.2.5</b> Regression-kriging (generic model)</a></li>
<li class="chapter" data-level="5.2.6" data-path="statistical-theory.html"><a href="statistical-theory.html#spatial-prediction-using-multiple-linear-regression"><i class="fa fa-check"></i><b>5.2.6</b> Spatial Prediction using multiple linear regression</a></li>
<li class="chapter" data-level="5.2.7" data-path="statistical-theory.html"><a href="statistical-theory.html#universal-kriging-prediction-error"><i class="fa fa-check"></i><b>5.2.7</b> Universal kriging prediction error</a></li>
<li class="chapter" data-level="5.2.8" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-examples"><i class="fa fa-check"></i><b>5.2.8</b> Regression-kriging examples</a></li>
<li class="chapter" data-level="5.2.9" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-examples-using-the-gsif-package"><i class="fa fa-check"></i><b>5.2.9</b> Regression-kriging examples using the GSIF package</a></li>
<li class="chapter" data-level="5.2.10" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-and-polygon-averaging"><i class="fa fa-check"></i><b>5.2.10</b> Regression-kriging and polygon averaging</a></li>
<li class="chapter" data-level="5.2.11" data-path="statistical-theory.html"><a href="statistical-theory.html#block-support"><i class="fa fa-check"></i><b>5.2.11</b> Predictions at point vs block support</a></li>
<li class="chapter" data-level="5.2.12" data-path="statistical-theory.html"><a href="statistical-theory.html#gstat-sims"><i class="fa fa-check"></i><b>5.2.12</b> Geostatistical simulations</a></li>
<li class="chapter" data-level="5.2.13" data-path="statistical-theory.html"><a href="statistical-theory.html#automated-mapping"><i class="fa fa-check"></i><b>5.2.13</b> Automated mapping</a></li>
<li class="chapter" data-level="5.2.14" data-path="statistical-theory.html"><a href="statistical-theory.html#selecting-spatial-prediction-models"><i class="fa fa-check"></i><b>5.2.14</b> Selecting spatial prediction models</a></li>
<li class="chapter" data-level="5.2.15" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-3D"><i class="fa fa-check"></i><b>5.2.15</b> 3D regression-kriging</a></li>
<li class="chapter" data-level="5.2.16" data-path="statistical-theory.html"><a href="statistical-theory.html#multiscale"><i class="fa fa-check"></i><b>5.2.16</b> Predicting with multiscale and multisource data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-assessment"><i class="fa fa-check"></i><b>5.3</b> Accuracy assessment and the mapping efficiency</a><ul>
<li class="chapter" data-level="5.3.1" data-path="statistical-theory.html"><a href="statistical-theory.html#mapping-accuracy"><i class="fa fa-check"></i><b>5.3.1</b> Mapping accuracy and numeric resolution</a></li>
<li class="chapter" data-level="5.3.2" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-assessment-methods"><i class="fa fa-check"></i><b>5.3.2</b> Accuracy assessment methods</a></li>
<li class="chapter" data-level="5.3.3" data-path="statistical-theory.html"><a href="statistical-theory.html#cross-validation-and-its-limitations"><i class="fa fa-check"></i><b>5.3.3</b> Cross-validation and its limitations</a></li>
<li class="chapter" data-level="5.3.4" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-of-the-predicted-model-uncertainty"><i class="fa fa-check"></i><b>5.3.4</b> Accuracy of the predicted model uncertainty</a></li>
<li class="chapter" data-level="5.3.5" data-path="statistical-theory.html"><a href="statistical-theory.html#derivation-and-interpretation-of-prediction-interval"><i class="fa fa-check"></i><b>5.3.5</b> Derivation and interpretation of prediction interval</a></li>
<li class="chapter" data-level="5.3.6" data-path="statistical-theory.html"><a href="statistical-theory.html#universal-measures-of-mapping-accuracy"><i class="fa fa-check"></i><b>5.3.6</b> Universal measures of mapping accuracy</a></li>
<li class="chapter" data-level="5.3.7" data-path="statistical-theory.html"><a href="statistical-theory.html#mapping-accuracy-and-soil-survey-costs"><i class="fa fa-check"></i><b>5.3.7</b> Mapping accuracy and soil survey costs</a></li>
<li class="chapter" data-level="5.3.8" data-path="statistical-theory.html"><a href="statistical-theory.html#summary-points-2"><i class="fa fa-check"></i><b>5.3.8</b> Summary points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html"><i class="fa fa-check"></i><b>6</b> Machine Learning Algorithms for soil mapping</a><ul>
<li class="chapter" data-level="6.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-properties-and-classes-using-mlas"><i class="fa fa-check"></i><b>6.1</b> Spatial prediction of soil properties and classes using MLA’s</a><ul>
<li class="chapter" data-level="6.1.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#loading-the-packages-and-data"><i class="fa fa-check"></i><b>6.1.1</b> Loading the packages and data</a></li>
<li class="chapter" data-level="6.1.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-classes-using-mlas"><i class="fa fa-check"></i><b>6.1.2</b> Spatial prediction of soil classes using MLA’s</a></li>
<li class="chapter" data-level="6.1.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#modelling-numeric-soil-properties-using-h2o"><i class="fa fa-check"></i><b>6.1.3</b> Modelling numeric soil properties using h2o</a></li>
<li class="chapter" data-level="6.1.4" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#prediction-3D"><i class="fa fa-check"></i><b>6.1.4</b> Spatial prediction of 3D (numeric) variables</a></li>
<li class="chapter" data-level="6.1.5" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#ensemble-predictions-using-h2oensemble"><i class="fa fa-check"></i><b>6.1.5</b> Ensemble predictions using h2oEnsemble</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#a-generic-framework-for-spatial-prediction-using-random-forest"><i class="fa fa-check"></i><b>6.2</b> A generic framework for spatial prediction using Random Forest</a><ul>
<li class="chapter" data-level="6.2.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#general-principle-of-rfsp"><i class="fa fa-check"></i><b>6.2.1</b> General principle of RFsp</a></li>
<li class="chapter" data-level="6.2.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#geographical-covariates"><i class="fa fa-check"></i><b>6.2.2</b> Geographical covariates</a></li>
<li class="chapter" data-level="6.2.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-2d-continuous-variable-using-rfsp"><i class="fa fa-check"></i><b>6.2.3</b> Spatial prediction 2D continuous variable using RFsp</a></li>
<li class="chapter" data-level="6.2.4" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-2d-variable-with-covariates-using-rfsp"><i class="fa fa-check"></i><b>6.2.4</b> Spatial prediction 2D variable with covariates using RFsp</a></li>
<li class="chapter" data-level="6.2.5" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-binomial-variable"><i class="fa fa-check"></i><b>6.2.5</b> Spatial prediction of binomial variable</a></li>
<li class="chapter" data-level="6.2.6" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-types"><i class="fa fa-check"></i><b>6.2.6</b> Spatial prediction of soil types</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#summary-points-3"><i class="fa fa-check"></i><b>6.3</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="SOC-chapter.html"><a href="SOC-chapter.html"><i class="fa fa-check"></i><b>7</b> Spatial prediction and assessment of Soil Organic Carbon</a><ul>
<li class="chapter" data-level="7.1" data-path="SOC-chapter.html"><a href="SOC-chapter.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="SOC-chapter.html"><a href="SOC-chapter.html#measurement-and-derivation-of-soil-organic-carbon"><i class="fa fa-check"></i><b>7.2</b> Measurement and derivation of soil organic carbon</a></li>
<li class="chapter" data-level="7.3" data-path="SOC-chapter.html"><a href="SOC-chapter.html#derivation-of-ocs-and-ocd-using-soil-profile-data"><i class="fa fa-check"></i><b>7.3</b> Derivation of OCS and OCD using soil profile data</a></li>
<li class="chapter" data-level="7.4" data-path="SOC-chapter.html"><a href="SOC-chapter.html#estimation-of-bulk-density-using-a-globally-calibrated-ptf"><i class="fa fa-check"></i><b>7.4</b> Estimation of Bulk Density using a globally-calibrated PTF</a></li>
<li class="chapter" data-level="7.5" data-path="SOC-chapter.html"><a href="SOC-chapter.html#generating-maps-of-ocs"><i class="fa fa-check"></i><b>7.5</b> Generating maps of OCS</a></li>
<li class="chapter" data-level="7.6" data-path="SOC-chapter.html"><a href="SOC-chapter.html#predicting-ocs-from-point-data-the-2d-approach"><i class="fa fa-check"></i><b>7.6</b> Predicting OCS from point data (the 2D approach)</a></li>
<li class="chapter" data-level="7.7" data-path="SOC-chapter.html"><a href="SOC-chapter.html#ocs-3d-approach"><i class="fa fa-check"></i><b>7.7</b> Deriving OCS from soil profile data (the 3D approach)</a></li>
<li class="chapter" data-level="7.8" data-path="SOC-chapter.html"><a href="SOC-chapter.html#deriving-ocs-using-spatiotemporal-models"><i class="fa fa-check"></i><b>7.8</b> Deriving OCS using spatiotemporal models</a></li>
<li class="chapter" data-level="7.9" data-path="SOC-chapter.html"><a href="SOC-chapter.html#summary-points-4"><i class="fa fa-check"></i><b>7.9</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="http://envirometrix.net/staff">T. (Tom) Hengl</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Soil Mapping with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-theory" class="section level1">
<h1><span class="header-section-number">5</span> Statistical theory for predictive soil mapping</h1>
<p><em>Edited by: Hengl T. and Heuvelink G.B.M.</em></p>
<div id="aspects-variability" class="section level2">
<h2><span class="header-section-number">5.1</span> Aspects of spatial variability of soil variables</h2>
<p>In this chapter we review the statistical theory for soil mapping. We focus on models that are most suitable for practical implementation and use with soil profile data and gridded covariates, and we provide the mathematical-statistical details of the selected models. We start by revisiting some basic statistical aspects of soil mapping, and finally illustrate the proposed framework for reproducible, semi-automated mapping of soil variables using simple, real-world examples.</p>
<p>To code examples are only shown for illustration. More complex predictive modeling is described in section <a href="soilmapping-using-mla.html#soilmapping-using-mla">6</a>. To install and optimize packages used in this chapter please refer to section <a href="software.html#Rstudio">2.3</a>.</p>
<div id="modelling-soil-variability" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Modelling soil variability</h3>
<p>Soils vary spatially in a way that is often only partially understood. The main (deterministic) causes of soil spatial variation are the well-known causal factors — climate, organisms, relief and parent material — but how these factors jointly shape the soil over time is a very complex process that is (still) extremely difficult to model mechanistically. Moreover, mechanistic modelling approaches require large sets of input data that are not available in practice. Some initial steps have been made, notably for mechanistic modelling of vertical soil variation (see e.g. <span class="citation">Finke and Hutson (<a href="references.html#ref-Finke2008462">2008</a>)</span>, <span class="citation">Sommer, Gerke, and Deumlich (<a href="references.html#ref-Sommer2008480">2008</a>)</span>, <span class="citation">Minasny, McBratney, and Salvador-Blanes (<a href="references.html#ref-Minasny2008140">2008</a>)</span>, and <span class="citation">Vanwalleghem et al. (<a href="references.html#ref-vanwalleghem2010spatial">2010</a>)</span>), but existing approaches are still rudimentary and cannot be used for operational soil mapping. Mainstream soil mapping therefore takes an empirical approach in which the relationship between the soil variable of interest and causal factors (or their proxies) is modelled statistically, using various types of regression models. The explanatory variables used in regression are also known as <em>covariates</em> (a list of common covariates used in soil mapping is provided in chapter <a href="soil-covs-chapter.html#soil-covs-chapter">4</a>).</p>
<p>Regression models explain only part of the variation (i.e. variance) of the soil variable of interest, because:</p>
<ul>
<li><p><em>The structure of the regression model does not represent the true mechanistic relationship between the soil and its causal factors</em>.</p></li>
<li><p><em>The regression model includes only a few of the many causal factors that formed the soil</em>.</p></li>
<li><p><em>The covariates used in regression are often only proxies of the true soil forming factors</em>.</p></li>
<li><p><em>The covariates often contain measurement errors and/or are measured at a much coarser scale (i.e. support) than that of the soil that needs to be mapped</em>.</p></li>
</ul>
<p>As a result, soil spatial regression models will often have a substantial amount of residual variance, which may well be larger than the amount of variance explained by the regression itself. The residual variation can subsequently be analysed on spatial structure through a variogram analysis. If there is spatial structure, then kriging the residual and incorporating the result of this in mapping can improve the accuracy of soil predictions <span class="citation">(Hengl, Heuvelink, and Rossiter <a href="references.html#ref-hengl2007regression">2007</a>)</span>.</p>
</div>
<div id="umsv" class="section level3">
<h3><span class="header-section-number">5.1.2</span> Universal model of soil variation</h3>
<p>From a statistical point of view, it is convenient to distinguish between three major components of soil variation: (1) deterministic component (trend), (2) spatially correlated component and (3) pure noise. This is the basis of the <em>universal model of soil variation</em> [<span class="citation">Burrough and McDonnell (<a href="references.html#ref-Burrough1998OUP">1998</a>)</span>;Webster2001Wiley p.133]:</p>
<span class="math display" id="eq:ukm">\[\begin{equation}
Z({\bf{s}}) = m({\bf{s}}) + \varepsilon &#39;({\bf{s}}) + \varepsilon &#39;&#39;({\bf{s}})
\tag{5.1}
\end{equation}\]</span>
<p>where <span class="math inline">\(\bf{s}\)</span> is two-dimensional location, <span class="math inline">\(m({\bf{s}})\)</span> is the deterministic component, <span class="math inline">\(\varepsilon &#39;({\bf{s}})\)</span> is the spatially correlated stochastic component and <span class="math inline">\(\varepsilon &#39;&#39;({\bf{s}})\)</span> is the pure noise (micro-scale variation and measurement error). This model was probably first introduced by <span class="citation">Matheron (<a href="references.html#ref-Matheron1969PhD">1969</a>)</span>, and has been used as a general framework for spatial prediction of quantities in various environmental research disciplines.</p>
<div class="rmdnote">
<p>
The <em>universal model of soil variation</em> assumes that there are three major components of soil variation: (1) the deterministic component (function of covariates), (2) spatially correlated component (treated as stochastic) and (3) pure noise.
</p>
</div>
<p>The universal model of soil variation model (Eq. <a href="statistical-theory.html#eq:ukm">(5.1)</a>) can be further generalised to three-dimensional space and the spatio-temporal domain (3D+T) by letting the variables also depend on depth and time:</p>
<span class="math display" id="eq:ukm3DT">\[\begin{equation}
Z({\bf{s}}, d, t) = m({\bf{s}}, d, t) + \varepsilon &#39;({\bf{s}}, d, t) + \varepsilon &#39;&#39;({\bf{s}}, d, t)
\tag{5.2}
\end{equation}\]</span>
<p>where <span class="math inline">\(d\)</span> is depth expressed in meters downward from the land surface and <span class="math inline">\(t\)</span> is time. The deterministic component <span class="math inline">\(m\)</span> may be further decomposed into parts that are purely spatial, purely temporal, purely depth-related or mixtures of all three. Space-time statistical soil models are discussed by <span class="citation">Grunwald (<a href="references.html#ref-Grunwald2005CRCPress">2005</a><a href="references.html#ref-Grunwald2005CRCPress">b</a>)</span>, but this area of soil mapping is still rather experimental.</p>
<p>In this chapter, we mainly focus on purely 2D models but also present some theory for 3D models, while 2D+T and 3D+T models of soil variation are significantly more complex (Fig. <a href="statistical-theory.html#fig:scheme-2D-3D-maps">5.1</a>).</p>
<div class="figure" style="text-align: center"><span id="fig:scheme-2D-3D-maps"></span>
<img src="figures/Fig_2D_3DT_maps.png" alt="Number of variogram parameters assuming an exponential model, minimum number of samples and corresponding increase in number of prediction locations for 2D, 3D, 2D+T and 3D+T models of soil variation. Here *“altitude”* refers to vertical distance from the land surface, which is in case of soil mapping often expressed as negative vertical distance from the land surface." width="60%" />
<p class="caption">
Figure 5.1: Number of variogram parameters assuming an exponential model, minimum number of samples and corresponding increase in number of prediction locations for 2D, 3D, 2D+T and 3D+T models of soil variation. Here <em>“altitude”</em> refers to vertical distance from the land surface, which is in case of soil mapping often expressed as negative vertical distance from the land surface.
</p>
</div>
<p>One of the reasons why 2D+T and 3D+T models of soil variations are rare is because there are very few point data sets that satisfy the requirements for analysis. One national soil data set that could be analyzed using space-time geostatistics is for example the Swiss soil-monitoring network (NABO) data set <span class="citation">(Desaules, Ammann, and Schwab <a href="references.html#ref-JPLN:JPLN200900269">2010</a>)</span>, but even this data set does not contain complete profile descriptions following international standards. At regional and global scale it would be even more difficult to find enough data to fit space-time models (and to fit 3D+T variogram models could be even more difficult). For catchments and plots, space-time datasets of soil moisture have been recorded and used in space-time geostatistical modelling (see e.g. <span class="citation">Snepvangers, Heuvelink, and Huisman (<a href="references.html#ref-snepvangers2003soil">2003</a>)</span> and <span class="citation">Jost, Heuvelink, and Papritz (<a href="references.html#ref-jost2005analysing">2005</a>)</span>).</p>
<p>Statistical modelling of spatial distribution of soils requires field observations because most statistical methods are data-driven. The minimum recommended number of points required to fit 2D geostatistical models, for example, is in the range 50–100 points, but this number increases with any increase in spatial or temporal dimension (Fig. <a href="statistical-theory.html#fig:scheme-2D-3D-maps">5.1</a>). The Cookfarm data set for example contains hundreds of thousands of observations, although the study area is relatively small and there are only ca. 50 station locations <span class="citation">(Gasch et al. <a href="references.html#ref-Gasch2015SPASTA">2015</a>)</span>.</p>
<p>The deterministic and stochastic components of soil spatial variation are separately described in more detail in subsequent sections, but before we do this we first address soil vertical variability and how it can be modelled statistically.</p>
</div>
<div id="soil-depth-models" class="section level3">
<h3><span class="header-section-number">5.1.3</span> Modelling the variation of soil with depth</h3>
<p>Soil properties vary with depth, in some cases much more than in the horizontal direction. There is an increasing awareness that the vertical dimension is important and needs to be incorporated in soil mapping. For example, many spatial prediction models are built using ambiguous vertical reference frames such as predicted soil property for <em>“top-soil”</em> or <em>“A-horizon”</em>. Top-soil can refer to different depths / thicknesses and so can the A-horizon range from a few centimeters to over one meter. Hence before fitting a 2D spatial model to soil profile data, it is a good idea to standardize values to standard depths, otherwise soil observation depth becomes an additional source of uncertainty. For example soil organic carbon content is strongly controlled by soil depth, so combining values from two A horizons one thick and the other thick, would increase complexity of 2D soil mapping because a fraction of the variance is controlled by the depth, which is ignored.</p>
<p>The concept of perfectly homogeneous soil horizons is often too restrictive and can be better replaced with continuous representations of soil vertical variation i.e. <em>soil-depth functions</em> or curves. Variation of soil properties with depth is typically modelled using one of two approaches (Fig. <a href="statistical-theory.html#fig:soil-depth-examples">5.2</a>):</p>
<ol style="list-style-type: decimal">
<li><p><em>Continuous vertical variation</em> — This assumes that soil variables change continuously with depth. The soil-depth relationship is modelled using either:</p>
<ol style="list-style-type: decimal">
<li><p><em>Parametric model</em> — The relationship is modelled using mathematical functions such as logarithmic or exponential decay functions.</p></li>
<li><p><em>Non-parametric model</em> — The soil property changes continuously but without obvious regularity with depth. Changes in values are modelled using locally fitted functions such as piecewise linear functions or splines.</p></li>
</ol></li>
<li><p><em>Abrupt or stratified vertical variation</em> — This assumes that soil horizons are distinct and homogeneous bodies of soil material and that soil properties are constant within horizons and change abruptly at boundaries between horizons.</p></li>
</ol>
<p>Combinations of the two approaches are also possible, such as the use of exponential decay functions per soil horizon <span class="citation">(Kempen, Brus, and Stoorvogel <a href="references.html#ref-Kempen2011Geoderma">2011</a>)</span>.</p>
<p>Parametric continuous models are chosen to reflect pedological knowledge e.g. knowledge of soil forming processes. For example, organic carbon usually origins from plant production i.e. litter or roots. Generally, the upper layers of the soil tend to have greater organic carbon content, which decreases continuously with depth, so that the soil-depth relationship can be modelled with a negative-exponential function:</p>
<span class="math display" id="eq:SOMdepth">\[\begin{equation}
{\texttt{ORC}} (d) = {\texttt{ORC}} (d_0) \cdot \exp(-\tau \cdot d)
\tag{5.3}
\end{equation}\]</span>
<p>where <span class="math inline">\(\texttt{ORC}(d)\)</span> is the soil organic carbon content at depth (<span class="math inline">\(d\)</span>), <span class="math inline">\({\texttt{ORC}} (d_0)\)</span> is the organic carbon content at the soil surface and <span class="math inline">\(\tau\)</span> is the rate of decrease with depth. This model has only two parameters that must be chosen such that model averages over sampling horizons match those of the observations as closely as possible. Once the model parameters have been estimated, we can easily predict concentrations for any depth interval.</p>
<p>Consider for example this sample profile from Nigeria:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lon =<span class="st"> </span><span class="fl">3.90</span>; lat =<span class="st"> </span><span class="fl">7.50</span>; id =<span class="st"> &quot;ISRIC:NG0017&quot;</span>; FAO1988 =<span class="st"> &quot;LXp&quot;</span> 
top =<span class="st"> </span><span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">18</span>, <span class="dv">36</span>, <span class="dv">65</span>, <span class="dv">87</span>, <span class="dv">127</span>) 
bottom =<span class="st"> </span><span class="kw">c</span>(<span class="dv">18</span>, <span class="dv">36</span>, <span class="dv">65</span>, <span class="dv">87</span>, <span class="dv">127</span>, <span class="dv">181</span>)
ORCDRC =<span class="st"> </span><span class="kw">c</span>(<span class="fl">18.4</span>, <span class="fl">4.4</span>, <span class="fl">3.6</span>, <span class="fl">3.6</span>, <span class="fl">3.2</span>, <span class="fl">1.2</span>)
munsell =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;7.5YR3/2&quot;</span>, <span class="st">&quot;7.5YR4/4&quot;</span>, <span class="st">&quot;2.5YR5/6&quot;</span>, <span class="st">&quot;5YR5/8&quot;</span>, <span class="st">&quot;5YR5/4&quot;</span>, <span class="st">&quot;10YR7/3&quot;</span>)
## prepare a SoilProfileCollection:
prof1 &lt;-<span class="st"> </span>plyr<span class="op">::</span><span class="kw">join</span>(<span class="kw">data.frame</span>(id, top, bottom, ORCDRC, munsell), 
         <span class="kw">data.frame</span>(id, lon, lat, FAO1988), <span class="dt">type=</span><span class="st">&#39;inner&#39;</span>) 
<span class="co">#&gt; Joining by: id</span>
prof1<span class="op">$</span>mdepth &lt;-<span class="st"> </span>prof1<span class="op">$</span>top<span class="op">+</span>(prof1<span class="op">$</span>bottom<span class="op">-</span>prof1<span class="op">$</span>top)<span class="op">/</span><span class="dv">2</span></code></pre></div>
<p>we can fit a log-log model by using e.g.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">d.lm &lt;-<span class="st"> </span><span class="kw">glm</span>(ORCDRC <span class="op">~</span><span class="st"> </span><span class="kw">log</span>(mdepth), <span class="dt">data=</span>prof1, <span class="dt">family=</span><span class="kw">gaussian</span>(log))
<span class="kw">options</span>(<span class="kw">list</span>(<span class="dt">scipen=</span><span class="dv">3</span>, <span class="dt">digits=</span><span class="dv">2</span>))
d.lm<span class="op">$</span>fitted.values
<span class="co">#&gt;    1    2    3    4    5    6 </span>
<span class="co">#&gt; 18.1  6.3  3.5  2.4  1.7  1.2</span></code></pre></div>
<p>which shows that the log-log fit comes relatively close to the actual values. Another possibility would be to fit a power-law model:</p>
<span class="math display" id="eq:loglog">\[\begin{equation}
{\texttt{ORC}} (d) = a \cdot d^b
\tag{5.4}
\end{equation}\]</span>
<p>A disadvantage of a single parametric soil property-depth model along the entire soil profile is that these completely ignore stratigraphy and abrupt changes at the boundaries between soil horizons. For example, <span class="citation">Kempen, Brus, and Stoorvogel (<a href="references.html#ref-Kempen2011Geoderma">2011</a>)</span> show that there are many cases where highly contrasting layers of peat can be found buried below the surface due to cultivation practices or holocene drift sand. The model given by Eq. <a href="statistical-theory.html#eq:loglog">(5.4)</a> illustrated in Fig. <a href="statistical-theory.html#fig:soil-depth-examples">5.2</a> (left) will not be able to represent such abrupt changes.</p>
<div class="rmdnote">
<p>
Before fitting a 2D spatial prediction model to soil profile data, it is important to standardize values to standard depths, otherwise soil observation depth can be an additional source of uncertainty.
</p>
</div>
<p>Non-parametric soil-depth functions are more flexible and can represent observations of soil property averages for sampling layers or horizons more accurately. One such technique that is particularly interesting is <em>equal-area or mass-preserving splines</em> <span class="citation">(Bishop, McBratney, and Laslett <a href="references.html#ref-Bishop1999Geoderma">1999</a>; Malone et al. <a href="references.html#ref-Malone2009Geoderma">2009</a>)</span> because it ensures that for each sampling layer (usually a soil horizon) the average of the spline function equals the measured value for the horizon. Disadvantages of the spline model are that it may not fit well if there are few observations along the soil profile and that it may create unrealistic values (through overshoots or extrapolation) in some instances, for instance near the surface. Also, mass-preserving splines cannot accommodate discontinuities unless, of course, separate spline functions are fitted above and below the discontinuity.</p>
<div class="figure" style="text-align: center"><span id="fig:soil-depth-examples"></span>
<img src="figures/Fig_soil_depth_examples.png" alt="Vertical variation in soil carbon modelled using a logarithmic function (left) and a mass-preserving spline (right) with abrupt changes by horizon ilustrated with solid lines." width="100%" />
<p class="caption">
Figure 5.2: Vertical variation in soil carbon modelled using a logarithmic function (left) and a mass-preserving spline (right) with abrupt changes by horizon ilustrated with solid lines.
</p>
</div>
<p>To fit mass preserving splines we can use:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(aqp)
<span class="co">#&gt; This is aqp 1.15</span>
<span class="kw">library</span>(rgdal)
<span class="co">#&gt; Loading required package: sp</span>
<span class="co">#&gt; rgdal: version: 1.2-16, (SVN revision 701)</span>
<span class="co">#&gt;  Geospatial Data Abstraction Library extensions to R successfully loaded</span>
<span class="co">#&gt;  Loaded GDAL runtime: GDAL 2.2.2, released 2017/09/15</span>
<span class="co">#&gt;  Path to GDAL shared files: /usr/share/gdal/2.2</span>
<span class="co">#&gt;  GDAL binary built with GEOS: TRUE </span>
<span class="co">#&gt;  Loaded PROJ.4 runtime: Rel. 4.9.2, 08 September 2015, [PJ_VERSION: 492]</span>
<span class="co">#&gt;  Path to PROJ.4 shared files: (autodetected)</span>
<span class="co">#&gt;  Linking to sp version: 1.2-5</span>
<span class="kw">library</span>(GSIF)
<span class="co">#&gt; GSIF version 0.5-4 (2017-04-25)</span>
<span class="co">#&gt; URL: http://gsif.r-forge.r-project.org/</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;GSIF&#39;</span>
<span class="co">#&gt; The following object is masked _by_ &#39;.GlobalEnv&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     munsell</span>
prof1.spc &lt;-<span class="st"> </span>prof1
<span class="kw">depths</span>(prof1.spc) &lt;-<span class="st"> </span>id <span class="op">~</span><span class="st"> </span>top <span class="op">+</span><span class="st"> </span>bottom
<span class="co">#&gt; Warning: converting IDs from factor to character</span>
<span class="kw">site</span>(prof1.spc) &lt;-<span class="st"> </span><span class="er">~</span><span class="st"> </span>lon <span class="op">+</span><span class="st"> </span>lat <span class="op">+</span><span class="st"> </span>FAO1988 
<span class="kw">coordinates</span>(prof1.spc) &lt;-<span class="st"> </span><span class="er">~</span><span class="st"> </span>lon <span class="op">+</span><span class="st"> </span>lat
<span class="kw">proj4string</span>(prof1.spc) &lt;-<span class="st"> </span><span class="kw">CRS</span>(<span class="st">&quot;+proj=longlat +datum=WGS84&quot;</span>)
## fit a spline:
ORCDRC.s &lt;-<span class="st"> </span><span class="kw">mpspline</span>(prof1.spc, <span class="dt">var.name=</span><span class="st">&quot;ORCDRC&quot;</span>)
<span class="co">#&gt; Fitting mass preserving splines per profile...</span>
<span class="co">#&gt; </span>
  <span class="op">|</span><span class="st">                                                                       </span>
<span class="st">  </span><span class="er">|</span><span class="st">                                                                 </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%
  <span class="op">|</span><span class="st">                                                                       </span>
<span class="st">  </span><span class="er">|=================================================================|</span><span class="st"> </span><span class="dv">100</span>%
ORCDRC.s<span class="op">$</span>var.std
<span class="co">#&gt;   0-5 cm 5-15 cm 15-30 cm 30-60 cm 60-100 cm 100-200 cm soil depth</span>
<span class="co">#&gt; 1     21      17      7.3      3.3       3.6        1.8        181</span></code></pre></div>
<p>where <code>var.std</code> shows average fitted values for standard depth intervals (i.e. those given in the <em>GlobalSoilMap</em> specifications), and <code>var.1cm</code> are the values fitted at 1–cm increments (Fig. <a href="statistical-theory.html#fig:soil-depth-examples">5.2</a>).</p>
<p>A disadvantage of using mathematical functions to convert soil observations at specific depth intervals to continuous values along the whole profile is that these values are only estimates with associated estimation errors. If estimates are treated as if these were observations then an important source of error is ignored, which may jeopardize the quality of the final soil predictions and in particular the associated uncertainty (see further Section <a href="statistical-theory.html#accuracy-assessment">5.3</a>). This problem can be avoided by taking, for example, a 3D modelling approach <span class="citation">(Poggio and Gimona <a href="references.html#ref-poggio2014national">2014</a>; Hengl <a href="references.html#ref-Hengl2015AfSoilGrids250m">2015</a>)</span>, in which model calibration and spatial interpolation are based on the original soil observations directly (although proper use of this requires that the differences in vertical support between measurements are taken into account also). We will address this also in later sections of this chapter, among others in Section <a href="soilmapping-using-mla.html#prediction-3D">6.1.4</a>.</p>
<div class="rmdnote">
<p>
Soil property-depth relationships are commonly modelled using various types of mathematical functions. Mass-preserving splines, which ensure that the average of the spline function equals the measured value for each sampling layer or horizon, can be used to convert measurements per layer to point values along the profile. Because soils can show both abrupt and continuous transitions within the same profile, no simple spline model is universally valid and case-dependent adjustments often need to be made.
</p>
</div>
</div>
<div id="vertical-aggregation" class="section level3">
<h3><span class="header-section-number">5.1.4</span> Vertical aggregation of soil properties</h3>
<p>As mentioned previously, soil variables refer to aggregate values over specific depth intervals (see Fig. <a href="statistical-theory.html#fig:soil-depth-examples">5.2</a>). For example, the organic carbon content is typically observed per soil horizon with values in e.g. g/kg or permilles <span class="citation">(Conant et al. <a href="references.html#ref-Conant2010">2010</a>; Baritz et al. <a href="references.html#ref-Rainer2010">2010</a>; Panagos et al. <a href="references.html#ref-Panagos2013439">2013</a>)</span>. The <em>Soil Organic Carbon Storage</em> (or <em>Soil Organic Carbon Stock</em>) in the whole profile can be calculated by using Eq <a href="SOC-chapter.html#eq:ocs">(7.1)</a>. Once we have determined soil organic carbon storage (<span class="math inline">\(\mathtt{OCS}\)</span>) per horizon, we can derive the total organic carbon in the soil by summing over all (<span class="math inline">\(H\)</span>) horizons:</p>
<span class="math display" id="eq:ORGCsum">\[\begin{equation}
\mathtt{OCS} = \sum\limits_{h = 1}^H { \mathtt{OCS}_h }
\tag{5.5}
\end{equation}\]</span>
<p>Obviously, the horizon-specific soil organic carbon content (<span class="math inline">\(\mathtt{ORC}_h\)</span>) and total soil organic carbon content (<span class="math inline">\(\mathtt{OCS}\)</span>) are NOT the same variables and need to be analysed and mapped separately.</p>
<p>In the case of pH (<span class="math inline">\(\mathtt{PHI}\)</span>) we usually do not aim at estimating the actual mass or quantity of hydrogen ions. To represent a soil profile with a single number, we may take a weighted mean of the measured pH values per horizon:</p>
<span class="math display" id="eq:pHmean">\[\begin{equation}
\mathtt{PHI} = \sum\limits_{h = 1}^H { w_h \cdot \mathtt{PHI}_h }; \qquad \sum\limits_{h = 1}^H{w_h} = 1
\tag{5.6}
\end{equation}\]</span>
<p>where the weights can be chosen proportional to the horizon thickness:</p>
<span class="math display">\[\begin{equation}
w _h  = \frac{{\mathtt{HSIZE}_h}}{\sum\limits_{h = 1}^H {{\mathtt{HSIZE}}_h}}
\end{equation}\]</span>
<p>Thus, it is important to be aware that all soil variables: (A) can be expressed as relative (percentages) or absolute (mass / quantities) values, and (B) refer to specific horizons or depth intervals or to the whole soil profile.</p>
<p>Similar <em>support</em>-effects show up in the horizontal, because soil observations at <em>point</em> locations are not the same as average or <em>bulk soil samples</em> taken by averaging a large number of point observations on a site or plot <span class="citation">(Webster and Oliver <a href="references.html#ref-Webster2001Wiley">2001</a>)</span>.</p>
<div class="rmdnote">
<p>
Soil variables can refer to a specific depth interval or to the whole profile. The differences in spatial patterns between variables representing fundamentally the same feature (e.g. soil organic carbon in of a specific soil horizon or soil layer and total organic carbon stock in of the whole profile), but at different spatial and vertical support, can be significant.
</p>
</div>
<p>In order to avoid misinterpretation of the results of mapping, we recommend that any delivered map of soil properties should specify the support size in the vertical and lateral directions, the analysis method (detection limit) and measurement units. Such information can be included in the metadata and/or in any key visualization or plot. Likewise, any end-user of soil data should specify whether estimates of the relative or total organic carbon, aggregated or at 2D/3D point support are required.</p>
</div>
</div>
<div id="spatial-prediction-of-soil-variables" class="section level2">
<h2><span class="header-section-number">5.2</span> Spatial prediction of soil variables</h2>
<div id="main-principles" class="section level3">
<h3><span class="header-section-number">5.2.1</span> Main principles</h3>
<p><em>“Pragmatically, the goal of a model is to predict, and at the same time scientists want to incorporate their understanding of how the world works into their models”</em> <span class="citation">(Cressie and Wikle <a href="references.html#ref-cressie2011statistics">2011</a>)</span>. In general terms, spatial prediction consists of the following seven steps (Fig. <a href="statistical-theory.html#fig:general-sp-process">5.3</a>):</p>
<ol style="list-style-type: decimal">
<li><p><em>Select the target variable, scale (spatial resolution) and associated geographical region of interest</em>;</p></li>
<li><p><em>Define a model of spatial variation for the target variable</em>;</p></li>
<li><p><em>Prepare a sampling plan and collect samples and relevant explanatory variables</em>;</p></li>
<li><p><em>Estimate the model parameters using the collected data</em>;</p></li>
<li><p><em>Derive and apply the spatial prediction method associated with the selected model</em>;</p></li>
<li><p><em>Evaluate the spatial prediction outputs and collect new data / run alternative models if necessary</em>;</p></li>
<li><p><em>Use the outputs of the spatial prediction process for decision making and scenario testing</em>.</p></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:general-sp-process"></span>
<img src="figures/Fig_general_SP_process.png" alt="From data to knowledge and back: the general spatial prediction scheme applicable to many environmental sciences." width="85%" />
<p class="caption">
Figure 5.3: From data to knowledge and back: the general spatial prediction scheme applicable to many environmental sciences.
</p>
</div>
<p>The spatial prediction process is repeated at all nodes of a grid covering <span class="math inline">\(D\)</span> (or a space-time domain in case of spatiotemporal prediction) and produces three main outputs:</p>
<ol style="list-style-type: decimal">
<li><p>Estimates of the model parameters (e.g., regression coefficients and variogram parameters), i.e. the <strong>model</strong>;</p></li>
<li><p>Predictions at new locations, i.e. a <strong>prediction map</strong>;</p></li>
<li><p>Estimate of uncertainty associated with the predictions, i.e. a <strong>prediction error variance map</strong>.</p></li>
</ol>
<p>It is clear from Fig. <a href="statistical-theory.html#fig:general-sp-process">5.3</a> that the key steps in the mapping procedure are: (a) <em>choice of the sampling scheme</em>, (b) <em>choice of the model of spatial variation</em>, and (c) <em>choice of the parameter estimation technique</em>. When the sampling scheme is given and cannot be changed, the focus of optimization of the spatial prediction process is then on selecting and fine-tuning the best performing spatial prediction method.</p>
<p>In a geostatistical framework, spatial prediction is estimation of values of some target variable <span class="math inline">\(Z\)</span> at a new location (<span class="math inline">\({\bf{s}}_0\)</span>) given the input data:</p>
<span class="math display" id="eq:sp">\[\begin{equation}
\hat Z({\bf{s}}_0) = E\left\{ Z({\bf{s}}_0)|z({\bf{s}}_i), \; {\bf{X}}({\bf{s}}_0), \; i=1,...,n \right\}
\tag{5.7}
\end{equation}\]</span>
<p>where the <span class="math inline">\(z({\bf{s}}_i)\)</span> are the input set of observations of the target variable, <span class="math inline">\({\bf{s}}_i\)</span> is a geographical location, <span class="math inline">\(n\)</span> is the number of observations and <span class="math inline">\({\bf{X}}({\bf{s}}_0)\)</span> is a list of <em>covariates</em> or explanatory variables, available at all prediction locations within the study area of interest (<span class="math inline">\({\bf{s}} \in \mathbb{A}\)</span>). To emphasise that the model parameters also influence the outcome of the prediction process, this can be made explicit by writing <span class="citation">(Cressie and Wikle <a href="references.html#ref-cressie2011statistics">2011</a>)</span>:</p>
<span class="math display" id="eq:datamodel">\[\begin{equation}
[Z|Y,{\bf{\theta}} ]
\tag{5.8}
\end{equation}\]</span>
<p>where <span class="math inline">\(Z\)</span> is the data, <span class="math inline">\(Y\)</span> is the (hidden) process that we are predicting, and <span class="math inline">\({\bf{\theta}}\)</span> is a list of model parameters (e.g. trend coefficients and variogram parameters).</p>
<p>There are many spatial prediction methods for generating spatial predictions from soil samples and covariate information. All differ in the underlying statistical model of spatial variation, although this model is not always made explicit and different methods may use the same statistical model. A review of currently used digital soil mapping methods is given, for example, in <span class="citation">McBratney et al. (<a href="references.html#ref-McBratney2011HSS">2011</a>)</span>, while the most extensive review can be found in <span class="citation">McBratney, Mendoça Santos, and Minasny (<a href="references.html#ref-McBratney2003Geoderma">2003</a>)</span> and <span class="citation">McBratney, Minasny, and Stockmann (<a href="references.html#ref-mcbratney2018pedometrics">2018</a>)</span>. <span class="citation">Li and Heap (<a href="references.html#ref-LiHeap2010EI">2010</a>)</span> list 40+ spatial prediction / spatial interpolation techniques. Many of the spatial prediction methods are often just different names for essentially the same thing — what is often in the statistical or mathematical literature known under one name, can be implemented through different computational frameworks, and lead to different outputs (mainly because many models are not written out in the finest detail and leave flexibility for actual implementation).</p>
</div>
<div id="soil-sampling" class="section level3">
<h3><span class="header-section-number">5.2.2</span> Soil sampling</h3>
<p>A <em>soil sample</em> is a collection of field observations, usually represented as points. Statistical aspects of sampling methods and approaches are discussed in detail by <span class="citation">Schabenberger and Gotway (<a href="references.html#ref-schabenberger2005statistical">2005</a>)</span> and <span class="citation">de Gruijter et al. (<a href="references.html#ref-deGruijter2006sampling">2006</a>)</span>, while some more practical suggestions for soil sampling can be found in <span class="citation">Pansu, Gautheyrou, and Loyer (<a href="references.html#ref-pansu2001soil">2001</a>)</span> <span class="citation">Webster and Oliver (<a href="references.html#ref-Webster2001Wiley">2001</a>)</span>, <span class="citation">Tan (<a href="references.html#ref-tan2005soil">2005</a>)</span>, and <span class="citation">Legros (<a href="references.html#ref-Legros2006SP">2006</a>)</span>. Some general recommendations for soil sampling are:</p>
<ol style="list-style-type: decimal">
<li><p><em>Points need to cover the entire geographical area of interest and not overrepresent specific subareas that have much different characteristics than the main area.</em></p></li>
<li><p><em>Soil observations at point locations should be done using consistent measurement methods. Replicates should ideally be taken to quantify the measurement error.</em></p></li>
<li><p><em>Bulk sampling is recommended when short-distance spatial variation is expected to be large and not of interest to the map user.</em></p></li>
<li><p><em>If a variogram is to be estimated then the sample size should be <span class="math inline">\(\gg 50\)</span> and there should be sufficient point pairs with small separation distances.</em></p></li>
<li><p><em>If trend coefficients are to be estimated then the covariates at sampling points should cover the entire feature space of each covariate.</em></p></li>
</ol>
<p>The sampling design or rationale used to decide where to locate soil profile observations or sampling points is often not clear and may vary from case to case. Therefore there is no guarantee that available legacy point data used as input to geostatistical modelling satisfy the recommendations listed above. Many of the legacy profile data in the world have been selected using convenience sampling. In fact, many points in traditional soil surveys may have been selected and sampled to capture information about unusual conditions or to locate boundaries at points of transition and maximum confusion about soil properties <span class="citation">(Legros <a href="references.html#ref-Legros2006SP">2006</a>)</span>. Once a soil becomes recognized as being widely distributed and dominant in the landscape, field surveyors often choose not to record observations when that soil is encountered, preferring to focus instead on recording unusual sites or areas where soil transition occurs. Thus the population of available soil point observations may not be representative of the true population of soils, with some soils being either over or under-represented.</p>
<div class="figure" style="text-align: center"><span id="fig:eberg-sampling-locs"></span>
<img src="figures/Fig_eberg_sampling_locs.png" alt="Occurrence probabilities derived for the actual sampling locations (left), and for a purely random sample design with exactly the same number of points (right). Probabilities derived using the `spsample.prob` function from the package. The shaded area on the left indicates which areas (in the environmental space) have been systematically represented, while the white colour indicates areas which have been systematically omitted (and which is not by chance)." width="100%" />
<p class="caption">
Figure 5.4: Occurrence probabilities derived for the actual sampling locations (left), and for a purely random sample design with exactly the same number of points (right). Probabilities derived using the <code>spsample.prob</code> function from the package. The shaded area on the left indicates which areas (in the environmental space) have been systematically represented, while the white colour indicates areas which have been systematically omitted (and which is not by chance).
</p>
</div>
<p>Fig. <a href="statistical-theory.html#fig:eberg-sampling-locs">5.4</a> (the Ebergötzen study area) illustrates a problem of dealing with clustered samples and omission of environmental features. Using the actual samples shown in the plot on the left of Fig. <a href="statistical-theory.html#fig:eberg-sampling-locs">5.4</a> we would like to map the whole area inside the rectangle. This is technically possible, but the user should be aware that the actual Ebergötzen points systematically miss some environmental features: in this case natural forests / rolling hills that were not of interest to the survey project. This does not mean that the Ebergötzen point data are not applicable for geostatistical analyses. It means that the sampling bias and under-representation of specific environmental conditions will lead to spatial predictions that may be biased and highly uncertain under these conditions <span class="citation">(Brus and Heuvelink <a href="references.html#ref-Brus2007Geoderma">2007</a>)</span>.</p>
</div>
<div id="sec:expertsystems" class="section level3">
<h3><span class="header-section-number">5.2.3</span> Knowledge-driven soil mapping</h3>
<p>As mentioned previously in section <a href="soil-resource-inventories-and-soil-maps.html#tacit-knowledge">1.4.8</a>, knowledge-driven mapping is often based on unstated and unformalized rules and understanding that exists mainly in the minds and memories of the individual soil surveyors who conducted field studies and mapping. Expert, or knowledge-based, information can be converted to mapping algorithms by converting conceptual rules to decision trees and/or statistical models <span class="citation">(MacMillan, Pettapiece, and Brierley <a href="references.html#ref-MacMillan2005CJSS">2005</a>; Walter, Lagacherie, and Follain <a href="references.html#ref-Walter2006DSS">2006</a>; Liu and Zhu <a href="references.html#ref-Liu2009">2009</a>)</span>. For example, a surveyor can define the classification rules subjectively, i.e. based on his/her knowledge of the area, then iteratively adjust the model until the output maps fit his/her expectation of the distribution of soils.</p>
<p>In areas where few or no field observations of soil properties are available the most common way to produce estimates is to rely on expert knowledge, or to base estimates on data from other, similar areas. This is a <em>‘knowledge transfer’</em> system. The best example of a knowledge transfer system is the concept of <em>soil series</em> in the USA <span class="citation">(Simonson <a href="references.html#ref-Simonson1968AA">1968</a>)</span>. Soil series (+phases) are the lowest level classes of soil types typically mapped. Each soil series should consist of pedons having soil horizons that are similar in colour, texture, structure, pH, consistence, mineral and chemical composition, and arrangement in the soil profile.</p>
<p>If one finds the same type of soil series repeatedly at similar locations, then there is no need to sample the soil again at additional, similar, locations and, consequently, soil survey field costs can be reduced. This sounds like an attractive approach because one can minimize the survey costs by focusing on delineating the distribution of soil series only. The problem is that there are $&gt;$15,000 soil series in the USA <span class="citation">(Smith <a href="references.html#ref-Smith1986SMSS">1986</a>)</span>, which obviously means that it is not easy to recognize the same soil series just by doing rapid field observations. In addition, the accuracy with which one can recognize a soil series may well fail on standard kappa statistics tests, indicating that there may be substantial confusion between soil series (e.g. large measurement error).</p>
<p>Large parts of the world basically contain few field records and hence one will need to <em>improvise</em> to be able to produce soil predictions. One idea to map such areas is to build attribute tables for representative soil types, then map the distribution of these soil types in areas without using local field samples. <span class="citation">Mallavan, Minasny, and McBratney (<a href="references.html#ref-Mallavan2010PSS">2010</a>)</span> refer to soil classes that can be predicted far away from the actual sampling locations as <em>homosoils</em>. The homosoils concept is based on the assumption that locations that share similar soil-forming factors are likely to exhibit similar soils and soil properties also.</p>
<div class="figure" style="text-align: center"><span id="fig:cross-section-catena"></span>
<img src="figures/Fig_cross_section_catena.png" alt="Landform positions and location of a prediction point for the Maungawhau data set." width="100%" />
<p class="caption">
Figure 5.5: Landform positions and location of a prediction point for the Maungawhau data set.
</p>
</div>
<p>Expert-based systems also rely on using standard mapping paradigms such as the concept of soil series and the catena concept. Fig. <a href="statistical-theory.html#fig:cross-section-catena">5.5</a>, for example, shows a cross-section derived using the elevation data in Fig. <a href="statistical-theory.html#fig:catena-maungawhau-3d">5.6</a>. An experienced soil surveyor would visit the area and produce a diagram showing a sequence of soil types along a cross-section. This expert knowledge can be further converted to a mapping system, provided that it is representative of the area, that it can be formalized through repeatable procedures and that it can be tested using real observations.</p>
<div class="figure" style="text-align: center"><span id="fig:catena-maungawhau-3d"></span>
<img src="figures/Fig_catena_Maungawhau_A.jpg" alt="A cross-section for the Maungawhau volcano dataset commonly used in R to illustrate DEM and image analysis techniques." width="80%" />
<p class="caption">
Figure 5.6: A cross-section for the Maungawhau volcano dataset commonly used in R to illustrate DEM and image analysis techniques.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:catena-maungawhau"></span>
<img src="figures/Fig_catena_Maungawhau_B.png" alt="Associated values of DEM-based covariates: TWI — Topographic Wetness Index and Valley depth for the cross-section from the previous figure." width="100%" />
<p class="caption">
Figure 5.7: Associated values of DEM-based covariates: TWI — Topographic Wetness Index and Valley depth for the cross-section from the previous figure.
</p>
</div>
<p>If some auxiliary information such as a Digital Elevation Model (DEM) is available for the study area, one can derive a number of DEM parameters that can help to quantify landforms and geomorphological processes. Landforms can also automatically be derived by computing various DEM parameters per pixel, or by using knowledge from Fig. <a href="statistical-theory.html#fig:catena-maungawhau">5.7</a> (sample of the study area) to objectively extract landforms and associated soils in an area. Such auxiliary landform information can be informative about the spatial distribution of the soil, which is the key principle of, for example, the SOTER methodology <span class="citation">(Van Engelen and Dijkshoorn <a href="references.html#ref-VanEngelen2012">2012</a>)</span>.</p>
<p>The mapping process of knowledge-driven soil mapping can be summarized as follows <span class="citation">(MacMillan, Pettapiece, and Brierley <a href="references.html#ref-MacMillan2005CJSS">2005</a>; MacMillan et al. <a href="references.html#ref-MacMillan2010DSM">2010</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li><p><em>Sample the study area using cross-sections</em>;</p></li>
<li><p><em>Assign soil types to each landform position or at each sample location</em>;</p></li>
<li><p><em>Derive DEM parameters and other auxiliary data sets</em>;</p></li>
<li><p><em>Develop (fuzzy) rules relating the distribution of soil classes to the auxiliary variables</em>;</p></li>
<li><p><em>Implement (fuzzy) rules to allocate soil classes (or compute memberships) to each grid location</em>;</p></li>
<li><p><em>Generate soil property values for each soil class using representative observations (class centers)</em>;</p></li>
<li><p><em>Estimate values of the target soil variable at grid locations using allocated soil class or membership values and central soil property values for each soil class</em>;</p></li>
</ol>
<p>In mathematical terms, soil property prediction based on fuzzy soil classification values using the SOLIM approach <span class="citation">Zhu et al. (<a href="references.html#ref-Zhu2001">2001</a>; Zhu et al. <a href="references.html#ref-Zhu2010Geoderma">2010</a>)</span> works as follows:</p>
<span class="math display" id="eq:solim">\[\begin{equation}
\begin{aligned}
 \hat z({\bf{s}}_0) = \sum\limits_{c_j = 1}^{c_p} {\nu _{c_j} ({\bf{s}}_0) \cdot z_{c_j} }; &amp; \hspace{.6cm}
 \sum\limits_{c_j = 1}^{c_p} {\nu _j ({\bf{s}}_0)}  = 1\end{aligned}
\tag{5.9}
\end{equation}\]</span>
<p>where <span class="math inline">\(\hat z({\bf{s}}_0)\)</span> is the predicted soil attribute at <span class="math inline">\({\bf{s}}_0\)</span>, <span class="math inline">\(\nu _{c_j} ({\bf{s}}_0)\)</span> is the membership value of class <span class="math inline">\(c_j\)</span> at location <span class="math inline">\({\bf{s}}_0\)</span>, and <span class="math inline">\(z_{c_j}\)</span> is the modal (or best representative) value of the inferred soil attribute of the <span class="math inline">\(c_j\)</span>-th category. The predicted soil attribute is mapped directly from membership maps using a linear additive weighing function. Consider the example of six soil classes <code>A</code>, <code>B</code>, <code>C</code>, <code>D</code>, <code>E</code> and <code>F</code>. The attribute table indicates that soil type <code>A</code> has 10%, <code>B</code> 10%, <code>C</code> 30%, <code>D</code> 40%, <code>E</code> 25%, and <code>F</code> 35% of clay. If the membership values at a grid position are 0.6, 0.2, 0.1, 0.05, 0.00 and 0.00, then Eq. <a href="statistical-theory.html#eq:solim">(5.9)</a> predicts the clay content as 13.5%.</p>
<p>It is obvious from this work flow that the critical aspects that determine the accuracy of the final predictions are the selection of where we locate the cross-sections and the <em>representative soil profiles</em> and the strength of the relationship between the resulting soil classes and target soil properties. <span class="citation">Qi et al. (<a href="references.html#ref-Qi2006Geoderma">2006</a>)</span>, for example, recommended that representative values for soil classes can be identified, if many soil profiles are available, by finding the sampling location that is in the grid cell with highest similarity value for a particular soil class. Soil mappers are now increasingly looking for ways to combine expert systems with statistical data mining and regression modelling techniques.</p>
<p>One problem of using a supervised mapping system as described above is that it is difficult to get an objective estimate of the prediction error (or at least a robust statistical theory has not yet been adopted). The only possibility to assess the accuracy of such maps would be to collect independent validation samples and estimate the mapping accuracy following the methods described in section <a href="statistical-theory.html#accuracy-assessment">5.3</a>. So in fact, also expert-based systems depend on statistical sampling and inference for evaluation of the accuracy of the resulting map.</p>
</div>
<div id="regression-kriging" class="section level3">
<h3><span class="header-section-number">5.2.4</span> Geostatistics-driven soil mapping (pedometric mapping)</h3>
<p>Pedometric mapping is based on using statistical models to predict soil properties, which leads us to the field of geostatistics. Geostatistics treats the soil as a realization of a <em>random process</em> <span class="citation">(Webster and Oliver <a href="references.html#ref-Webster2001Wiley">2001</a>)</span>. It uses the observations and covariates to predict the random process at unobserved locations, which yields conditional probability distributions, whose spread (i.e. standard deviation, width of prediction intervals) explicitly characterizes the uncertainty associated with the predictions. As mentioned previously in section <a href="soil-resource-inventories-and-soil-maps.html#pedometric-mapping">1.3.6</a>, geostatistics is a data-driven approach to soil mapping in which georeferenced point samples are the key input to map production.</p>
<p>Traditional geostatistics has basically been identified with various ways of variogram modeling and kriging <span class="citation">(Haining, Kerry, and Oliver <a href="references.html#ref-Haining2010GEAN780">2010</a>)</span>. Contemporary geostatistics extends linear models and plain kriging techniques to non-linear and hybrid models; it also extends purely spatial models (2D) to 3D and space-time models <span class="citation">(Schabenberger and Gotway <a href="references.html#ref-schabenberger2005statistical">2005</a>; Bivand, Pebesma, and Rubio <a href="references.html#ref-Bivand2008Springer">2008</a>; Diggle and Ribeiro Jr <a href="references.html#ref-Diggle2007Springer">2007</a>; Cressie and Wikle <a href="references.html#ref-cressie2011statistics">2011</a>)</span>. Implementation of more sophisticated geostatistical models for soil mapping is an ongoing activity and is quite challenging (computationally), especially in the case of fine-resolution mapping of large areas <span class="citation">(Hengl, Mendes de Jesus, et al. <a href="references.html#ref-Hengl2017SoilGrids250m">2017</a>)</span>.</p>
<p>Note also that geostatistical mapping is often restricted to quantitative soil properties. Soil prediction models that predict categorical soil variables such as soil type or soil colour class are often quite complex (see e.g. <span class="citation">Hengl et al. (<a href="references.html#ref-Hengl2007Geoderma">2007</a>)</span> and <span class="citation">Kempen et al. (<a href="references.html#ref-Kempen2009Geoderma">2009</a>)</span> for a discussion). The <em>GlobalSoilMap</em> specifications also require predictions in 3D, or at least 2D predictions (layers) for several depth intervals. This can be done by treating each layer separately in a 2D analysis, possibly by taking vertical correlations into account, but also by direct 3D geostatistical modelling. Both approaches are reviewed in the following sections.</p>
<p>Over the last decade statisticians have recommended using <em>model-based geostatistics</em> as the most reliable framework for spatial predictions. The essence of model-based statistics is that <em>“the statistical methods are derived by applying general principles of statistical inference based on an explicitly declared stochastic model of the data generating mechanism”</em> <span class="citation">(Diggle and Ribeiro Jr <a href="references.html#ref-Diggle2007Springer">2007</a>; Brown <a href="references.html#ref-Brown2014JSS">2015</a>)</span>. This avoids <em>ad hoc</em>, heuristic solution methods and has the advantage that it yields generic and portable solutions. Some examples of diverse geostatistical models are given in <span class="citation">Brown (<a href="references.html#ref-Brown2014JSS">2015</a>)</span>.</p>
<p>The basic geostatistical model treats the soil property of interest as the sum of a deterministic trend and a stochastic residual (Eq. <a href="statistical-theory.html#eq:ukm">(5.1)</a>):</p>
<span class="math display" id="eq:ukm-gstat">\[\begin{equation}
Z({\bf{s}}) = m({\bf{s}}) + \varepsilon({\bf{s}})
\tag{5.10}
\end{equation}\]</span>
<p>where <span class="math inline">\(\varepsilon\)</span> and hence <span class="math inline">\(Z\)</span> are normally distributed stochastic processes. This is the same model as that presented in Eq. <a href="statistical-theory.html#eq:ukm">(5.1)</a>, with in this case <span class="math inline">\(\varepsilon = \varepsilon &#39; + \varepsilon &#39;&#39;\)</span> being the sum of the spatially correlated and spatially uncorrelated stochastic components. The mean of <span class="math inline">\(\varepsilon\)</span> is taken to be zero. Note that we use capital letter <span class="math inline">\(Z\)</span> because we use a probabilistic model, i.e. we treat the soil property as an outcome of a stochastic process and define a model of that stochastic process. Ideally, the spatial variation of the stochastic residual of Eq. <a href="statistical-theory.html#eq:ukm-gstat">(5.10)</a> is much less than that of the dependent variable.</p>
<p>When the assumption of normality is not realistic, such as when the frequency distribution of the residuals at observation locations is very skewed, the easiest solution is to take a Transformed Gaussian approach <span class="citation">(Diggle and Ribeiro Jr <a href="references.html#ref-Diggle2007Springer">2007</a> $$3.8)</span> in which the Gaussian geostatistical model is formulated for a transformation of the dependent variable (e.g. logarithmic, logit, square root, Box-Cox transform). A more advanced approach would drop the normal distribution approach entirely and assume a <em>Generalized Linear Geostatistical Model</em> <span class="citation">(Diggle and Ribeiro Jr <a href="references.html#ref-Diggle2007Springer">2007</a>; Brown <a href="references.html#ref-Brown2014JSS">2015</a>)</span> but this complicates the statistical analysis and prediction process dramatically. The Transformed Gaussian approach is nearly as simple as the Gaussian approach although the back-transformation requires attention, especially when the spatial prediction includes a change of support (leading to block kriging). If this is the case, it may be necessary to use a stochastic simulation approach and derive the predictions and associated uncertainty (i.e. the conditional probability distribution) using numerical simulations.</p>
<p>Model-based geostatistics is based on using an explicitly declared stochastic model of the data generating mechanism. One basic geostatistical model of soil variation is to treat the soil property of interest as the sum of a deterministic trend (modelled via some regression function) and a zero-mean stochastic residual.</p>
<p>The trend part of Eq. <a href="statistical-theory.html#eq:ukm-gstat">(5.10)</a> (i.e. <span class="math inline">\(m\)</span>) can take many forms. In the simplest case it would be a constant but usually it is taken as some function of known, exhaustively available covariates. This is where soil mapping can benefit from other sources of information and can implement Jenny’s <em>State Factor Model of soil formation</em> <span class="citation">(Jenny, Salem, and Wallis <a href="references.html#ref-Jenny1968">1968</a>; Jenny <a href="references.html#ref-jenny1994factors">1994</a>; Heuvelink and Webster <a href="references.html#ref-Heuvelink2001Geoderma">2001</a>; McBratney et al. <a href="references.html#ref-McBratney2011HSS">2011</a>)</span>. The covariates are often maps of environmental properties that are known to be related to the soil property of interest (e.g. elevation, land cover, geology) but could also be the outcome of a mechanistic soil process model (such as a soil acidification model, a soil nutrient leaching model or a soil genesis model). In the case of the latter one might opt for taking <span class="math inline">\(m\)</span> equal to the output of the deterministic model, but when the covariates are related environmental properties one must define a structure for <span class="math inline">\(m\)</span> and introduce parameters to be estimated from paired observations of the soil property and covariates. One of the simplest approaches is to use <em>multiple linear regression</em> to predict values at some new location <span class="math inline">\({\bf{s}}_0\)</span> <span class="citation">(Kutner et al. <a href="references.html#ref-kutner2005applied">2005</a>)</span>:</p>
<span class="math display" id="eq:MRK2D">\[\begin{equation}
m({\bf{s}}_0 ) = \sum\limits_{j = 0}^p { \beta _j \cdot X_j ({\bf{s}}_0 )}
\tag{5.11}
\end{equation}\]</span>
<p>where $ _j$ are the regression model coefficients, <span class="math inline">\(\beta _0\)</span> is the intercept, <span class="math inline">\(j=1,\ldots,p\)</span> are <em>covariates</em> or explanatory variables (available at all locations within the study area of interest <span class="math inline">\(\mathbb{A}\)</span>), and <span class="math inline">\(p\)</span> is the number of covariates. Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a> can also include categorical covariates (e.g. maps of land cover, geology, soil type) by representing these by as many binary dummy variables as there are categories (minus one, to be precise, since an intercept is included in the model). In addition, transformed covariates may be included or interactions between covariates. The latter is achieved by extending the set of covariates with products or other mixtures of covariates. However, note that this will dramatically increase the number of covariates. The risk of offering a large number of covariates is that it may become difficult to obtain reliable estimates of the regression coefficients, also because one may run the risk of <em>multicollinearity</em> — property of covariates being mutually strongly correlated (as indicated by <span class="citation">Jenny, Salem, and Wallis (<a href="references.html#ref-Jenny1968">1968</a>)</span> already in <span class="citation">(<a href="references.html#ref-Jenny1968">1968</a>)</span>).</p>
<p>The advantage Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a> is that it is linear in the unknown coefficients, which makes their estimation relatively straightforward and also permits derivation of the uncertainty about the regression coefficients (<span class="math inline">\(\beta\)</span>). However, in many practical cases the linear formulation may be too restrictive and that is why alternative structures to establish the relationship between the dependent and covariates have been extensively developed. Examples of these so-called <em>‘statistical learning’</em> and/or <em>‘machine learning’</em> approaches are:</p>
<ul>
<li><p><em>artificial neural networks</em> <span class="citation">(Yegnanarayana <a href="references.html#ref-yegnanarayana2004artificial">2004</a>)</span>,</p></li>
<li><p><em>classification and regression trees</em> <span class="citation">(Breiman <a href="references.html#ref-breiman1993classification">1993</a>)</span>,</p></li>
<li><p><em>support vector machines</em> <span class="citation">(Hearst et al. <a href="references.html#ref-hearst1998support">1998</a>)</span>,</p></li>
<li><p><em>computer-based expert systems</em>,</p></li>
<li><p><em>random forests</em> <span class="citation">(Breiman <a href="references.html#ref-breiman2001random">2001</a>; Meinshausen <a href="references.html#ref-meinshausen2006quantile">2006</a>)</span>,</p></li>
</ul>
<p>Statistical treatment of many of these methods is given in <span class="citation">Hastie, Tibshirani, and Friedman (<a href="references.html#ref-hastie2009elements">2009</a>)</span>. Care needs to be taken when using machine learning techniques such as random forest because such techniques are more sensitive to noise and blunders in the data .</p>
<p>Most methods listed above require appropriate levels of expertise to avoid pitfalls and incorrect use, but when feasible and used properly these methods should extract maximal information about the target variable from the covariates <span class="citation">(Statnikov, Wang, and Aliferis <a href="references.html#ref-Statnikov2008">2008</a>; Kanevski, Timonin, and Pozdnukhov <a href="references.html#ref-kanevski2009machine">2009</a>)</span>.</p>
<p>The trend (<span class="math inline">\(m\)</span>) relates covariates to soil properties and for this it uses a soil-environment correlation model — the so-called <em>CLORPT model</em>, which was formulated by Jenny in 1941 (a <span class="citation">(<a href="references.html#ref-jenny1994factors">1994</a>)</span> reprint from that book is also available). <span class="citation">McBratney, Mendoça Santos, and Minasny (<a href="references.html#ref-McBratney2003Geoderma">2003</a>)</span> further formulated an extension of the CLORPT model known as the <em>“SCORPAN”</em> model.</p>
<p>The CLORPT model may be written as:</p>
<span class="math display" id="eq:clorpt">\[\begin{equation}
S = f (cl, o, r, p, t)
\tag{1.2}
\end{equation}\]</span>
<p>where <span class="math inline">\(S\)</span> stands for soil (properties and classes), <span class="math inline">\(cl\)</span> for climate, <span class="math inline">\(o\)</span> for organisms (including humans), <span class="math inline">\(r\)</span> is relief, <span class="math inline">\(p\)</span> is parent material or geology and <span class="math inline">\(t\)</span> is time. In other words, we can assume that distribution of both soil and vegetation (at least in a natural system) can be at least partially explained with environmental conditions. Eq. <a href="soil-resource-inventories-and-soil-maps.html#eq:clorpt">(1.2)</a> suggests that soil is a resultant of environmental factors, while in reality there are many feedbacks and soil influences many of the factors on the right-hand side of Eq. <a href="soil-resource-inventories-and-soil-maps.html#eq:clorpt">(1.2)</a>, such as <span class="math inline">\(cl\)</span>, <span class="math inline">\(o\)</span> and <span class="math inline">\(r\)</span>.</p>
<p>Uncertainty about the estimation errors of model coefficients can fairly easily be taken into account in the subsequent prediction analysis if the model is linear in the coefficients, such as in Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a>. In this book we therefore restrict ourselves to this case but allow that the <span class="math inline">\(X_j\)</span>’s in Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a> are derived in various ways.</p>
<p>Since the stochastic residual of Eq. <a href="statistical-theory.html#eq:ukm-gstat">(5.10)</a> is normally distributed and has zero mean, only its variance-covariance remains to be specified:</p>
<span class="math display">\[\begin{equation}
C\left[Z({\bf{s}}),Z({\bf{s}}+\bf{h})\right] = \sigma (\bf{s}) \cdot \sigma(\bf{s}+\bf{h}) \cdot \rho (\bf{h})
\end{equation}\]</span>
<p>where <span class="math inline">\({\bf{h}}\)</span> is the separation distance between two locations. Note that here we assumed that the correlation function <span class="math inline">\(\rho\)</span> is invariant to geographic translation (i.e., it only depends on the distance <span class="math inline">\(\bf{h}\)</span> between locations and not on the locations themselves). If in addition the standard deviation <span class="math inline">\(\sigma\)</span> would be spatially invariant then <span class="math inline">\(C\)</span> would be <em>second-order stationary</em>. These type of simplifying assumptions are needed to be able to estimate the variance-covariance structure of <span class="math inline">\(C\)</span> from the observations. If the standard deviation is allowed to vary with location, then it could be defined in a similar way as in Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a>. The correlation function <span class="math inline">\(\rho\)</span> would be parameterised to a common form (e.g. exponential, spherical, Matérn), thus ensuring that the model is statistically valid and <em>positive-definite</em>. It is also quite common to assume isotropy, meaning that two-dimensional geographic distance <span class="math inline">\({\bf{h}}\)</span> can be reduced to one-dimensional Euclidean distance <span class="math inline">\(h\)</span>.</p>
<p>Once the model has been defined its parameters must be estimated from the data. These are the regression coefficients of the trend (when applicable) and the parameters of the variance-covariance structure of the stochastic residual. Commonly used estimation methods are least squares and maximum likelihood. Both methods have been extensively described in the literature (e.g. <span class="citation">Webster and Oliver (<a href="references.html#ref-Webster2001Wiley">2001</a>)</span> and <span class="citation">Diggle and Ribeiro Jr (<a href="references.html#ref-Diggle2007Springer">2007</a>)</span>). More complex trend models may also use the same techniques to estimate their parameters, although they might also need to rely on more complex parameter estimation methods such as genetic algorithms and <em>simulated annealing</em> <span class="citation">(Lark and Papritz <a href="references.html#ref-lark2003fitting">2003</a>)</span>.</p>
<div class="rmdnote">
<p>
Spatial prediction under the linear Gaussian model with a trend boils down to <em>regression-kriging</em> when the trend coefficients are determined prior to kriging i.e. to <em>universal kriging</em> or <em>kriging with external drift</em> when they are estimated together with kriging weights. Both computational approaches — regression-kriging, kriging with external drift or universal kriging — yield exactly the same predictions if run using the same inputs and assuming the same (global) geostatistical model <span class="citation"><span class="citation">(Hengl, Heuvelink, and Rossiter <a href="references.html#ref-hengl2007regression">2007</a>)</span></span>.
</p>
</div>
<p>The optimal spatial prediction in the case of a model Eq. <a href="statistical-theory.html#eq:ukm-gstat">(5.10)</a> with a linear trend Eq. <a href="statistical-theory.html#eq:MRK2D">(5.11)</a> and a normally distributed residual is given by the well-kown <em>Best Linear Unbiased Predictor</em> (BLUP):</p>
<p><span class="math display">\[\label{E:BLUP}
\hat z({{\bf{s}}_0}) = {\bf{X}}_{\bf{0}}^{\bf{T}}\cdot \hat{\bf{\beta}} + \hat{\bf{\lambda}}_{\bf{0}}^{\bf{T}}\cdot({\bf{z}} - {\bf{X}}\cdot \hat{\bf{\beta}} )\]</span></p>
<p>where the regression coefficients and kriging weights are estimated using:</p>
<span class="math display" id="eq:betas">\[\begin{equation}
\begin{aligned}
\hat{\bf{\beta}}  &amp;= {\left( {{{\bf{X}}^{\bf{T}}}\cdot{{\bf{C}}^{ - {\bf{1}}}}\cdot{\bf{X}}} \right)^{ - {\bf{1}}}}\cdot{{\bf{X}}^{\bf{T}}}\cdot{{\bf{C}}^{ - {\bf{1}}}}\cdot{\bf{z}} \\
\hat{\bf{\lambda}}_{\bf{0}} &amp;= \bf{C}^{ - {\bf{1}}} \cdot {\bf{c}}_{\bf{0}} \notag\end{aligned}
\tag{5.12}
\end{equation}\]</span>
<p>and where <span class="math inline">\({\bf{X}}\)</span> is the matrix of <span class="math inline">\(p\)</span> predictors at the <span class="math inline">\(n\)</span> sampling locations, <span class="math inline">\(\hat{\bf{\beta}}\)</span> is the vector of estimated regression coefficients, <span class="math inline">\(\bf{C}\)</span> is the <span class="math inline">\(n\)</span><span class="math inline">\(n\)</span> variance-covariance matrix of residuals, <span class="math inline">\(\bf{c}_{\bf{0}}\)</span> is the vector of <span class="math inline">\(n\)</span><span class="math inline">\(1\)</span> covariances at the prediction location, and <span class="math inline">\(\bf{\lambda}_{\bf{0}}\)</span> is the vector of <span class="math inline">\(n\)</span> kriging weights used to interpolate the residuals. Derivation of BLUP for spatial data can be found in many standard statistical books e.g. <span class="citation">Stein (<a href="references.html#ref-Stein1999Springer">1999</a>)</span>, <span class="citation">Christensen (<a href="references.html#ref-Christensen2001Springer">2001</a>, 277)</span>, <span class="citation">Venables and Ripley (<a href="references.html#ref-Venables2002Springer">2002</a>, 425–30)</span> and/or <span class="citation">Schabenberger and Gotway (<a href="references.html#ref-schabenberger2005statistical">2005</a>)</span>.</p>
<p>Any form of kriging computes the conditional distribution of <span class="math inline">\(Z({\bf{s}}_0)\)</span> at an unobserved location <span class="math inline">\({\bf{s}}_0\)</span> from the observations <span class="math inline">\(z({\bf{s}}_1 )\)</span>, <span class="math inline">\(z({\bf{s}}_2 ), \ldots , z({\bf{s}}_n )\)</span> and the covariates <span class="math inline">\({\bf{X}}({\bf{s}}_0)\)</span> (matrix of size <span class="math inline">\(p \times n\)</span>). From a statistical perspective this is straightforward for the case of a linear model and normally distributed residuals. However, solving large matrices and more sophisticated model fitting algorithms such as restricted maximum likelihood can take a significant amount of time if the number of observations is large and/or the prediction grid dense. Pragmatic approaches to addressing constraints imposed by large data sets are to constrain the observation data set to local neighbourhoods or to take a multiscale nested approach.</p>
<p>Kriging not only yields optimal predictions but also quantifies the prediction error with the kriging standard deviation. Prediction intervals can be computed easily because the prediction errors are normally distributed. Alternatively, uncertainty in spatial predictions can also be quantified with spatial stochastic simulation. While kriging yields the <em>‘optimal’</em> prediction of the soil property at anyone location, spatial stochastic simulation yields a series of possible values by sampling from the conditional probability distribution. In this way a large number of <em>‘realizations’</em> can be generated, which can be useful when the resulting map needs to be back-transformed or when it is used in a spatial uncertainty propagation analysis. Spatial stochastic simulation of the linear Gaussian model can be done using a technique known as sequential Gaussian simulation <span class="citation">(Goovaerts <a href="references.html#ref-Goovaerts1997Oxford">1997</a>; Yamamoto <a href="references.html#ref-Yamamoto2008">2008</a>)</span>. It is not, in principal, more difficult than kriging but it is certainly numerically more demanding i.e. takes significantly more time to compute.</p>
</div>
<div id="RK-generic" class="section level3">
<h3><span class="header-section-number">5.2.5</span> Regression-kriging (generic model)</h3>
<p>Ignoring the assumptions about the cross-correlation between the trend and residual components, we can extend the regression-kriging model and use any type of (non-linear) regression to predict values (e.g. regression trees, artificial neural networks and other machine learning models), calculate residuals at observation locations, fit a variogram for these residuals, interpolate the residuals using ordinary or simple kriging, and add the result to the predicted regression part. This means that RK can, in general, be formulated as:</p>
<span class="math display" id="eq:RKgeneral">\[\begin{equation}
{\rm prediction} \; = \;
\begin{matrix}
{\rm trend} \; {\rm predicted} \\
{\rm using} \; {\rm regression} \end{matrix} \; + \;
\begin{matrix}
{\rm residual} \; {\rm predicted} \\
{\rm using} \; {\rm kriging} \end{matrix}
\tag{5.13}
\end{equation}\]</span>
<p>Again, statistical inference and prediction is relatively simple if the stochastic residual or a transformation thereof may be assumed normally distributed. Error of the regression-kriging model is likewise a sum of the regression and the kriging model errors.</p>
</div>
<div id="spatial-prediction-using-multiple-linear-regression" class="section level3">
<h3><span class="header-section-number">5.2.6</span> Spatial Prediction using multiple linear regression</h3>
<p>The predictor <span class="math inline">\(\hat Y({{\bf s}_0})\)</span> of <span class="math inline">\(Y({{\bf s}_0})\)</span> is typically taken as a function of covariates and the <span class="math inline">\(Y({\bf s}_i)\)</span> which, upon substitution of the observations <span class="math inline">\(y({\bf s}_i)\)</span>, yields a (deterministic) prediction <span class="math inline">\(\hat y({{\bf s}_0})\)</span>. In the case of multiple linear regression (MLR), model assumptions state that at any location in <span class="math inline">\(D\)</span> the dependent variable is the sum of a linear combination of the covariates at that location and a zero-mean normally distributed residual. Thus, at the <span class="math inline">\(n\)</span> observation locations we have:</p>
<span class="math display" id="eq:lm">\[\begin{equation}
{\bf Y} = {\bf X}^{{\bf T}} \cdot {\bf \beta} + {\bf \varepsilon}
\tag{5.14}
\end{equation}\]</span>
<p>where <span class="math inline">\({\bf Y}\)</span> is a vector of the target variable at the <span class="math inline">\(n\)</span> observation locations, <span class="math inline">\({\bf X}\)</span> is an <span class="math inline">\(n \times p\)</span> matrix of covariates at the same locations and <span class="math inline">\({\bf \beta}\)</span> is a vector of <span class="math inline">\(p\)</span> regression coefficients. The stochastic residual <span class="math inline">\({\bf \varepsilon}\)</span> is assumed to be independently and identically distributed. The paired observations of the target variable and covariates (<span class="math inline">\({\bf y}\)</span> and <span class="math inline">\({\bf X}\)</span>) are used to estimate the regression coefficients using, e.g., Ordinary Least Squares <span class="citation">(Kutner et al. <a href="references.html#ref-Kutner2004McGraw">2004</a>)</span>:</p>
<span class="math display" id="eq:ols-betas">\[\begin{equation}
\hat{{\bf \beta}}  = \left( {{{\bf X}}^{{\bf T}} \cdot {{\bf X}}} \right)^{ - {{\bf 1}}} \cdot
{{\bf X}}^{{\bf T}} \cdot {{\bf y}}
\tag{5.15}
\end{equation}\]</span>
<p>once the coefficients are estimated, these can be used to generate a prediction at <span class="math inline">\({\bf s}_0\)</span>:</p>
<span class="math display">\[\begin{equation}
\hat y({\bf s}_0) = {\bf x}_0^{\bf T} \cdot {\bf \hat \beta}
\end{equation}\]</span>
<p>with associated prediction error variance:</p>
<span class="math display" id="eq:ols-sigma">\[\begin{equation}
\sigma ^2 ({\bf s}_0 ) = var\left[ \varepsilon ({\bf s}_0) \right] \cdot \left[ {1 +
{\mathbf x}_0^{\rm T}  \cdot \left(
{{\mathbf X}^{\rm T}  \cdot {\mathbf X}} \right)^{ -
{\mathbf 1}}  \cdot {\mathbf x}_0 } \right]
\tag{5.16}
\end{equation}\]</span>
<p>here, <span class="math inline">\({\mathbf x}_0\)</span> is a vector with covariates at the prediction location and <span class="math inline">\(var\left[ \varepsilon ({\bf s}_0) \right]\)</span> is the variance of the stochastic residual. The latter is usually estimated by the mean squared error (MSE):</p>
<span class="math display">\[\begin{equation}
{\mathrm{MSE}} = \frac{\sum\limits_{i = 1}^n {(y_i - \hat y_i)^2}}{n-p}
\end{equation}\]</span>
<p>The prediction error variance given by Eq. <a href="statistical-theory.html#eq:ols-sigma">(5.16)</a> is smallest at prediction points where the covariate values are in the center of the covariate (<em>‘feature’</em>) space and increases as predictions are made further away from the center. They are particularly large in case of extrapolation in feature space <span class="citation">(Kutner et al. <a href="references.html#ref-Kutner2004McGraw">2004</a>)</span>. Note that the model defined in Eq. <a href="statistical-theory.html#eq:lm">(5.14)</a> is a non-spatial model because the observation locations and spatial-autocorrelation of the dependent variable are not taken into account.</p>
</div>
<div id="universal-kriging-prediction-error" class="section level3">
<h3><span class="header-section-number">5.2.7</span> Universal kriging prediction error</h3>
<p>In the case of universal kriging, regression-kriging or Kriging with External Drift, the prediction error is computed as <span class="citation">(Christensen <a href="references.html#ref-Christensen2001Springer">2001</a>)</span>:</p>
<span class="math display" id="eq:UKvar">\[\begin{equation}
\hat \sigma _{\tt{UK}}^2 ({\bf{s}}_0 )  = (C_0  + C_1 ) - {\bf{c}}_{\bf{0}}^{\bf{T}}  \cdot {\bf{C}}^{ - {\bf{1}}}  \cdot
{\bf{c}}_{\bf{0}} + \left( {{\bf{X}}_{\bf{0}}  -
{\bf{X}}^{\bf{T}} \cdot {\bf{C}}^{ - {\bf{1}}} \cdot
{\bf{c}}_{\bf{0}} } \right)^{\bf{T}}  \cdot \left( {{\bf{X}}^{\bf{T}}
\cdot {\bf{C}}^{ - {\bf{1}}} \cdot {\bf{X}}} \right)^{{\bf{ - 1}}} \cdot \left( {{\bf{X}}_{\bf{0}}  - {\bf{X}}^{\bf{T}}  \cdot
{\bf{C}}^{ - {\bf{1}}} \cdot {\bf{c}}_{\bf{0}} } \right)
\tag{5.17}
\end{equation}\]</span>
<p>where <span class="math inline">\(C_0 + C_1\)</span> is the sill variation (variogram parameters), <span class="math inline">\(\bf{C}\)</span> is the covariance matrix of the residuals, and <span class="math inline">\({\bf{c}}_0\)</span> is the vector of covariances of residuals at the unvisited location.</p>
<p>Ignoring the mixed component of the prediction variance in Eq. <a href="statistical-theory.html#eq:UKvar">(5.17)</a>, one can also derive a simplified regression-kriging variance i.e. as a sum of the kriging variance and the standard error of estimating the regression mean:</p>
<span class="math display" id="eq:RKvar-simple">\[\begin{equation}
\hat \sigma _{\tt{RK}}^2 ({\bf{s}}_0) = (C_0  + C_1 ) -
{\bf{c}}_{\bf{0}}^{\bf{T}}  \cdot {\bf{C}}^{ - {\bf{1}}}  \cdot
{\bf{c}}_{\bf{0}} + {\it{SEM}}^2
\tag{5.18}
\end{equation}\]</span>
<p>which is the general approach used in the GSIF package.</p>
<p>Note that there will always be a small difference between results of Eq. <a href="statistical-theory.html#eq:UKvar">(5.17)</a> and Eq. <a href="statistical-theory.html#eq:RKvar-simple">(5.18)</a>, and this the major disadvantage of using the general regression-kriging framework for spatial prediction: although the predicted mean derived by using regression-kriging or universal kriging approaches might not differ, the estimate of the prediction variance using Eq. <a href="statistical-theory.html#eq:RKvar-simple">(5.18)</a> will be suboptimal as it ignores product component. On the other hand, the advantage of running separate regression and kriging predictions is worth the sacrifice as the computing time is an order of magnitude shorter and we have more flexibility to combine different type of regression models with kriging when regression is run separately from kriging <span class="citation">(Hengl, Heuvelink, and Rossiter <a href="references.html#ref-hengl2007regression">2007</a>)</span>.</p>
</div>
<div id="regression-kriging-examples" class="section level3">
<h3><span class="header-section-number">5.2.8</span> Regression-kriging examples</h3>
<p>The type of regression-kriging model explained in the previous section can be implemented in by combining the and packages. Consider for example the Meuse case study:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(gstat)
<span class="kw">demo</span>(meuse, <span class="dt">echo=</span><span class="ot">FALSE</span>)</code></pre></div>
<p>We can overlay the points and grids to create the regression matrix by:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meuse.ov &lt;-<span class="st"> </span><span class="kw">over</span>(meuse, meuse.grid)
meuse.ov &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">as.data.frame</span>(meuse), meuse.ov)
<span class="kw">head</span>(meuse.ov[,<span class="kw">c</span>(<span class="st">&quot;x&quot;</span>,<span class="st">&quot;y&quot;</span>,<span class="st">&quot;dist&quot;</span>,<span class="st">&quot;soil&quot;</span>,<span class="st">&quot;om&quot;</span>)])
<span class="co">#&gt;        x      y   dist soil   om</span>
<span class="co">#&gt; 1 181072 333611 0.0014    1 13.6</span>
<span class="co">#&gt; 2 181025 333558 0.0122    1 14.0</span>
<span class="co">#&gt; 3 181165 333537 0.1030    1 13.0</span>
<span class="co">#&gt; 4 181298 333484 0.1901    2  8.0</span>
<span class="co">#&gt; 5 181307 333330 0.2771    2  8.7</span>
<span class="co">#&gt; 6 181390 333260 0.3641    2  7.8</span></code></pre></div>
<p>which allows us to fit a linear model for organic carbon as a function of distance to river and soil type:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.ov)
<span class="kw">summary</span>(m)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; lm(formula = log1p(om) ~ dist + soil, data = meuse.ov)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residuals:</span>
<span class="co">#&gt;     Min      1Q  Median      3Q     Max </span>
<span class="co">#&gt; -1.0831 -0.1504  0.0104  0.2098  0.5913 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   2.3421     0.0425   55.05   &lt; 2e-16 ***</span>
<span class="co">#&gt; dist         -0.8009     0.1787   -4.48 0.0000147 ***</span>
<span class="co">#&gt; soil2        -0.3358     0.0702   -4.78 0.0000041 ***</span>
<span class="co">#&gt; soil3         0.0366     0.1247    0.29      0.77    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Residual standard error: 0.33 on 149 degrees of freedom</span>
<span class="co">#&gt;   (2 observations deleted due to missingness)</span>
<span class="co">#&gt; Multiple R-squared:  0.384,  Adjusted R-squared:  0.371 </span>
<span class="co">#&gt; F-statistic: 30.9 on 3 and 149 DF,  p-value: 1.32e-15</span></code></pre></div>
<p>Next, we can derive the regression residuals and fit a variogram:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">meuse.s &lt;-<span class="st"> </span>meuse[<span class="op">-</span>m<span class="op">$</span>na.action,]
meuse.s<span class="op">$</span>om.res &lt;-<span class="st"> </span><span class="kw">resid</span>(m)
vr.fit &lt;-<span class="st"> </span><span class="kw">fit.variogram</span>(<span class="kw">variogram</span>(om.res<span class="op">~</span><span class="dv">1</span>, meuse.s), <span class="kw">vgm</span>(<span class="dv">1</span>, <span class="st">&quot;Exp&quot;</span>, <span class="dv">300</span>, <span class="dv">1</span>))
vr.fit
<span class="co">#&gt;   model psill range</span>
<span class="co">#&gt; 1   Nug 0.048     0</span>
<span class="co">#&gt; 2   Exp 0.065   285</span></code></pre></div>
<p>With this, all model parameters (four regression coefficients and three variogram parameters) for regression-kriging have been estimated and the model can be used to generate predictions. Note that the regression model we fitted is significant, and the remaining residuals still show spatial auto-correlation. The nugget variation is about of the sill variation.</p>
<p>Using the gstat package <span class="citation">(Pebesma <a href="references.html#ref-Pebesma2004CG">2004</a>; Bivand, Pebesma, and Rubio <a href="references.html#ref-Bivand2013Springer">2013</a>)</span>, regression and kriging can be combined by running universal kriging or kriging with external drift <span class="citation">(Hengl, Heuvelink, and Rossiter <a href="references.html#ref-hengl2007regression">2007</a>)</span>. First the variogram of the residuals is calculated:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">v.s &lt;-<span class="st"> </span><span class="kw">variogram</span>(<span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.s)
vr.fit &lt;-<span class="st"> </span><span class="kw">fit.variogram</span>(v.s, <span class="kw">vgm</span>(<span class="dv">1</span>, <span class="st">&quot;Exp&quot;</span>, <span class="dv">300</span>, <span class="dv">1</span>))
vr.fit
<span class="co">#&gt;   model psill range</span>
<span class="co">#&gt; 1   Nug 0.048     0</span>
<span class="co">#&gt; 2   Exp 0.065   285</span></code></pre></div>
<p>which gives almost the same model parameter values as the regression-kriging above. Next, the kriging can be executed in with a single call to the generic <code>krige</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk &lt;-<span class="st"> </span><span class="kw">krige</span>(<span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.s, meuse.grid, vr.fit)
<span class="co">#&gt; [using universal kriging]</span></code></pre></div>
<p>The package nlme fits the regression model and the variogram of the residuals all at once <span class="citation">(Pinheiro and Bates <a href="references.html#ref-pinheiro2009mixed">2009</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nlme)
m.gls &lt;-<span class="st"> </span><span class="kw">gls</span>(<span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.s, <span class="dt">correlation=</span><span class="kw">corExp</span>(<span class="dt">nugget=</span><span class="ot">TRUE</span>))
m.gls
<span class="co">#&gt; Generalized least squares fit by REML</span>
<span class="co">#&gt;   Model: log1p(om) ~ dist + soil </span>
<span class="co">#&gt;   Data: meuse.s </span>
<span class="co">#&gt;   Log-restricted-likelihood: -26</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt; (Intercept)        dist       soil2       soil3 </span>
<span class="co">#&gt;       2.281      -0.623      -0.244      -0.057 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Correlation Structure: Exponential spatial correlation</span>
<span class="co">#&gt;  Formula: ~1 </span>
<span class="co">#&gt;  Parameter estimate(s):</span>
<span class="co">#&gt;  range nugget </span>
<span class="co">#&gt;   2.00   0.07 </span>
<span class="co">#&gt; Degrees of freedom: 153 total; 149 residual</span>
<span class="co">#&gt; Residual standard error: 0.34</span></code></pre></div>
<p>In this case the regression coefficients have been estimated using Eq. <a href="statistical-theory.html#eq:betas">(5.12)</a> i.e. via <em>Restricted maximum likelihood</em> (REML). The advantage of fitting the regression model and spatial autocorrelation structure at once is that both fits are adjusted: the estimation of the regression coefficients is adjusted for spatial autocorrelation of the residual and variogram parameters are adjusted for the adjusted trend estimate. A disadvantage of using the nlme package is that the computational intensity increases with the size of the data set, so for any data set <span class="math inline">\(\gg 1000\)</span> points the computation time can <em>escalate</em> to tens of hours of computing. On the other hand, coefficients fitted by REML methods might not result in significantly better predictions. Getting the most objective estimate of the model parameters is sometimes not worth the effort, as demonstrated by <span class="citation">Minasny and McBratney (<a href="references.html#ref-Minasny2007Geoderma">2007</a>)</span>.</p>
<p>Simultaneous estimation of regression coefficients and variogram parameters and including estimation errors in regression coefficients into account by using universal kriging / kriging with external drift is more elegant from a statistical point of view, but there are computational and other challenges. One of these is that it is difficult to implement global estimation of regression coefficients with local spatial prediction of residuals, which is a requirement in the case of large spatial data sets. Also, the approach does not extend to more complex non-linear trend models. In such cases we recommend separating trend estimation from kriging of residuals by using the regression-kriging approach discussed above (Eq. <a href="statistical-theory.html#eq:RKgeneral">(5.13)</a>).</p>
</div>
<div id="regression-kriging-examples-using-the-gsif-package" class="section level3">
<h3><span class="header-section-number">5.2.9</span> Regression-kriging examples using the GSIF package</h3>
<p>In the package, most of the steps described above (regression modelling and variogram modelling) used to fit regression-kriging models are wrapped into generic functions. A regression-kriging model can be fitted in one step by running:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, <span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.grid)
<span class="co">#&gt; Fitting a linear model...</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span>
<span class="kw">str</span>(omm, <span class="dt">max.level =</span> <span class="dv">2</span>)
<span class="co">#&gt; Formal class &#39;gstatModel&#39; [package &quot;GSIF&quot;] with 4 slots</span>
<span class="co">#&gt;   ..@ regModel :List of 32</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;class&quot;)= chr [1:2] &quot;glm&quot; &quot;lm&quot;</span>
<span class="co">#&gt;   ..@ vgmModel :&#39;data.frame&#39;:    2 obs. of  9 variables:</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;singular&quot;)= logi FALSE</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;SSErr&quot;)= num 0.00000107</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;call&quot;)= language gstat::fit.variogram(object = svgm, model = ivgm)</span>
<span class="co">#&gt;   ..@ svgmModel:&#39;data.frame&#39;:    15 obs. of  6 variables:</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;direct&quot;)=&#39;data.frame&#39;: 1 obs. of  2 variables:</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;boundaries&quot;)= num [1:16] 0 106 213 319 426 ...</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;pseudo&quot;)= num 0</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;what&quot;)= chr &quot;semivariance&quot;</span>
<span class="co">#&gt;   ..@ sp       :Formal class &#39;SpatialPointsDataFrame&#39; [package &quot;sp&quot;] with 5 slots</span></code></pre></div>
<p>the resulting <code>gstatModel</code> class object consists of a (1) regression component, (2) variogram model for residual, and (3) sample variogram for plotting, (4) spatial locations of observations used to fit the model. To predict values of organic carbon using this model, we can run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating predictions using the trend model (RK method)...</span>
<span class="co">#&gt; [using ordinary kriging]</span>
<span class="co">#&gt; </span>
<span class="dv">100</span>% done
<span class="co">#&gt; Running 5-fold cross validation using &#39;krige.cv&#39;...</span>
<span class="co">#&gt; Creating an object of class &quot;SpatialPredictions&quot;</span>
om.rk
<span class="co">#&gt;   Variable           : om </span>
<span class="co">#&gt;   Minium value       : 1 </span>
<span class="co">#&gt;   Maximum value      : 17 </span>
<span class="co">#&gt;   Size               : 153 </span>
<span class="co">#&gt;   Total area         : 4964800 </span>
<span class="co">#&gt;   Total area (units) : square-m </span>
<span class="co">#&gt;   Resolution (x)     : 40 </span>
<span class="co">#&gt;   Resolution (y)     : 40 </span>
<span class="co">#&gt;   Resolution (units) : m </span>
<span class="co">#&gt;   GLM call formula   : log1p(om) ~ dist + soil </span>
<span class="co">#&gt;   Family             : gaussian </span>
<span class="co">#&gt;   Link function      : identity </span>
<span class="co">#&gt;   Vgm model          : Exp </span>
<span class="co">#&gt;   Nugget (residual)  : 0.048 </span>
<span class="co">#&gt;   Sill (residual)    : 0.065 </span>
<span class="co">#&gt;   Range (residual)   : 285 </span>
<span class="co">#&gt;   RMSE (validation)  : 2.4 </span>
<span class="co">#&gt;   Var explained      : 49.4% </span>
<span class="co">#&gt;   Effective bytes    : 295 </span>
<span class="co">#&gt;   Compression method : gzip</span>
## back-transformation:
meuse.grid<span class="op">$</span>om.rk &lt;-<span class="st"> </span><span class="kw">expm1</span>(om.rk<span class="op">@</span>predicted<span class="op">$</span>om <span class="op">+</span><span class="st"> </span>om.rk<span class="op">@</span>predicted<span class="op">$</span>var1.var<span class="op">/</span><span class="dv">2</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:meuse-om-rk-glm"></span>
<img src="figures/Fig_meuse_om_RK_vs_GLMK.png" alt="Predictions of organic carbon in percent (top soil) for the Meuse data set derived using regression-kriging with transformed values, GLM-kriging, regression tress (rpart) and random forest models combined with kriging. The percentages in brackets indicates amount of variation explained by the models." width="85%" />
<p class="caption">
Figure 5.8: Predictions of organic carbon in percent (top soil) for the Meuse data set derived using regression-kriging with transformed values, GLM-kriging, regression tress (rpart) and random forest models combined with kriging. The percentages in brackets indicates amount of variation explained by the models.
</p>
</div>
<p>We could also have opted for fitting a GLM with a link function, which would look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm2 &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, om<span class="op">~</span>dist<span class="op">+</span>soil, meuse.grid, <span class="dt">family=</span><span class="kw">gaussian</span>(<span class="dt">link=</span>log))
<span class="co">#&gt; Fitting a linear model...</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span>
<span class="kw">summary</span>(omm2<span class="op">@</span>regModel)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = om ~ dist + soil, family = fit.family, data = rmatrix)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;    Min      1Q  Median      3Q     Max  </span>
<span class="co">#&gt; -7.066  -1.492  -0.281   1.635   7.401  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   10.054      0.348   28.88  &lt; 2e-16 ***</span>
<span class="co">#&gt; dist          -8.465      1.461   -5.79    4e-08 ***</span>
<span class="co">#&gt; soil2         -2.079      0.575   -3.62  0.00041 ***</span>
<span class="co">#&gt; soil3          0.708      1.021    0.69  0.48913    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 7.2)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 1791.4  on 152  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 1075.5  on 149  degrees of freedom</span>
<span class="co">#&gt;   (2 observations deleted due to missingness)</span>
<span class="co">#&gt; AIC: 742.6</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 2</span>
om.rk2 &lt;-<span class="st"> </span><span class="kw">predict</span>(omm2, meuse.grid)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating predictions using the trend model (RK method)...</span>
<span class="co">#&gt; [using ordinary kriging]</span>
<span class="co">#&gt; </span>
<span class="dv">100</span>% done
<span class="co">#&gt; Running 5-fold cross validation using &#39;krige.cv&#39;...</span>
<span class="co">#&gt; Creating an object of class &quot;SpatialPredictions&quot;</span></code></pre></div>
<p>or fitting a regression tree:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm3 &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, <span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.grid, <span class="dt">method=</span><span class="st">&quot;rpart&quot;</span>)
<span class="co">#&gt; Fitting a regression tree model...</span>
<span class="co">#&gt; Estimated Complexity Parameter (for prunning): 0.09396</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span></code></pre></div>
<p>or a random forest model:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm4 &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, om<span class="op">~</span>dist<span class="op">+</span>soil, meuse.grid, <span class="dt">method=</span><span class="st">&quot;quantregForest&quot;</span>)
<span class="co">#&gt; Fitting a Quantile Regression Forest model...</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span></code></pre></div>
<p>All regression-kriging models listed above are valid and the differences between their respective results are not likely to be large (Fig. <a href="statistical-theory.html#fig:meuse-om-rk-glm">5.8</a>). Regression tree combined with kriging (rpart-kriging) seems to produce slightly better results i.e. smallest cross-validation error, although the difference between four prediction methods is in fact not large (<span class="math inline">\(\pm5\)</span>% of variance explained). It is important to run such comparisons nevertheless, as they allow us to objectively select the most efficient method.</p>
<div class="figure" style="text-align: center"><span id="fig:rk-vs-rf-meuse"></span>
<img src="figures/Fig_RK_vs_randomForestK_Meuse.png" alt="Predictions of the organic carbon (log-transformed values) using random forest vs linear regression-kriging. The random forest-kriging variance has been derived using the quantregForest package [@meinshausen2006quantile]." width="100%" />
<p class="caption">
Figure 5.9: Predictions of the organic carbon (log-transformed values) using random forest vs linear regression-kriging. The random forest-kriging variance has been derived using the quantregForest package <span class="citation">(Meinshausen <a href="references.html#ref-meinshausen2006quantile">2006</a>)</span>.
</p>
</div>
<p>Fig. <a href="statistical-theory.html#fig:rk-vs-rf-meuse">5.9</a> shows the RK variance derived for the random forest model using the package <span class="citation">(Meinshausen <a href="references.html#ref-meinshausen2006quantile">2006</a>)</span> and the formula in Eq. <a href="statistical-theory.html#eq:RKvar-simple">(5.18)</a>. Note that the quantregForest package estimates a much larger prediction variance than simple linear RK for large parts of the study area.</p>
</div>
<div id="regression-kriging-and-polygon-averaging" class="section level3">
<h3><span class="header-section-number">5.2.10</span> Regression-kriging and polygon averaging</h3>
<p>Although many soil mappers may not realize it, many simpler regression-based techniques can be viewed as a special case of RK, or its variants. Consider for example a technique commonly used to generate predictions of soil properties from polygon maps: weighted averaging. Here the principal covariate available is a polygon map (showing the distribution of mapping units). In this model it is assumed that the trend is constant within mapping units and that the stochastic residual is spatially uncorrelated. In that case the Best Linear Unbiased Predictor of the values is simple averaging of soil properties per unit <span class="citation">(Webster and Oliver <a href="references.html#ref-Webster2001Wiley">2001</a>, 43)</span>:</p>
<span class="math display" id="eq:regavg">\[\begin{equation}
\hat z({\bf{s}}_0 ) = \bar \mu _p  = \frac{1}{{n_p }}\sum\limits_{i = 1}^{n_p } {z({\bf{s}}_i )}
\tag{5.19}
\end{equation}\]</span>
<p>The output map produced by polygon averaging will exhibit abrupt changes at boundaries between polygon units. The prediction variance of this area-class prediction model is simply the sum of the within-unit variance and the estimation variance of the unit mean:</p>
<span class="math display" id="eq:polvar">\[\begin{equation}
\hat \sigma^2 ({\bf{s}}_0 ) = \left( 1 + \frac{1}{n_p } \right) \cdot \sigma _p^2
\tag{5.20}
\end{equation}\]</span>
<p>From Eq. <a href="statistical-theory.html#eq:polvar">(5.20)</a> it is evident that the accuracy of the prediction under this model depends on the degree of within-unit variation. The approach is advantageous if the within-unit variation is small compared to the between-unit variation. The predictions under this model can also be expressed as:</p>
<span class="math display">\[\begin{equation}
\hat z({\bf{s}}_0 ) = \sum\limits_{i = 1}^n {w_i  \cdot z({\bf{s}}_i)}; \qquad w_i  = \left\{ {\begin{array}{*{20}c}
   {1/n_p } &amp; {{\rm for} \; {\bf{s}}_i \in p}  \\
   0 &amp; {{\rm otherwise}}  \\
 \end{array} } \right.
\end{equation}\]</span>
<p>where <span class="math inline">\(p\)</span> is the unit identifier. So in fact, weighted averaging per unit is a special version of regression-kriging where spatial autocorrelation is ignored (assumed zero) and all covariates are categorical variables.</p>
<p>Going back to the Meuse data set, we can fit a regression model for organic matter using soil types as predictors, which gives:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, <span class="kw">log1p</span>(om)<span class="op">~</span>soil<span class="op">-</span><span class="dv">1</span>, meuse.grid)
<span class="co">#&gt; Fitting a linear model...</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span>
<span class="kw">summary</span>(omm<span class="op">@</span>regModel)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; glm(formula = log1p(om) ~ soil - 1, family = fit.family, data = rmatrix)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -1.0297  -0.2087  -0.0044   0.2098   0.6668  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; soil1   2.2236     0.0354    62.9   &lt;2e-16 ***</span>
<span class="co">#&gt; soil2   1.7217     0.0525    32.8   &lt;2e-16 ***</span>
<span class="co">#&gt; soil3   1.9293     0.1006    19.2   &lt;2e-16 ***</span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 0.12)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 672.901  on 153  degrees of freedom</span>
<span class="co">#&gt; Residual deviance:  18.214  on 150  degrees of freedom</span>
<span class="co">#&gt;   (2 observations deleted due to missingness)</span>
<span class="co">#&gt; AIC: 116.6</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 2</span></code></pre></div>
<p>and these regression coefficients for soil classes <code>1</code>, <code>2</code>, <code>3</code> are equal to the mean values per class:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>(<span class="kw">log1p</span>(om) <span class="op">~</span><span class="st"> </span>soil, meuse, mean) 
<span class="co">#&gt;   soil log1p(om)</span>
<span class="co">#&gt; 1    1       2.2</span>
<span class="co">#&gt; 2    2       1.7</span>
<span class="co">#&gt; 3    3       1.9</span></code></pre></div>
<p>Note that this equality can be observed only if we remove the intercept from the regression model, hence we use:</p>
<pre><code>log1p(om) ~ soil-1</code></pre>
<p>and NOT:</p>
<pre><code>log1p(om) ~ soil</code></pre>
<p>The RK model can also be extended to fuzzy memberships, in which case <span class="math inline">\({\rm{MU}}\)</span> values are binary variables with continuous values in the range 0–1. Hence also the SOLIM model (Eq. <a href="statistical-theory.html#eq:solim">(5.9)</a>) is in fact just a special version of regression on mapping units:</p>
<span class="math display" id="eq:SOLIMreg">\[\begin{equation}
\hat z({\bf{s}}_0 ) = \sum\limits_{c_j = 1}^{c_p} {\nu _{c_j} ({\bf{s}}_0) \cdot z_{c_j} } = \sum\limits_{j = 1}^p { {\rm{MU}}_j \cdot \hat b_j}  \hspace{.5cm} {\rm {for}}  \hspace{.5cm}  z_{c_j} = \frac{1}{{n_p }}\sum\limits_{i = 1}^{n_p } {z({\bf{s}}_i )}
\tag{5.21}
\end{equation}\]</span>
<p>where <span class="math inline">\({\rm{MU}}\)</span> is the mapping unit or soil type, <span class="math inline">\(z_{c_j}\)</span> is the modal (or most representative) value of some soil property <span class="math inline">\(z\)</span> for the <span class="math inline">\(c_j\)</span> class, and <span class="math inline">\(n_p\)</span> is total number of points in some mapping unit <span class="math inline">\({\rm{MU}}\)</span>.</p>
<p>Ultimately, spatially weighted averaging of values per mapping unit, different types of regression, and regression kriging are all, in principle, different variants of the same statistical method. The differences are related to whether only categorical or both categorical and continuous covariates are used and whether the stochastic residual is spatially correlated or not. Although there are different ways to implement combined deterministic/stochastic predictions, one should not treat these nominally equivalent techniques as highly different.</p>
</div>
<div id="block-support" class="section level3">
<h3><span class="header-section-number">5.2.11</span> Predictions at point vs block support</h3>
<p>The geostatistical model refers to a soil variable that is defined by the type of property and how it is measured (e.g. soil pH (KCl), soil pH (H<span class="math inline">\(_2\)</span>O), clay content, soil organic carbon measured with spectroscopy), but also to the size and orientation of the soil samples that were taken from the field. This is important because the spatial variation of the dependent variable strongly depends on the support size (e.g. due to an averaging out effect the average organic content of bulked samples taken from 1 ha plots typically has less spatial variation than that of single soil samples taken from squares). This implies that observations at different supports cannot be merged without taking this effect into account <span class="citation">(Webster and Oliver <a href="references.html#ref-Webster2001Wiley">2001</a>)</span>. When making spatial predictions using kriging one can use <em>block-kriging</em> <span class="citation">(Webster and Oliver <a href="references.html#ref-Webster2001Wiley">2001</a>)</span> or <em>area-to-point kriging</em> <span class="citation">(Kyriakidis <a href="references.html#ref-Kyriakidis2004GEAN1135">2004</a>)</span> to make predictions at larger or smaller supports. Both block-kriging and area-to-point kriging are implemented in the gstat package via the generic function <code>krige</code> <span class="citation">(Pebesma <a href="references.html#ref-Pebesma2004CG">2004</a>)</span>.</p>
<p><em>Support</em> can be defined as the integration volume or aggregation level at which an observation is taken or for which an estimate or prediction is given. Support is often used in the literature as a synonym for <em>scale</em> — large support can be related to coarse or general scales and vice versa <span class="citation">(Hengl <a href="references.html#ref-Hengl2006CG">2006</a>)</span>. The notion of support is important to characterize and relate different scales of soil variation <span class="citation">(Schabenberger and Gotway <a href="references.html#ref-schabenberger2005statistical">2005</a>)</span>. Any research of soil properties is made with specific support and spatial spacing, the latter being the distance between sampling locations. If properties are to be used with different support, e.g. when model inputs require a different support than the support of the observations, scaling (aggregation or disaggregation) becomes necessary <span class="citation">(Heuvelink and Pebesma <a href="references.html#ref-Heuvelink1999Geoderma">1999</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:confidence-limits-block"></span>
<img src="figures/Fig_confidence_limits.png" alt="Scheme with predictions on point (above) and block support (below). In the case of various versions of kriging, both point and block predictions smooth the original measurements proportionally to the nugget variation. After @Goovaerts1997Oxford." width="100%" />
<p class="caption">
Figure 5.10: Scheme with predictions on point (above) and block support (below). In the case of various versions of kriging, both point and block predictions smooth the original measurements proportionally to the nugget variation. After <span class="citation">Goovaerts (<a href="references.html#ref-Goovaerts1997Oxford">1997</a>)</span>.
</p>
</div>
<p>Depending on how significant the nugget variation is, prediction variance estimated by a model can be significantly reduced by increasing the support from points to blocks. The block kriging variance is smaller than the point kriging variance for an amount approximately equal to the nugget variation. Even if we take a block size of a few meters this decreases the prediction error significantly, if indeed the nugget variation occurs within a few meters. Because, by definition, many kriging-type techniques smooth original sampled values, one can easily notice that for support sizes smaller than half of the average shortest distance between the sampling locations, both point and block predictions might lead to practically the same predictions (see some examples by <span class="citation">Goovaerts (<a href="references.html#ref-Goovaerts1997Oxford">1997</a>, 158)</span>, <span class="citation">Heuvelink and Pebesma (<a href="references.html#ref-Heuvelink1999Geoderma">1999</a>)</span> and/or <span class="citation">Hengl (<a href="references.html#ref-Hengl2006CG">2006</a>)</span>).</p>
<div class="rmdnote">
<p>
The spatial support is the integration volume or size of the blocks being sampled and/or predicted. By increasing the support size from point to block support we decrease the prediction error variance. The decrease in the prediction error variance is approximately equal to the nugget variance.
</p>
</div>
<p>Consider for example point and block predictions and simulations using the estimates of organic matter content in the topsoil (in dg/kg) for the Meuse case study. We first generate predictions and simulations on point support:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm &lt;-<span class="st"> </span><span class="kw">fit.gstatModel</span>(meuse, <span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.grid)
<span class="co">#&gt; Fitting a linear model...</span>
<span class="co">#&gt; Fitting a 2D variogram...</span>
<span class="co">#&gt; Saving an object of class &#39;gstatModel&#39;...</span>
om.rk.p &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">block=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating predictions using the trend model (RK method)...</span>
<span class="co">#&gt; [using ordinary kriging]</span>
<span class="co">#&gt; </span>
<span class="dv">100</span>% done
<span class="co">#&gt; Running 5-fold cross validation using &#39;krige.cv&#39;...</span>
<span class="co">#&gt; Creating an object of class &quot;SpatialPredictions&quot;</span>
om.rksim.p &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">nsim=</span><span class="dv">20</span>, <span class="dt">block=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>))
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating 20 conditional simulations using the trend model (RK method)...</span>
<span class="co">#&gt; drawing 20 GLS realisations of beta...</span>
<span class="co">#&gt; [using conditional Gaussian simulation]</span>
<span class="co">#&gt; </span>
 <span class="dv">73</span>% done
<span class="dv">100</span>% done
<span class="co">#&gt; Creating an object of class &quot;RasterBrickSimulations&quot;</span>
<span class="co">#&gt; Loading required package: raster</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;raster&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:nlme&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     getData</span>
<span class="co">#&gt; The following objects are masked from &#39;package:aqp&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     metadata, metadata&lt;-</span></code></pre></div>
<p>where the argument <code>block</code> defines the support size for the predictions (in this case points). To produce predictions on block support for square blocks of by we run:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk.b &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">block=</span><span class="kw">c</span>(<span class="dv">40</span>,<span class="dv">40</span>), <span class="dt">nfold=</span><span class="dv">0</span>)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating predictions using the trend model (RK method)...</span>
<span class="co">#&gt; [using ordinary kriging]</span>
<span class="co">#&gt; </span>
<span class="dv">100</span>% done
<span class="co">#&gt; Creating an object of class &quot;SpatialPredictions&quot;</span>
om.rksim.b &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">nsim=</span><span class="dv">2</span>, <span class="dt">block=</span><span class="kw">c</span>(<span class="dv">40</span>,<span class="dv">40</span>))
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating 2 conditional simulations using the trend model (RK method)...</span>
<span class="co">#&gt; drawing 2 GLS realisations of beta...</span>
<span class="co">#&gt; [using conditional Gaussian simulation]</span>
<span class="co">#&gt; </span>
  <span class="dv">9</span>% done
 <span class="dv">19</span>% done
 <span class="dv">27</span>% done
 <span class="dv">34</span>% done
 <span class="dv">41</span>% done
 <span class="dv">48</span>% done
 <span class="dv">56</span>% done
 <span class="dv">62</span>% done
 <span class="dv">69</span>% done
 <span class="dv">76</span>% done
 <span class="dv">83</span>% done
 <span class="dv">89</span>% done
 <span class="dv">96</span>% done
<span class="dv">100</span>% done
<span class="co">#&gt; Creating an object of class &quot;RasterBrickSimulations&quot;</span>
## computationally intensive</code></pre></div>
<p>Visual comparison confirms that the point and block kriging prediction maps are quite similar, while the block kriging variance is much smaller than the point kriging variance (Fig. <a href="statistical-theory.html#fig:meuse-block-predictions">5.11</a>).</p>
<p>Even though block kriging variances are smaller than point kriging variances this does not imply that block kriging should always be preferred over point kriging. If the user interest is in point values rather than block averages, point kriging should be used. Block kriging is also computationally more demanding than point kriging. Note also that it is more difficult (read: more expensive) to validate block kriging maps. In the case of point predictions, maps can be validated to some degree using cross-validation, which is inexpensive. For example, via one can estimate the cross-validation error using the <code>krige.cv</code> function. The package reports automatically the cross-validation error <span class="citation">(Hengl, Nikolić, and MacMillan <a href="references.html#ref-Hengl2013JAG">2013</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk.p
<span class="co">#&gt;   Variable           : om </span>
<span class="co">#&gt;   Minium value       : 1 </span>
<span class="co">#&gt;   Maximum value      : 17 </span>
<span class="co">#&gt;   Size               : 153 </span>
<span class="co">#&gt;   Total area         : 4964800 </span>
<span class="co">#&gt;   Total area (units) : square-m </span>
<span class="co">#&gt;   Resolution (x)     : 40 </span>
<span class="co">#&gt;   Resolution (y)     : 40 </span>
<span class="co">#&gt;   Resolution (units) : m </span>
<span class="co">#&gt;   GLM call formula   : log1p(om) ~ dist + soil </span>
<span class="co">#&gt;   Family             : gaussian </span>
<span class="co">#&gt;   Link function      : identity </span>
<span class="co">#&gt;   Vgm model          : Exp </span>
<span class="co">#&gt;   Nugget (residual)  : 0.048 </span>
<span class="co">#&gt;   Sill (residual)    : 0.065 </span>
<span class="co">#&gt;   Range (residual)   : 285 </span>
<span class="co">#&gt;   RMSE (validation)  : 2.4 </span>
<span class="co">#&gt;   Var explained      : 50.2% </span>
<span class="co">#&gt;   Effective bytes    : 306 </span>
<span class="co">#&gt;   Compression method : gzip</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:meuse-block-predictions"></span>
<img src="figures/Fig_meuse_block_predictions.jpg" alt="Predictions and simulations (2) at point (above) and block (below) support using the Meuse dataset. Note that prediction values produced by point and block methods are quite similar. Simulations on block support produce *smoother* maps than the point-support simulations." width="100%" />
<p class="caption">
Figure 5.11: Predictions and simulations (2) at point (above) and block (below) support using the Meuse dataset. Note that prediction values produced by point and block methods are quite similar. Simulations on block support produce <em>smoother</em> maps than the point-support simulations.
</p>
</div>
<p>which shows that the mapping accuracy at point support is ca. 53% of the original variance (see further Eq. <a href="statistical-theory.html#eq:normvar">(5.28)</a>).</p>
<p>Note also that, cross-validation using block support in is not possible because the input data needed for cross-validation are only available at point support. This basically means that, for the Meuse example, to estimate the mapping accuracy at block support we would have to revisit the study area and collect additional (composite) samples on block support that match the support size of block predictions.</p>
<p>Although prediction at block support is attractive because it leads to more <em>precise</em> predictions, the amount of variation explained by predictions at block at point support might not differ all that much or even at all. Likewise users might not be interested in block averages and may require point predictions. Geostatistical simulations on block support can also be computationally intensive and extra field effort is almost certain to be necessary to validate these maps.</p>
<p>One can use point samples to produce both point and block predictions, but it is more difficult to produce point predictions from block observations. This can be done using area-to-point kriging <span class="citation">(Kyriakidis <a href="references.html#ref-Kyriakidis2004GEAN1135">2004</a>)</span>, but this technique is computationally intensive, yields large prediction uncertainties, and is hampered by the fact that it requires the point support variogram which cannot uniquely be derived from only block observations.</p>
<div class="figure" style="text-align: center"><span id="fig:meuse-block-support-plots1"></span>
<img src="figures/Fig_meuse_block_support_plots1.png" alt="Correlation plots for predictions and prediction variance: point vs block support." width="100%" />
<p class="caption">
Figure 5.12: Correlation plots for predictions and prediction variance: point vs block support.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:meuse-block-support-plots2"></span>
<img src="figures/Fig_meuse_block_support_plots2.png" alt="Difference in variograms sampled from the simulated maps: point vs block support." width="100%" />
<p class="caption">
Figure 5.13: Difference in variograms sampled from the simulated maps: point vs block support.
</p>
</div>
<p>What confuses non-geostatisticians is that both point and block predictions are normally visualized using raster GIS models, hence one does not see that the point predictions refer to the centres of the grid cells <span class="citation">(Hengl <a href="references.html#ref-Hengl2006CG">2006</a>)</span>. In the case of soil survey, the available soil profile data most typically refer to point locations (<span class="math inline">\(1\times 1\)</span> meter or smaller horizontal blocks) because soil samples have small support. In some cases surveyors mix soil samples from different profle locations to produce composite estimates of values. Nevertheless, we can assume that large majority of soil profiles that are collected in the world refer to (lateral) point support. Hence the most typical combination of support size that we work with is: point support for soil property observations, block support for covariates and point or block support for soil property predictions. Modelling at full point support (both soil sampled, covariates and outputs at point support) is in fact very rare. Soil covariates are often derived from remote sensing data, which is almost always delivered at block support.</p>
<p>In principle there is no problem with using covariates at block support to predict the soil at point support, except the strength of relationship between the covariate and target soil property may be weakened by a mismatch in the support. Ideally, one should always try to collect all input data at the finest support possible, then aggregate based on the project requirements. This is unfortunately not always possible hence most inputs are often <em>bulked</em> already and our knowledge about the short range variation is often very limited.</p>
<p>Figs. <a href="statistical-theory.html#fig:meuse-block-support-plots1">5.12</a> and <a href="statistical-theory.html#fig:meuse-block-support-plots2">5.13</a> (correlation plots for Meuse data set) confirms that: (1) predictions on block and point support show practically no differences and (2) the difference in the prediction error variance for point and block kriging effectively equals the nugget variance.</p>
<p>The targeted support size for the <em>GlobalSoilMap</em> project, for example, is 3–arcsecond (ca. 100 m) horizontal dimensions of the SRTM and other covariate data layers used to support prediction of spatial variation in soil properties. This project probably needs predictions at both point and block support at the target resolution, and then also provide aggregated values at coarser resolution blocks (250, 500, 1000 m etc). In any case, understanding consequences of aggregating spatial data and converting from point to block support is important.</p>
<div class="rmdnote">
<p>
In geostatistics, one needs to consider that any input / output spatial layer refers to some support. In soil mapping, there are three main support sizes: support size of the soil samples (sampling support; can refer to point locations or blocks of land), support size of the covariates (often equivalent to the grid cell size), and support size of predictions (again point locations or blocks of land).
</p>
</div>
</div>
<div id="gstat-sims" class="section level3">
<h3><span class="header-section-number">5.2.12</span> Geostatistical simulations</h3>
<p>In statistical terms, the assessment of the uncertainty of produced maps is equally important as the prediction of values at all locations. As shown in the previous Section, uncertainty of soil variables can be assessed in several ways. Three aspects, however, appear to be important for any type of spatial prediction model:</p>
<ul>
<li><p>What are the <em>conditional probability distribution functions</em> (PDFs) of the target variable at each location?</p></li>
<li><p>Where does the prediction model exhibit its <em>largest errors</em>?</p></li>
<li><p>What is the <em>accuracy</em> of the spatial predictions for the whole area of interest? And how accurate is the map overall?</p></li>
</ul>
<p>For situations in which PDFs can be estimated <em>‘reliably’</em>, <span class="citation">Heuvelink and Brown (<a href="references.html#ref-Heuvelink2006Elsevier">2006</a>)</span> argued that they confer a number of advantages over non-probabilistic techniques. For example, PDFs include methods for describing interdependence or correlation between uncertainties, methods for propagating uncertainties through environmental models and methods for tracing the sources of uncertainty in environmental data and models <span class="citation">(Heuvelink <a href="references.html#ref-Heuvelink1998a">1998</a>)</span>. By taking a geostatistical approach, kriging not only yields prediction maps but automatically produces PDFs at prediction points and quantifies the spatial correlation in the prediction errors. Geostatistical simulation,as already introduced in previous sections, refers to a method where realizations are drawn from the conditional PDF using a pseudo-random number generator. These simulations give a more realistic image of the spatial correlation structure or spatial pattern of the target variable because, unlike kriging, they do not smooth out the values.</p>
<div class="figure" style="text-align: center"><span id="fig:sims-cross-section"></span>
<img src="figures/Fig_20_sims_cross_section.png" alt="20 simulations (at block support) of the soil organic carbon for the Meuse study area (cross-section from West to East at Y=330348). Bold line indicates the median value and broken lines indicate upper and lower quantiles (95% probability)." width="100%" />
<p class="caption">
Figure 5.14: 20 simulations (at block support) of the soil organic carbon for the Meuse study area (cross-section from West to East at Y=330348). Bold line indicates the median value and broken lines indicate upper and lower quantiles (95% probability).
</p>
</div>
<p>Estimates of the model accuracy are also provided by the geostatistical model, i.e. the kriging variance. It is useful to note that the variance of a large number of geostatistical simulations will approximate the kriging variance (and likewise will the average of a large number of simulations approximate the kriging prediction map).</p>
<div class="figure" style="text-align: center"><span id="fig:hist-om-predicted-simulated"></span>
<img src="figures/Fig_hist_om_predicted_vs_simulated.png" alt="Histogram for the target variable (Meuse data set; log of organic matter) based on the actual observations (left), predictions at all grid nodes (middle) and simulations (right). Note that the histogram for predicted values will always show somewhat narrower distribution (smoothed), depending on the strength of the model, while the simulations should be able to reproduce the original range (see also @Yamamoto2008)." width="100%" />
<p class="caption">
Figure 5.15: Histogram for the target variable (Meuse data set; log of organic matter) based on the actual observations (left), predictions at all grid nodes (middle) and simulations (right). Note that the histogram for predicted values will always show somewhat narrower distribution (smoothed), depending on the strength of the model, while the simulations should be able to reproduce the original range (see also <span class="citation">Yamamoto (<a href="references.html#ref-Yamamoto2008">2008</a>)</span>).
</p>
</div>
<p>The differences among an ensemble of realizations produced using geostatistical simulations capture the uncertainty associated with the prediction map and can be used to communicate uncertainty or used as input in a spatial uncertainty propagation analysis.</p>
<p>Even though the kriging variance and geostatistical simulations are valid and valuable means to quantify the prediction accuracy, it is important to be aware that these assessments of uncertainty are <em>model-based</em>, i.e. are only valid under the assumptions made by the geostatistical model. A truly <em>model-free</em> assessment of the map accuracy can (only) be obtained by probability-based validation <span class="citation">(Brus, Kempen, and Heuvelink <a href="references.html#ref-Brus2011EJSS">2011</a>)</span>. For this we need independent sample i.e. a sample that was not used to build the model and make the predictions, and that, in addition, was selected from the study area using a probabilistic sampling design.</p>
<p>For the regression-kriging model fitted for organic carbon of the Meuse data set, we can produce 20 simulations by switching the <code>nsim</code> argument:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rksim.p &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">block=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">nsim=</span><span class="dv">20</span>)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating 20 conditional simulations using the trend model (RK method)...</span>
<span class="co">#&gt; drawing 20 GLS realisations of beta...</span>
<span class="co">#&gt; [using conditional Gaussian simulation]</span>
<span class="co">#&gt; </span>
 <span class="dv">18</span>% done
<span class="dv">100</span>% done
<span class="co">#&gt; Creating an object of class &quot;RasterBrickSimulations&quot;</span>
<span class="kw">log1p</span>(meuse<span class="op">@</span>data[<span class="dv">1</span>,<span class="st">&quot;om&quot;</span>])
<span class="co">#&gt; [1] 2.7</span>
<span class="kw">extract</span>(<span class="kw">raster</span>(om.rk.p<span class="op">@</span>predicted), meuse[<span class="dv">1</span>,])
<span class="co">#&gt;     </span>
<span class="co">#&gt; 2.7</span>
<span class="kw">extract</span>(om.rksim.p<span class="op">@</span>realizations, meuse[<span class="dv">1</span>,])
<span class="co">#&gt;      sim1 sim2 sim3 sim4 sim5 sim6 sim7 sim8 sim9 sim10 sim11 sim12 sim13</span>
<span class="co">#&gt; [1,]  2.2  2.8  2.6  3.1  2.6  2.4  2.7  3.1  2.9     3   3.1   2.4   2.6</span>
<span class="co">#&gt;      sim14 sim15 sim16 sim17 sim18 sim19 sim20</span>
<span class="co">#&gt; [1,]   2.8   2.8   2.3   2.1   2.4     3   3.1</span></code></pre></div>
<p>which shows the difference between sampled value (2.681022), predicted value (2.677931) and simulated values for about the same location i.e. a PDF (see also histograms in Fig. <a href="#fig:hist-om-predicted-vs-simulated"><strong>??</strong></a>). If we average the 20 simulations we obtain an alternative estimate of the mean:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(<span class="kw">extract</span>(om.rksim.p<span class="op">@</span>realizations, meuse[<span class="dv">1</span>,]))
<span class="co">#&gt; [1] 2.7</span></code></pre></div>
<p>In this case there remains a small difference between the two results, which is probably due to the small number of simulations (20) used.</p>
</div>
<div id="automated-mapping" class="section level3">
<h3><span class="header-section-number">5.2.13</span> Automated mapping</h3>
<p>Applications of geostatistics today suggest that we will be increasingly using <em>automated mapping</em> algorithms for mapping environmental variables. The authors of the [^3] package for , for example, have produced a wrapper function <code>interpolate</code> that automatically generates predictions for a given input observations and prediction locations <span class="citation">(Pebesma et al. <a href="references.html#ref-Pebesma2011CompGeoSci">2011</a>)</span>. Consider the following example for predicting organic matter content using the Meuse case study:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(intamap)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;intamap&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:raster&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     interpolate</span>
<span class="kw">demo</span>(meuse, <span class="dt">echo=</span><span class="ot">FALSE</span>)
meuse<span class="op">$</span>value =<span class="st"> </span>meuse<span class="op">$</span>zinc
output &lt;-<span class="st"> </span><span class="kw">interpolate</span>(meuse, meuse.grid, <span class="kw">list</span>(<span class="dt">mean=</span><span class="ot">TRUE</span>, <span class="dt">variance=</span><span class="ot">TRUE</span>))
<span class="co">#&gt; R 2018-06-06 16:28:51 interpolating 155 observations, 3103 prediction locations</span>
<span class="co">#&gt; Warning in predictTime(nObs = dim(observations)[1], nPred = nPred, formulaString = formulaString, : </span>
<span class="co">#&gt;  using standard model for estimating time. For better </span>
<span class="co">#&gt;  platform spesific predictions, please run </span>
<span class="co">#&gt;  timeModels &lt;- generateTimeModels()</span>
<span class="co">#&gt;   and save the workspace</span>
<span class="co">#&gt; [1] &quot;estimated time for  copula 133.535601771229&quot;</span>
<span class="co">#&gt; Checking object ... OK</span></code></pre></div>
<p>which gives the (presumably) best interpolation method for the problem at hand (<code>value</code> column), given the time available set with <code>maximumTime</code> <span class="citation">(Pebesma et al. <a href="references.html#ref-Pebesma2011CompGeoSci">2011</a>)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(output, <span class="dt">max.level =</span> <span class="dv">2</span>)
<span class="co">#&gt; List of 16</span>
<span class="co">#&gt;  $ observations       :Formal class &#39;SpatialPointsDataFrame&#39; [package &quot;sp&quot;] with 5 slots</span>
<span class="co">#&gt;  $ formulaString      :Class &#39;formula&#39;  language value ~ 1</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: 0x109fe488&gt; </span>
<span class="co">#&gt;  $ predictionLocations:Formal class &#39;SpatialPixelsDataFrame&#39; [package &quot;sp&quot;] with 7 slots</span>
<span class="co">#&gt;  $ params             :List of 15</span>
<span class="co">#&gt;   ..$ doAnisotropy     : logi TRUE</span>
<span class="co">#&gt;   ..$ testMean         : logi FALSE</span>
<span class="co">#&gt;   ..$ removeBias       : logi NA</span>
<span class="co">#&gt;   ..$ addBias          : logi NA</span>
<span class="co">#&gt;   ..$ biasRemovalMethod: chr &quot;LM&quot;</span>
<span class="co">#&gt;   ..$ nmax             : num 50</span>
<span class="co">#&gt;   ..$ ngrid            : num 100</span>
<span class="co">#&gt;   ..$ nsim             : num 100</span>
<span class="co">#&gt;   ..$ sMin             : num 4</span>
<span class="co">#&gt;   ..$ block            : num(0) </span>
<span class="co">#&gt;   ..$ processType      : chr &quot;gaussian&quot;</span>
<span class="co">#&gt;   ..$ confProj         : logi TRUE</span>
<span class="co">#&gt;   ..$ debug.level      : num 0</span>
<span class="co">#&gt;   ..$ nclus            : num 1</span>
<span class="co">#&gt;   ..$ significant      : logi TRUE</span>
<span class="co">#&gt;   ..- attr(*, &quot;class&quot;)= chr &quot;IntamapParams&quot;</span>
<span class="co">#&gt;  $ outputWhat         :List of 2</span>
<span class="co">#&gt;   ..$ mean    : logi TRUE</span>
<span class="co">#&gt;   ..$ variance: logi TRUE</span>
<span class="co">#&gt;  $ blockWhat          : chr &quot;none&quot;</span>
<span class="co">#&gt;  $ intCRS             : chr &quot;+init=epsg:28992 +proj=sterea +lat_0=52.15616055555555 +lon_0=5.38763888888889 +k=0.9999079 +x_0=155000 +y_0=46&quot;| __truncated__</span>
<span class="co">#&gt;  $ lambda             : num -0.27</span>
<span class="co">#&gt;  $ anisPar            :List of 4</span>
<span class="co">#&gt;   ..$ ratio     : num 1.48</span>
<span class="co">#&gt;   ..$ direction : num 56.1</span>
<span class="co">#&gt;   ..$ Q         : num [1, 1:3] 3.05e-07 2.29e-07 -9.28e-08</span>
<span class="co">#&gt;   .. ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   ..$ doRotation: logi TRUE</span>
<span class="co">#&gt;  $ variogramModel     :Classes &#39;variogramModel&#39; and &#39;data.frame&#39;:    2 obs. of  9 variables:</span>
<span class="co">#&gt;   ..$ model: Factor w/ 20 levels &quot;Nug&quot;,&quot;Exp&quot;,&quot;Sph&quot;,..: 1 3</span>
<span class="co">#&gt;   ..$ psill: num [1:2] 0.00141 0.02527</span>
<span class="co">#&gt;   ..$ range: num [1:2] 0 1282</span>
<span class="co">#&gt;   ..$ kappa: num [1:2] 0 0</span>
<span class="co">#&gt;   ..$ ang1 : num [1:2] 0 33.9</span>
<span class="co">#&gt;   ..$ ang2 : num [1:2] 0 0</span>
<span class="co">#&gt;   ..$ ang3 : num [1:2] 0 0</span>
<span class="co">#&gt;   ..$ anis1: num [1:2] 1 0.674</span>
<span class="co">#&gt;   ..$ anis2: num [1:2] 1 1</span>
<span class="co">#&gt;   ..- attr(*, &quot;singular&quot;)= logi FALSE</span>
<span class="co">#&gt;   ..- attr(*, &quot;SSErr&quot;)= num 2.84e-08</span>
<span class="co">#&gt;   ..- attr(*, &quot;call&quot;)= language fit.variogram(object = experimental_variogram, model = vgm(psill = psill,      model = model, range = range, nugg| __truncated__ ...</span>
<span class="co">#&gt;  $ sampleVariogram    :Classes &#39;gstatVariogram&#39; and &#39;data.frame&#39;:    11 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ np     : num [1:11] 7 31 94 132 147 ...</span>
<span class="co">#&gt;   ..$ dist   : num [1:11] 67.2 94.2 142.9 193.5 248.9 ...</span>
<span class="co">#&gt;   ..$ gamma  : num [1:11] 0.000891 0.005635 0.005537 0.006056 0.010289 ...</span>
<span class="co">#&gt;   ..$ dir.hor: num [1:11] 0 0 0 0 0 0 0 0 0 0 ...</span>
<span class="co">#&gt;   ..$ dir.ver: num [1:11] 0 0 0 0 0 0 0 0 0 0 ...</span>
<span class="co">#&gt;   ..$ id     : Factor w/ 1 level &quot;var1&quot;: 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;direct&quot;)=&#39;data.frame&#39;:    1 obs. of  2 variables:</span>
<span class="co">#&gt;   ..- attr(*, &quot;boundaries&quot;)= num [1:12] 36.8 73.5 110.3 165.5 220.6 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;pseudo&quot;)= num 0</span>
<span class="co">#&gt;   ..- attr(*, &quot;what&quot;)= chr &quot;semivariance&quot;</span>
<span class="co">#&gt;  $ methodParameters   : chr &quot;  vmodel = data.frame(matrix(0,nrow =  2 ,ncol =  9 ))\nnames(vmodel) = c(\&quot;model\&quot;,\&quot;psill\&quot;,\&quot;range\&quot;,\&quot;kappa&quot;| __truncated__</span>
<span class="co">#&gt;  $ predictions        :Formal class &#39;SpatialPixelsDataFrame&#39; [package &quot;sp&quot;] with 7 slots</span>
<span class="co">#&gt;  $ outputTable        : num [1:4, 1:3103] 181180 333740 842 44785 181140 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   ..- attr(*, &quot;transposed&quot;)= logi TRUE</span>
<span class="co">#&gt;  $ processPlot        : chr &quot;&quot;</span>
<span class="co">#&gt;  $ processDescription : chr &quot;Spatial prediction using the method  transGaussian&quot;</span>
<span class="co">#&gt;  - attr(*, &quot;class&quot;)= chr &quot;transGaussian&quot;</span></code></pre></div>
<p>The interpolate function automatically chooses between: (1) kriging, (2) copula methods, (3) inverse distance interpolation, projected spatial gaussian process methods in the package, (4) transGaussian kriging or Yamamoto interpolation.</p>
<div class="rmdnote">
<p>
Automated mapping is the computer-aided generation of (meaningful) maps from measurements. In the context of geostatistical mapping, automated mapping implies that the model fitting, prediction and visualization can be run with little or no human interaction / intervention.
</p>
</div>
<p>The same idea of automated model fitting and prediction has been implemented in the package for , which extends simple point-based models to 2D, 3D, 2D+T regression-kriging models. Some examples of automated soil mapping have been already shown previously.</p>
<div class="figure" style="text-align: center"><span id="fig:scheme-statmodels"></span>
<img src="figures/Fig_statmodels.png" alt="A modern workflow of predictive soil mapping. This often includes state-of-the-art Machine Learning Algorithms." width="60%" />
<p class="caption">
Figure 5.16: A modern workflow of predictive soil mapping. This often includes state-of-the-art Machine Learning Algorithms.
</p>
</div>
<p>Automated mapping, as long as it is not a <em>black-box</em> system, is beneficial for soil mapping applications for several reasons: (1) it saves time and effort needed to get initial results, (2) it allows generation of maps using current data (live geostatistics) even via a web-interfaces, (3) it greatly reduces the workload in cases where maps need to be produced repeatedly, such as when regular updates are needed or the same model is applied in different subareas. In practice, automated mapping is typically a three-stage process (Fig. <a href="statistical-theory.html#fig:scheme-statmodels">5.16</a>):</p>
<ol style="list-style-type: decimal">
<li><p><em>Rapidly generate predictions and a report of analysis</em> (analyze why was a particular technique chosen and how well does it perform? Are there any outliers or artifacts? Which predictors are most significant? etc).</p></li>
<li><p><em>Review the results of spatial prediction and fine-tune some parameters</em> if necessary / filter and/or adjust the input maps.</p></li>
<li><p><em>Re-run the prediction process and publish the final maps</em>.</p></li>
</ol>
<p>hence geostatisticians are still an essential and active part of the process. In automated mapping they primarily focus their expertise on doing interpretation of the results rather than on manually analyzing the data.</p>
<p>It is unlikely that a simple linear prediction model can be used to fit every type of soil data. It is more likely that some customized models, i.e. models designed for each property, would perform better than if a single model were used for a diversity of soil properties. This is because different soil properties have different distributions, they vary differently at different scales, and are controlled by different processes. On the other hand, the preferred way to ensure that a single model can be used to map a variety of soil properties is to develop a generic framework with multi-thematic, multi-scale predictors that allows for iterative search for optimal model structure and parameters, and then implement this model via an automated mapping system.</p>
</div>
<div id="selecting-spatial-prediction-models" class="section level3">
<h3><span class="header-section-number">5.2.14</span> Selecting spatial prediction models</h3>
<p>The purpose of spatial prediction is to (a) produce a map showing spatial distribution of the variable of interest for the area of interest, and (b) to do this in an unbiased way. A comprehensive path to evaluating spatial predictions is the <a href="http://topepo.github.io/caret/index.html">caret</a> approach <span class="citation">(Kuhn and Johnson <a href="references.html#ref-kuhn2013applied">2013</a>)</span>, which wraps up many of the standard processes such as model training and validation, method comparison and visualization. Consider for example the organic matter % in topsoil in the meuse data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret); <span class="kw">library</span>(rgdal)
<span class="co">#&gt; Loading required package: lattice</span>
<span class="co">#&gt; Loading required package: ggplot2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;caret&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:intamap&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     preProcess</span>
<span class="kw">demo</span>(meuse, <span class="dt">echo=</span><span class="ot">FALSE</span>)
meuse.ov &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">over</span>(meuse, meuse.grid), meuse<span class="op">@</span>data)
meuse.ov<span class="op">$</span>x0 =<span class="st"> </span><span class="dv">1</span></code></pre></div>
<p>We can quickly compare performance of using GLM vs random forest vs no model for predicting organic matter (om) by using the caret package functionality:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fitControl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number=</span><span class="dv">2</span>, <span class="dt">repeats=</span><span class="dv">2</span>)
mFit0 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">train</span>(om<span class="op">~</span>x0, <span class="dt">data=</span>meuse.ov, <span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, 
               <span class="dt">family=</span><span class="kw">gaussian</span>(<span class="dt">link=</span>log), <span class="dt">trControl=</span>fitControl, 
               <span class="dt">na.action=</span>na.omit)
<span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type =</span>
<span class="co">#&gt; ifelse(type == : prediction from a rank-deficient fit may be misleading</span>

<span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type =</span>
<span class="co">#&gt; ifelse(type == : prediction from a rank-deficient fit may be misleading</span>

<span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type =</span>
<span class="co">#&gt; ifelse(type == : prediction from a rank-deficient fit may be misleading</span>

<span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type =</span>
<span class="co">#&gt; ifelse(type == : prediction from a rank-deficient fit may be misleading</span>
<span class="co">#&gt; Warning in nominalTrainWorkflow(x = x, y = y, wts = weights, info =</span>
<span class="co">#&gt; trainInfo, : There were missing values in resampled performance measures.</span>
mFit1 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">train</span>(om<span class="op">~</span>soil, <span class="dt">data=</span>meuse.ov, <span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, 
               <span class="dt">family=</span><span class="kw">gaussian</span>(<span class="dt">link=</span>log), <span class="dt">trControl=</span>fitControl, 
               <span class="dt">na.action=</span>na.omit)
mFit2 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">train</span>(om<span class="op">~</span>dist<span class="op">+</span>soil<span class="op">+</span>ffreq, <span class="dt">data=</span>meuse.ov, <span class="dt">method=</span><span class="st">&quot;glm&quot;</span>, 
               <span class="dt">family=</span><span class="kw">gaussian</span>(<span class="dt">link=</span>log), <span class="dt">trControl=</span>fitControl, 
               <span class="dt">na.action=</span>na.omit)
mFit3 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">train</span>(om<span class="op">~</span>dist<span class="op">+</span>soil<span class="op">+</span>ffreq, <span class="dt">data=</span>meuse.ov, <span class="dt">method=</span><span class="st">&quot;ranger&quot;</span>, 
               <span class="dt">trControl=</span>fitControl, <span class="dt">na.action=</span>na.omit)</code></pre></div>
<p>This will run repeated Cross-validation with 50% : 50% splits training and validation, which means that in each iteration models will be refitted from scratch. Next we can compare performance of the three models by using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">resamps &lt;-<span class="st"> </span><span class="kw">resamples</span>(<span class="kw">list</span>(<span class="dt">Mean=</span>mFit0, <span class="dt">Soilmap=</span>mFit1, <span class="dt">GLM=</span>mFit2, <span class="dt">RF=</span>mFit3))
<span class="kw">bwplot</span>(resamps, <span class="dt">layout =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">1</span>), <span class="dt">metric=</span><span class="kw">c</span>(<span class="st">&quot;RMSE&quot;</span>,<span class="st">&quot;Rsquared&quot;</span>), 
       <span class="dt">fill=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">scales =</span> <span class="kw">list</span>(<span class="dt">relation =</span> <span class="st">&quot;free&quot;</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:bwplot-meuse"></span>
<img src="Statistical_theory_files/figure-html/bwplot-meuse-1.png" alt="Comparison of spatial prediction accuracy (RMSE at cross-validation points) for simple averaging (Mean), GLM with only soil map as covariate (Soilmap), GLM and random forest (RF) models with all possible covariates. Error bars indicate range of RMSE values for repeated CV." width="576" />
<p class="caption">
Figure 5.17: Comparison of spatial prediction accuracy (RMSE at cross-validation points) for simple averaging (Mean), GLM with only soil map as covariate (Soilmap), GLM and random forest (RF) models with all possible covariates. Error bars indicate range of RMSE values for repeated CV.
</p>
</div>
<p>In the case above, it seems that random forest (<a href="https///github.com/imbs-hl/ranger">ranger package</a>) helps decrease mean RMSE of predicting organic matter for about 32%:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>((<span class="dv">1</span><span class="op">-</span><span class="kw">min</span>(mFit3<span class="op">$</span>results<span class="op">$</span>RMSE)<span class="op">/</span><span class="kw">min</span>(mFit0<span class="op">$</span>results<span class="op">$</span>RMSE))<span class="op">*</span><span class="dv">100</span>)
<span class="co">#&gt; [1] 31</span></code></pre></div>
<p>There is certainly added value in using spatial covariates (in the case above: distance to water and flooding frequency maps) and in using machine learning for spatial prediction, even with smaller data sets.</p>
<p>Note also that the assessment of spatial prediction accuracy for the three models based on the train function above is model-free, i.e. cross-validation of the models is independent from the models used because at each cross-validation subset fitting of the model is repeated and validation points are kept away from model training. Subsetting point samples is not always trivial however: in order to consider cross-validation as completely reliable, the samples ought to be representative of the study area and preferably collected using objective sampling such as simple random sampling or similar <span class="citation">(Brus, Kempen, and Heuvelink <a href="references.html#ref-Brus2011EJSS">2011</a>)</span>. In the case the sampling locations are clustered in geographical space i.e. if some parts of the study area are completely omitted from sampling, then also the results of cross-validation will reflect that sampling bias / poor representation. In all the following examples we will assume that cross-validation gives a reliable measure of mapping accuracy and we will use it as the basis of accuracy assessment i.e. mapping efficiency. In reality, cross-validation might be tricky to implement and could often lead to somewhat over-optimistic results if either sampling bias exists or/and if there are too little points for model validation. For example, in the case of soil profile data, it is highly recommended that whole profiles are taken out from CV because soil horizons are too strongly correlated (as discussed in detail in <span class="citation">Gasch et al. (<a href="references.html#ref-Gasch2015SPASTA">2015</a>)</span> and <span class="citation">Brenning (<a href="references.html#ref-Brenning2012">2012</a>)</span>).</p>
<p>The whole process of spatial prediction of soil properties could be summarized in 5 steps:</p>
<ol style="list-style-type: decimal">
<li>Initial model comparison (comparison of prediction accuracy and computing time).</li>
<li>Selection of applicable model(s) and estimation of model parameters i.e. model fitting.</li>
<li>Predictions i.e. generation of maps for all areas of interest.</li>
<li>Objective accuracy assessment using independent (cross-)validation.</li>
<li>Export and sharing of maps and summary documentation explaining all processing steps.</li>
</ol>
<p>Studying the <a href="http://topepo.github.io/caret/index.html">caret package tutorial</a> and/or the <a href="https://mlr-org.github.io">mlr tutorials</a> is highly recommended for anyone looking for a systematic introduction to predictive modelling.</p>
</div>
<div id="regression-kriging-3D" class="section level3">
<h3><span class="header-section-number">5.2.15</span> 3D regression-kriging</h3>
<p>Measurements of soil properties at point support can be thought of as describing explicit 3D locations (easting, northing and depth), and are amenable to being dealt with using 3D geostatistics (e.g. 3D kriging). Application of 3D kriging to soil measurements is cumbersome for several reasons:</p>
<ol style="list-style-type: decimal">
<li><p>The differences between sampling intervals and spatial correlation in the horizontal and vertical dimensions are very large (<span class="math inline">\(&lt;10\)</span> in the vertical v.s. 100’s to 1000’s of in the horizontal). The resulting strong anisotropy must be accounted for when the geostatisitcal model is derived. Estimation of the anisotropy may be hampered by the relatively small number of observations along the vertical profile, although under a stationarity assumption it can benefit from the many repetitions of profile data for all profile locations.</p></li>
<li><p>Soil property values refer to vertical block support (usually because they are composite samples, i.e. the average over a soil horizon), hence some of the local variation (in the vertical dimension) has been smoothed out.</p></li>
<li><p>Soil surveyors systematically under-represent lower depths — surveyors tend to systematically take fewer samples as they assume that deeper horizons are of less importance for management or because deeper horizons are more expensive to collect or because deeper horizons are assumed to be more homogeneous and uniform.</p></li>
<li><p>Many soil properties show clear trends along in the vertical dimension and, if this is ignored, the result can be a very poor geostatistical model. It may not be that easy to incorporate a vertical trend because such a trend is generally not consistently similar between different soil types. On the other hand, soil variables are auto-correlated in both horizontal and vertical (depth) dimensions, so that it makes sense to treat them using 3D geostatistics whenever we have enough 3D soil observations.</p></li>
</ol>
<div class="rmdnote">
<p>
Because soil variables are auto-correlated in both horizontal and vertical (depth) dimensions it makes sense to treat them using 3D geostatistics, as long as there are enough measurements in all spatial dimensions.
</p>
</div>
<div class="figure" style="text-align: center"><span id="fig:voxel-scheme"></span>
<img src="figures/Fig_voxel_scheme.png" alt="Spatial 3D prediction locations in a gridded system (voxels). In soil mapping, we often predict for larger blocks of land e.g. 100 to 1000 m, but then for vertical depths of few tens of centimeters, so the output voxels might appear in reality as being somewhat disproportional." width="60%" />
<p class="caption">
Figure 5.18: Spatial 3D prediction locations in a gridded system (voxels). In soil mapping, we often predict for larger blocks of land e.g. 100 to 1000 m, but then for vertical depths of few tens of centimeters, so the output voxels might appear in reality as being somewhat disproportional.
</p>
</div>
<p>The fact that there are almost always <span class="math inline">\(&lt;10\)</span> soil observations over the total depth of a soil profile, so that the estimates of the range in the vertical dimension will be relatively poor, is something that cannot be improved. The fact that soil samples taken by horizon refer to block support is a more serious problem as part of short range variation has been lost, plus we know that the point values do not refer to horizon center but to the whole horizon block, which, in addition to everythign else, tend to be irregular i.e. do not have constant depth and width.</p>
<p>To predict in 3D space, we extend the regression model from Eq. <a href="statistical-theory.html#eq:ukm-gstat">(5.10)</a> with a soil depth function:</p>
<span class="math display" id="eq:MRK3D">\[\begin{equation}
\begin{split}
\hat z({\bf{s}}_0, d_0 ) = \sum\limits_{j = 0}^p {\hat \beta _j \cdot X_j ({\bf{s}}_0, d_0 )} + {\bf{\hat g}}(d_0) + \sum\limits_{i = 1}^n {\hat{\lambda}_i ({\bf{s}}_0, d_0 ) \cdot e({\bf{s}}_i, d_i )}
\end{split}
\tag{5.22}
\end{equation}\]</span>
<p>where <span class="math inline">\(d\)</span> is the 3rd depth dimension expressed in meters from the land surface, <span class="math inline">\({\bf{\hat g}}(d_0)\)</span> is the predicted soil depth function, typically modelled by a spline function. This allows prediction of soil properties at any depth using observations at other depths but does require 3D modelling of the covariance structure, which is not easy because there may be zonal and geometric anisotropies (i.e. the variance and correlation lengths may differ between vertical and horizontal directions). Also, the vertical support of observations becomes important and it should be realized that observations are the averages over depth intervals and not values at points along the vertical axis (Fig. <a href="statistical-theory.html#fig:voxel-scheme">5.18</a>). Spline functions have been proposed and used as mass-preserving curve fitting methods to derive point and block values along the vertical axis from observations at given depth intervals, but the difficulty is that these yield estimates (with uncertainties) that should not be confused with real observations.</p>
<p>A 3D variogram, e.g. modelled using an exponential model with three standard parameters (nugget <span class="math inline">\(c_0\)</span>, partial sill <span class="math inline">\(c_1\)</span>, range parameter <span class="math inline">\(r\)</span>):</p>
<span class="math display" id="eq:exp">\[\begin{equation}
\gamma \left( {\bf{h}} \right) = \left\{
{\begin{array}{*{20}c}
   0 &amp; {{\rm{if}}} &amp; {h = 0}  \\
   {c_0  + c_1  \cdot \left[ {1 - e^{ - \left( {\frac{{h}}
{r}} \right)} } \right]} &amp; {{\rm{if}}} &amp; {h &gt; 0}  \\
 \end{array} } \right. \qquad {\bf{h}} =  \left[ {h_x  , h_y  , h_d } \right]
\tag{5.23}
\end{equation}\]</span>
<p>where the scalar <em>‘distance’</em> <span class="math inline">\(h\)</span> is calculated by scaling horizontal and vertical separation distances using three anisotropy parameters:</p>
<span class="math display" id="eq:anisotropy">\[\begin{equation}
h = \sqrt {\left( {\frac{{h_x  }}{{a_x  }}} \right)^2  + \left( {\frac{{h_y  }}{{a_y  }}} \right)^2  + \left( {\frac{{h_d }}{{a_d }}} \right)^2 }
\tag{5.24}
\end{equation}\]</span>
<p>Typically, in the case of soil data, the anisotropy ratio between horizontal and vertical distances is high — spatial variation observed in a few depth change may correspond with several or more in horizontal space, so that the initial settings of the anisotropy ratio (i.e. the ratio of the horizontal and vertical variogram ranges) are between 3000–8000, for example. Variogram fitting criteria can then be used to optimize the anisotropy parameters. In our case we assumed no horizontal anisotropy and hence assumed <span class="math inline">\(a_x=a_y=1\)</span>, leaving only <span class="math inline">\(a_d\)</span> to be estimated. Once the anisotropy ratio is obtained, 3D variogram modelling does not meaningfully differ from 2D variogram modelling.</p>
<p>The 3D RK framework explained above can be compared to the approach of <span class="citation">Malone et al. (<a href="references.html#ref-Malone2009Geoderma">2009</a>)</span>, who first fit equal-area spline function to estimate the soil properties at a standard depth, and next fit regression and variogram models at each depth. A drawback of the approach by <span class="citation">Malone et al. (<a href="references.html#ref-Malone2009Geoderma">2009</a>)</span>, however, is that the separate models for each depth ignore all vertical correlations. In addition, the equal-area spline is not used to model soil-depth relationships but only to estimate the values at standard depths for sampling locations i.e. it is implemented for each soil profile (site) separately. In the 3D RK framework explained above, a single model is used to generate predictions at any location and for any depth, and which takes into account both horizontal and vertical relationships simultaneously. The 3D RK approach is both easier to implement, and allows for incorporating all (vertical) soil-depth relationships including the spatial correlations.</p>
</div>
<div id="multiscale" class="section level3">
<h3><span class="header-section-number">5.2.16</span> Predicting with multiscale and multisource data</h3>
<p>Fig. <a href="statistical-theory.html#fig:general-sp-process">5.3</a> indicates that spatial prediction is a linear processes with one line of inputs and one line of outputs. In some cases soil mappers have to use methods that can work with <em>multi-scale</em> and/or <em>multi-source</em> data i.e. data with different extents, resolution and uncertainty. Here by <em>multiscale data</em> we imply covariates used for geostatistical mapping that are available at two or more (distinctly different) resolutions, but that cover the same area of interest (see also: <code>RasterStack</code> class in the package). In the case of the <em>multisource data</em>, covariates can be of any scale, they can have a variable extent, and variable accuracy (Fig. <a href="statistical-theory.html#fig:multiscale-vs-multisource">5.19</a>b). In other words, when referring to multiscale data, we assume that the input covariate layers differ only in their resolution; when referring to multisource data, we consider that all technical aspects of the input data could be different.</p>
<p>Organizing (and using) multiscale and multisource data is something that probably can not be avoided in global soil mapping projects. From the GIS perspective, and assuming a democratic right to independently develop and apply spatial prediction models, merging of the multiscale and multisource data is likely to be inevitable.</p>
<div class="figure" style="text-align: center"><span id="fig:multiscale-vs-multisource"></span>
<img src="figures/Fig_multiscale_vs_multisource.png" alt="A general scheme for generating spatial predictions using multiscale and multisource data." width="90%" />
<p class="caption">
Figure 5.19: A general scheme for generating spatial predictions using multiscale and multisource data.
</p>
</div>
<p>As a general strategy, for multi-scale data we propose fitting a single model to combined covariates downscaled or upscaled to the same resolution (Fig. <a href="statistical-theory.html#fig:multiscale-vs-multisource">5.19</a>a), while for the multi-source data we propose using data assimilation methods i.e. merging of predictions (Fig. <a href="statistical-theory.html#fig:multiscale-vs-multisource">5.19</a>b). Imagine if we have covariate layers for one whole continent at some coarse resolution of e.g. 500 m, but for some specific country have other predictions at a finer resolution of e.g. 100 m. Obviously any model we develop that uses both sources of data is limited in its application to just the extent of that country. To ensure that all covariate and soil data available for that country are used to generate predictions, we can fit two models at seperate scales of and and independently, and then merge the predictions only for the extent of the country of interest. In that sense, methods for multisource data merging are more attractive for pan-continental and global projects, because for most of the countries in the world, both soil and covariate data are available at different effective scales.</p>
<div class="rmdnote">
<p>
A sensible approach to merging multiple predictions (usually at multiple resolutions) is to derive a weighted average of two or more predictions / use the per-pixel accuracy to assign the weights, so that more accurate predictions receive more weight <span class="citation"><span class="citation">(Heuvelink and Bierkens <a href="references.html#ref-Heuvelink19921">1992</a>)</span></span>.
</p>
</div>
<p>It is important to emphasize however that, in order to combine various predictors, we do need to have an estimate of the prediction uncertainty e.g. derived using cross-validation, otherwise we are not able to assign the weights. In principle, linear combination of statistical techniques using the equation above should be avoided if a theoretical basis exists that incorporates such combination.</p>
<p>Combined predictions are especially interesting for situations where:</p>
<ul>
<li><p>predictions are produced using different inputs i.e. data with different coverage,</p></li>
<li><p>there are several prediction methods which are equally applicable,</p></li>
<li><p>where no theory exists that reflects combination of spatial prediction methods,</p></li>
<li><p>where fitting and prediction of individual models is faster and less problematic than fitting of a hybrid model.</p></li>
</ul>
<p>Estimation of the prediction variance and confidence interval of combined or merged predictions is more complex than estimation of the mean value.</p>
</div>
</div>
<div id="accuracy-assessment" class="section level2">
<h2><span class="header-section-number">5.3</span> Accuracy assessment and the mapping efficiency</h2>
<div id="mapping-accuracy" class="section level3">
<h3><span class="header-section-number">5.3.1</span> Mapping accuracy and numeric resolution</h3>
<p>Every time a digital soil mapper produces soil maps, soil GIS and soil geographical databases those products can be evaluated using independent validation studies. Unfortunately, much evaluation of soil maps in the world is still done using subjective <em>‘look-good’</em> assessments and the inherent uncertainty of the product is often underreported. In this book we promote objective assessment of the mapping accuracy, i.e. based on statistical testing of ground truth data.</p>
<p><em>Mapping accuracy</em> can be defined as the difference between an estimated value and the <em>“true”</em> value, i.e. a value of the same target variable estimated using a significantly more accurate method. In the most simple terms, accuracy is the error component of the perfectly accurate map <span class="citation">(Mowrer and Congalton <a href="references.html#ref-mowrer2000quantifying">2000</a>)</span>. Although we know that soils form under systematic environmental conditions and probably much of the variation is deterministic (Eq. <a href="statistical-theory.html#eq:ukm">(5.1)</a>), we do not yet have tools that allow us to model soil formation and evolution processes perfectly (see also section <a href="soil-resource-inventories-and-soil-maps.html#sources-uncertainty">1.6.2</a>). The best we can do is to calibrate some spatial prediction model using field records, and then generate (the best possible) predictions. The resulting soil property map, i.e. what we know about soils, is then a sum of two <em>signals</em>:</p>
<span class="math display" id="eq:varparts">\[\begin{equation}
z^{\rm{map}}({\bf{s}}) = Z({\bf{s}}) + \varepsilon({\bf{s}})
\tag{5.25}
\end{equation}\]</span>
<p>where <span class="math inline">\(Z({\bf{s}})\)</span> is the <em>true</em> variation, and <span class="math inline">\(\varepsilon({\bf{s}})\)</span> is the error component i.e. what we do not know. The error component, also known as the <em>error budget</em>, consists of two parts: (1) <em>the unexplained part of soil variation</em>, and (2) <em>the pure noise</em> (sampling and measurement errors described in section <a href="soil-resource-inventories-and-soil-maps.html#sources-uncertainty">1.6.2</a>).</p>
<p>The unexplained part of soil variation is the variation we somehow failed to explain because we are not using all relevant covariates and/or due to the limited sampling intensity. For example, the sampling plan might miss some hot-spots or similar local features. The unexplained part of variation also includes short-range variation, which is possibly deterministic but often not of interest or is simply not feasible to describe at common mapping scales.</p>
<p>The way to determine the error part in Eq. <a href="statistical-theory.html#eq:varparts">(5.25)</a> is to collect additional samples and then determine the average error or the <em>Root Mean Square Error</em> <span class="citation">(Goovaerts <a href="references.html#ref-goovaerts2001geostatistical">2001</a>; Finke <a href="references.html#ref-Finke2006Elsevier">2006</a>; Li and Heap <a href="references.html#ref-LiHeap2010EI">2010</a>)</span>:</p>
<span class="math display" id="eq:RMSE">\[\begin{equation}
{\it RMSE} = \sqrt {\frac{1}{l} \cdot \sum\limits_{i = 1}^l {\left[
{\hat z({\bf{s}}_i ) - z ({\bf{s}}_i )} \right]^2 } }
\tag{5.26}
\end{equation}\]</span>
<p>where <span class="math inline">\(l\)</span> is the number of validation points, and the expected estimate of prediction error at sampling locations is equal to the nugget variation (<span class="math inline">\(E\{ {\it RMSE} \} = \sigma({\bf{h}}=0)\)</span>). In addition to <span class="math inline">\(\it{RMSE}\)</span>, it is often interesting to see also whether the errors are in average positive (over-estimation) or negative (under-estimation) i.e. whether there is maybe any bias in our predictions:</p>
<span class="math display" id="eq:ME">\[\begin{equation}
{\rm ME} = \frac{1}{m} \sum_{j=1}^{m} (\hat y ({\bf s}_j) - y ({\bf s}_j))
\tag{5.27}
\end{equation}\]</span>
<p>To see how much of the global variation budget has been explained by the model we can use:</p>
<span class="math display" id="eq:normvar">\[\begin{equation}
 {\Sigma}_{\%} = \left[ 1 - \frac{{\it{SSE}}}{{\it{SSTO}}} \right] = \left[ 1 - \frac{{\it{RMSE}}^2}{\sigma_z^2} \right] [0-100\%]
\tag{5.28}
\end{equation}\]</span>
<p>where <span class="math inline">\(\it{SSE}\)</span> is the sum of squares for residuals at cross-validation points (i.e. <span class="math inline">\({\it{MSE}} \cdot n\)</span>), and <span class="math inline">\(\it{SSTO}\)</span> is the total sum of squares. <span class="math inline">\({\Sigma}_{\%}\)</span> is a global estimate of the map accuracy, valid only under the assumption that the validation points are spatially independent from the calibration points, representative and large enough (e.g. <span class="math inline">\(l&gt;50\)</span>), and that the error component is normally distributed around the zero value (<span class="math inline">\(E\left\{ {\hat z({{\bf{s}}_i}) - z({{\bf{s}}_i})} \right\} = 0\)</span>).</p>
<p>Once we have estimated <span class="math inline">\(\it{RMSE}\)</span>, we can also determine the effective <em>numeric resolution</em> for the predictions <span class="citation">(Hengl, Nikolić, and MacMillan <a href="references.html#ref-Hengl2013JAG">2013</a>)</span>. For example, assuming that the original sampling variance is 1.85 and that <span class="math inline">\(\it{RMSE}\)</span>=1 (i.e. <span class="math inline">\({\Sigma}_{\%}\)</span>=47%), the effective numeric resolution for predictions is then 0.5 (as shown previously in Fig. <a href="soil-resource-inventories-and-soil-maps.html#fig:sigma-rmse-relationship">1.16</a>). There is probably no need to code the values with a better precision than 0.5 units.</p>
</div>
<div id="accuracy-assessment-methods" class="section level3">
<h3><span class="header-section-number">5.3.2</span> Accuracy assessment methods</h3>
<p>There are three possibilities for estimating the <span class="math inline">\(\it{RMSE}\)</span> (Fig. <a href="statistical-theory.html#fig:cross-validation-types">5.20</a>):</p>
<ol style="list-style-type: decimal">
<li><p><em>Run cross-validation using the same input data used for model fitting</em>.</p></li>
<li><p><em>Collect new samples using a correct probability sampling to ensure unbiased estimate of accuracy</em>.</p></li>
<li><p><em>Compare predicted values with more detailed maps for small study areas produced at much higher accuracy, usually also at much finer level of detail</em>.</p></li>
</ol>
<div class="figure" style="text-align: center"><span id="fig:cross-validation-types"></span>
<img src="figures/Fig_cross_validation_types.png" alt="General types of validation procedures for evaluating accuracy of spatial prediction models." width="70%" />
<p class="caption">
Figure 5.20: General types of validation procedures for evaluating accuracy of spatial prediction models.
</p>
</div>
<p>Although the prediction variance already indicates what the potential accuracy of the maps is, only by independent validation can we determine the true accuracy of the maps. <span class="citation">Brus, Kempen, and Heuvelink (<a href="references.html#ref-Brus2011EJSS">2011</a>)</span> further show that, actually, only if the validation points are selected using some probability-based sampling, like simple random sampling or stratified sampling, can one determine the true accuracy of the produced gridded maps. In practice, we can rarely afford to collect new samples, so that cross-validation is often the only viable option.</p>
</div>
<div id="cross-validation-and-its-limitations" class="section level3">
<h3><span class="header-section-number">5.3.3</span> Cross-validation and its limitations</h3>
<p>Because collecting additional (independent) samples is often impractical and expensive, validation of prediction models is commonly done by using <em>cross-validation</em> i.e. by subsetting the original point set into two data sets — calibration and validation — and then repeating the analysis. There are several types of cross-validation methods <span class="citation">(Bivand, Pebesma, and Rubio <a href="references.html#ref-Bivand2008Springer">2008</a>, 221–26)</span>:</p>
<ul>
<li><p>the <span class="math inline">\(k\)</span>–fold cross-validation — the original sample is split into <span class="math inline">\(k\)</span> equal parts and then each is used for cross-validation;</p></li>
<li><p><em>leave-one-out</em> cross-validation (LOO) — each sampling point is used for cross-validation;</p></li>
<li><p><em>Jackknifing</em> — similar to LOO, but aims at estimating the bias of statistical analysis and not of predictions;</p></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:cross-validation-repetitions"></span>
<img src="figures/Fig_cross_validation_repetitions.png" alt="Left: confidence limits for the amount of variation explained (0–100%) for two spatial prediction methods: inverse distance interpolation (IDW) and regression-kriging (RK) for mapping organic carbon content (Meuse data set). Right: the average amount of variation explained for two realizations (5-fold cross-validation) as a function of number of cross-validation runs (repetitions). In this case the RK method is distinctly better than method IDW, but the cross-validation score seems to stabilize only after 10 runs." width="85%" />
<p class="caption">
Figure 5.21: Left: confidence limits for the amount of variation explained (0–100%) for two spatial prediction methods: inverse distance interpolation (IDW) and regression-kriging (RK) for mapping organic carbon content (Meuse data set). Right: the average amount of variation explained for two realizations (5-fold cross-validation) as a function of number of cross-validation runs (repetitions). In this case the RK method is distinctly better than method IDW, but the cross-validation score seems to stabilize only after 10 runs.
</p>
</div>
<div class="rmdnote">
<p>
Cross-validation is a cost-efficient way to get an objective estimate of the mapping accuracy. Under assumption that the input samples are representative of the study area (ideally collected using objective / probability sampling to avoid any kind of bias).
</p>
</div>
<p>Both <span class="math inline">\(k\)</span>–fold and the leave-one-out cross validation are implemented in the e.g. package (<code>krige.cv</code> methods), which makes this type of assessment convenient to implement. Note also that cross-validation is not necessarily independent — points used for cross-validation are a subset of the original sampling design, hence if the original design is biased and/or non-representative, then also the cross-validation might not reveal the true accuracy of a technique. However, if the sampling design has been generated using some unbiased design based sampling (e.g. random sampling), randomly taken subsets will be an unbiased estimators of the true mapping accuracy.</p>
<p><em>“Models can only be evaluated in relative terms, and their predictive value is always open to question. The primary value of models is heuristic.”</em> <span class="citation">(Oreskes, Shrader-Frechette, and Belitz <a href="references.html#ref-Oreskes04021994">1994</a>)</span> Hence also in soil mapping accuracy assessment should only be considered in relative terms. Each evaluation of soil mapping accuracy might give somewhat different numbers, so it is often a good idea to repeat the evaluation multiple times. Also cross-validation requires enough repetition (<span class="math inline">\(\gg 2\)</span>) otherwise over-positive or over-negative results can be produced by chance (Fig. <a href="statistical-theory.html#fig:cross-validation-repetitions">5.21</a>). Many geostatisticians (see e.g. <code>krige.cv</code> function described in <span class="citation">Bivand, Pebesma, and Rubio (<a href="references.html#ref-Bivand2008Springer">2008</a>, 222–23)</span>) suggest that at least 5 repetitions are needed to produce <em>‘stable’</em> measure of the mapping accuracy. If only one realization of cross-validation is used, this can accidentally lead to over-optimistic or over-pessimistic estimate of the true mapping accuracy.</p>
</div>
<div id="accuracy-of-the-predicted-model-uncertainty" class="section level3">
<h3><span class="header-section-number">5.3.4</span> Accuracy of the predicted model uncertainty</h3>
<p>Recall from Eq. <a href="statistical-theory.html#eq:sp">(5.7)</a> that the output of the prediction process is typically (1) predicted mean value at some location (<span class="math inline">\(\hat Z({\bf{s}}_0)\)</span>), and (2) predicted prediction variance i.e. regression-kriging error (<span class="math inline">\(\hat{\sigma}({\bf{s}}_0)\)</span>). In the previous section we have shown some common accuracy measures for the prediction of the mean value. It might sound confusing but, in geostatistics, one can also validate the <em>uncertainty of uncertainty</em> i.e. derive the <em>error of the estimation error</em>. In the case of the Meuse data set:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk.cv &lt;-<span class="st"> </span><span class="kw">krige.cv</span>(<span class="kw">log1p</span>(om)<span class="op">~</span>dist<span class="op">+</span>soil, meuse.s, vr.fit)
<span class="kw">hist</span>(om.rk.cv<span class="op">$</span>zscore, <span class="dt">main=</span><span class="st">&quot;Z-scores histogram&quot;</span>, 
       <span class="dt">xlab=</span><span class="st">&quot;z-score value&quot;</span>, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">breaks=</span><span class="dv">25</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:z-scores-histogram"></span>
<img src="Statistical_theory_files/figure-html/z-scores-histogram-1.png" alt="Z-scores for the cross-validation of the soil organic carbon model." width="576" />
<p class="caption">
Figure 5.22: Z-scores for the cross-validation of the soil organic carbon model.
</p>
</div>
<p>Here the cross-validation function <code>krige.cv</code> reports errors at validation points (5–fold cross-validation by default), but it also compares the different between the regression-kriging error estimated by the model and the actual error. The ratio between the actual and expected error is referred to as the <span class="math inline">\(z\)</span>-scores <span class="citation">(Bivand, Pebesma, and Rubio <a href="references.html#ref-Bivand2008Springer">2008</a>, 225)</span>:</p>
<span class="math display" id="eq:z-scores">\[\begin{equation}
 \sigma_r ({\bf{s}}_j) = \frac{\hat z({\bf{s}}_j ) - z^* ({\bf{s}}_j )}{\hat{\sigma}({\bf{s}}_j )}; \qquad  E\{var(\sigma_r)\} = 1
\tag{5.29}
\end{equation}\]</span>
<p>Ideally, the mean value of <span class="math inline">\(z\)</span>-scores should be around 0 and the variance of the <span class="math inline">\(z\)</span>-scores should be around 1. If the <span class="math inline">\(z\)</span>-score variance is substantially smaller than <span class="math inline">\(1\)</span> then the model overestimates the actual prediction uncertainty. If the <span class="math inline">\(z\)</span>-score variance is substantially greater than <span class="math inline">\(1\)</span> then the model underestimates the prediction uncertainty. The difference between the actual and predicted model error can be also referred to as the <em>model reliability</em>. A model can be accurate but then <em>‘overpessimistic’</em> if the predicted model uncertainty is wider than the actual uncertainty, or accurate but <em>‘overoptimistic’</em> if the actual confidence limits are too narrow (Fig. <a href="statistical-theory.html#fig:difference-accuracy-reliability">5.23</a>).</p>
<p>Ideally, we aim at producing predictions and prediction error maps that are both accurate and realistic or at least realistic. For a review of methods for assessment of uncertainty in soil maps refer to <span class="citation">Goovaerts (<a href="references.html#ref-goovaerts2001geostatistical">2001</a>, 3–26)</span> and/or <span class="citation">Brus, Kempen, and Heuvelink (<a href="references.html#ref-Brus2011EJSS">2011</a>)</span>.</p>
<div class="figure" style="text-align: center"><span id="fig:difference-accuracy-reliability"></span>
<img src="figures/Fig_difference_accuracy_reliability.png" alt="Mapping accuracy and model reliability (accuracy of the prediction intervals vs actual intervals). Although a method can be accurate in predicting the mean values, it could fail in predicting the prediction intervals i.e. the associated uncertainty." width="85%" />
<p class="caption">
Figure 5.23: Mapping accuracy and model reliability (accuracy of the prediction intervals vs actual intervals). Although a method can be accurate in predicting the mean values, it could fail in predicting the prediction intervals i.e. the associated uncertainty.
</p>
</div>
<p>In the case discussed above (Fig. <a href="statistical-theory.html#fig:z-scores-histogram">5.22</a>) it appears that the error estimated by the model is often different from the actual regression-kriging variance: in this case the estimated values are often lower than actual measured values (under-estimation), so that the whole histogram shifts toward 0 value. Because variance of the <span class="math inline">\(z\)</span>-scores is <span class="math inline">\(&lt;1\)</span>:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(om.rk.cv<span class="op">$</span>zscore, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
<span class="co">#&gt; [1] 0.95</span></code></pre></div>
<p>we can also say that the regression-kriging variance is slightly over-pessimistic or too conservative about the actual accuracy of the model. On the other hand, Fig. <a href="statistical-theory.html#fig:z-scores-histogram">5.22</a> shows that, at some points, the cross-validation errors are much higher than the error estimated by the model.</p>
</div>
<div id="derivation-and-interpretation-of-prediction-interval" class="section level3">
<h3><span class="header-section-number">5.3.5</span> Derivation and interpretation of prediction interval</h3>
<p>Another important issue for understanding the error budget is derivation of <em>prediction interval</em> i.e. upper and lower values of the target variable for which we assume that our predictions will fall within with a high probability (e.g. 19 out of 20 times or the 95% probability). Prediction interval or <em>confidence limits</em> are commonly well accepted by users as the easiest way to communicate uncertainty <span class="citation">(Brodlie, Osorio, and Lopes <a href="references.html#ref-brodlie2012review">2012</a>)</span>. For example, organic carbon in Meuse study area (based on 153 samples of organic matter) has a 95% interval of 2–16%:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">signif</span>(<span class="kw">quantile</span>(meuse<span class="op">$</span>om, <span class="kw">c</span>(.<span class="dv">025</span>, .<span class="dv">975</span>), <span class="dt">na.rm=</span><span class="ot">TRUE</span>), <span class="dv">2</span>)
<span class="co">#&gt; 2.5%  98% </span>
<span class="co">#&gt;    2   16</span></code></pre></div>
<p>We have previously fitted a geostatistical model using two covariates, which can now be used to generate predictions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rk &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating predictions using the trend model (RK method)...</span>
<span class="co">#&gt; [using ordinary kriging]</span>
<span class="co">#&gt; </span>
<span class="dv">100</span>% done
<span class="co">#&gt; Running 5-fold cross validation using &#39;krige.cv&#39;...</span>
<span class="co">#&gt; Creating an object of class &quot;SpatialPredictions&quot;</span></code></pre></div>
<p>and which allows us to estimate confidence limits for organic matter (assuming normal distribution) at any location within the study area e.g.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">pt1 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="dv">179390</span>, <span class="dt">y=</span><span class="dv">330820</span>)
<span class="kw">coordinates</span>(pt1) &lt;-<span class="st"> </span><span class="er">~</span>x<span class="op">+</span>y
<span class="kw">proj4string</span>(pt1) =<span class="st"> </span><span class="kw">proj4string</span>(meuse.grid)
pt1.om &lt;-<span class="st"> </span><span class="kw">over</span>(pt1, om.rk<span class="op">@</span>predicted[<span class="st">&quot;om&quot;</span>])
pt1.om.sd &lt;-<span class="st"> </span><span class="kw">over</span>(pt1, om.rk<span class="op">@</span>predicted[<span class="st">&quot;var1.var&quot;</span>])
<span class="kw">signif</span>(<span class="kw">expm1</span>(pt1.om<span class="op">-</span><span class="fl">1.645</span><span class="op">*</span><span class="kw">sqrt</span>(pt1.om.sd)), <span class="dv">2</span>)
<span class="co">#&gt;    om</span>
<span class="co">#&gt; 1 4.6</span>
<span class="kw">signif</span>(<span class="kw">expm1</span>(pt1.om<span class="op">+</span><span class="fl">1.645</span><span class="op">*</span><span class="kw">sqrt</span>(pt1.om.sd)), <span class="dv">2</span>)
<span class="co">#&gt;    om</span>
<span class="co">#&gt; 1 8.9</span></code></pre></div>
<p>where 4.6–8.9 are the upper and lower confidence limits. This interval can also be expressed as:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">signif</span>((<span class="kw">expm1</span>(pt1.om<span class="op">+</span><span class="fl">1.645</span><span class="op">*</span><span class="kw">sqrt</span>(pt1.om.sd)) <span class="op">-</span>
<span class="st">       </span><span class="kw">expm1</span>(pt1.om<span class="op">-</span><span class="fl">1.645</span><span class="op">*</span><span class="kw">sqrt</span>(pt1.om.sd)))<span class="op">/</span><span class="dv">2</span>, <span class="dv">2</span>)
<span class="co">#&gt;    om</span>
<span class="co">#&gt; 1 2.1</span></code></pre></div>
<p>or <span class="math inline">\(6.3\pm 2.1\)</span> where half the error of estimating organic matter at that location is about 1 s.d. Note that these are location specific prediction intervals and need to be computed for each location.</p>
<p>To visualize the range of values within different strata, we can use simulations that we can generate using the geostatistical model (which can be time-consuming to compute!):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">om.rksim &lt;-<span class="st"> </span><span class="kw">predict</span>(omm, meuse.grid, <span class="dt">nsim=</span><span class="dv">5</span>)
<span class="co">#&gt; Subsetting observations to fit the prediction domain in 2D...</span>
<span class="co">#&gt; Generating 5 conditional simulations using the trend model (RK method)...</span>
<span class="co">#&gt; drawing 5 GLS realisations of beta...</span>
<span class="co">#&gt; [using conditional Gaussian simulation]</span>
<span class="co">#&gt; </span>
  <span class="dv">0</span>% done
 <span class="dv">12</span>% done
 <span class="dv">20</span>% done
 <span class="dv">27</span>% done
 <span class="dv">33</span>% done
 <span class="dv">39</span>% done
 <span class="dv">46</span>% done
 <span class="dv">51</span>% done
 <span class="dv">57</span>% done
 <span class="dv">63</span>% done
 <span class="dv">69</span>% done
 <span class="dv">74</span>% done
 <span class="dv">80</span>% done
 <span class="dv">85</span>% done
 <span class="dv">91</span>% done
 <span class="dv">97</span>% done
<span class="dv">100</span>% done
<span class="co">#&gt; Creating an object of class &quot;RasterBrickSimulations&quot;</span>
ov &lt;-<span class="st"> </span><span class="kw">as</span>(om.rksim<span class="op">@</span>realizations, <span class="st">&quot;SpatialGridDataFrame&quot;</span>)
meuse.grid<span class="op">$</span>om.sim1 &lt;-<span class="st"> </span><span class="kw">expm1</span>(ov<span class="op">@</span>data[,<span class="dv">1</span>][meuse.grid<span class="op">@</span>grid.index])
meuse.grid<span class="op">$</span>om.rk &lt;-<span class="st"> </span><span class="kw">expm1</span>(om.rk<span class="op">@</span>predicted<span class="op">$</span>om)
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">boxplot</span>(om<span class="op">~</span>ffreq, omm<span class="op">@</span>regModel<span class="op">$</span>data, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>,
    <span class="dt">xlab=</span><span class="st">&quot;Flooding frequency classes&quot;</span>,
    <span class="dt">ylab=</span><span class="st">&quot;Organic matter in %&quot;</span>,
    <span class="dt">main=</span><span class="st">&quot;Sampled (N = 153)&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>))
<span class="kw">boxplot</span>(om.sim1<span class="op">~</span>ffreq, meuse.grid, <span class="dt">col=</span><span class="st">&quot;grey&quot;</span>,
    <span class="dt">xlab=</span><span class="st">&quot;Flooding frequency classes&quot;</span>,
    <span class="dt">ylab=</span><span class="st">&quot;Organic matter in %&quot;</span>,
    <span class="dt">main=</span><span class="st">&quot;Predicted (spatial simulations)&quot;</span>, <span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>))</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:confidence-limits-boxplot"></span>
<img src="Statistical_theory_files/figure-html/confidence-limits-boxplot-1.png" alt="Prediction intervals for three flooding frequency classes for sampled and predicted soil organic matter. The grey boxes show 1st and 3rd quantiles i.e. range where of data falls." width="90%" />
<p class="caption">
Figure 5.24: Prediction intervals for three flooding frequency classes for sampled and predicted soil organic matter. The grey boxes show 1st and 3rd quantiles i.e. range where of data falls.
</p>
</div>
<p>Fig. <a href="statistical-theory.html#fig:confidence-limits-boxplot">5.24</a> shows that the confidence limits for samples and based on the geostatistical model are about the same width (grey boxes in the plot showing 1st and 3rd quantile), which should be the case because geostatistical simulations are supposed maintain the original variances (see also Fig. <a href="statistical-theory.html#fig:hist-om-predicted-simulated">5.15</a>).</p>
<p>What is also often of interest to soil information users is the error of estimating the mean value i.e. <em>standard error of the mean</em> (<span class="math inline">\({\rm{SE}}_{\bar{x}}\)</span>), which can be derived using samples only <span class="citation">(Kutner et al. <a href="references.html#ref-kutner2005applied">2005</a>)</span>:</p>
<span class="math display" id="eq:mean-pop">\[\begin{equation}
{\rm{SE}}_{\bar{x}} = \frac{\sigma_x}{\sqrt{n-1}}
\tag{5.30}
\end{equation}\]</span>
<p>or in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sd.om &lt;-<span class="st"> </span><span class="kw">qt</span>(<span class="fl">0.975</span>, <span class="dt">df=</span><span class="kw">length</span>(meuse<span class="op">$</span>om)<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span>
<span class="st">    </span><span class="kw">sd</span>(meuse<span class="op">$</span>om, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)<span class="op">/</span><span class="kw">sqrt</span>(<span class="kw">length</span>(meuse<span class="op">$</span>om))
sd.om
<span class="co">#&gt; [1] 0.54</span></code></pre></div>
<p>Note that this is (only) error of estimating the population mean, which is way narrower than the actual variation inside the units. This number does not mean that we can estimate organic matter at any location with precision of <span class="math inline">\(\pm0.54\)</span>! This number means that, if we would like to estimate (aggregated) mean value for the whole population then the standard error of that mean would be <span class="math inline">\(\pm0.54\)</span>. In other words the population mean for organic matter based on 153 samples is <span class="math inline">\(7.48\pm 0.54\)</span>, but if we would know the values of organic matter at individual locations, then the confidence limits are about <span class="math inline">\(7.48\pm 3.4\)</span> (where 3.4 is the standard error).</p>
<p>The actual variation within the units based on simulations is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">lapply</span>(<span class="kw">levels</span>(meuse.grid<span class="op">$</span>ffreq), <span class="cf">function</span>(x){
    <span class="kw">sapply</span>(<span class="kw">subset</span>(meuse.grid<span class="op">@</span>data, ffreq<span class="op">==</span>x,
           <span class="dt">select=</span>om.sim1), sd, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
})
<span class="co">#&gt; [[1]]</span>
<span class="co">#&gt; om.sim1 </span>
<span class="co">#&gt;       3 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[2]]</span>
<span class="co">#&gt; om.sim1 </span>
<span class="co">#&gt;     2.7 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; [[3]]</span>
<span class="co">#&gt; om.sim1 </span>
<span class="co">#&gt;     1.7</span></code></pre></div>
<p>This can be confusing especially if the soil data producer does not clearly report if the confidence limits refer to the population mean, or to individual values. In principle, most users are interested in what are the confidence limits of measuring some value at individual location, which are always few times wider than confidence limits of estimating the population mean.</p>
<p>Assessment of the confidence limits should be best considered as a regression problem in fact. It can be easily shown that, by fitting a regression model on strata, we automatically get an estimate of confidence limits for the study area:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">omm0 &lt;-<span class="st"> </span><span class="kw">lm</span>(om<span class="op">~</span>ffreq<span class="op">-</span><span class="dv">1</span>, omm<span class="op">@</span>regModel<span class="op">$</span>data)
om.r &lt;-<span class="st"> </span><span class="kw">predict</span>(omm0, meuse.grid, <span class="dt">se.fit=</span><span class="ot">TRUE</span>)
meuse.grid<span class="op">$</span>se.fit &lt;-<span class="st"> </span>om.r<span class="op">$</span>se.fit
<span class="kw">signif</span>(<span class="kw">mean</span>(meuse.grid<span class="op">$</span>se.fit, <span class="dt">na.rm=</span><span class="ot">TRUE</span>), <span class="dv">3</span>)
<span class="co">#&gt; [1] 0.48</span></code></pre></div>
<p>This number is similar to 0.54 we derived directly from simulations. The difference in the values is because the regression model estimates the prediction intervals for the whole study area based on the covariate data (and not only for the sampling locations). The value is also different than previously derived 0.54 because we use <code>ffreq</code> stratification as a covariate, so that, as long as the strata is relatively homogenous, the confidence limits get narrower.</p>
<div class="rmdnote">
<p>
Prediction intervals (upper and lower ranges of expected values with some high probability) are possibly the most accepted way to communicate uncertainty. Users are commonly interested in what are the probability confidence limits of measuring some value at individual location, or the high probability prediction range.
</p>
</div>
<p>To estimate the actual prediction intervals of estimating individual values (estimation error) we need to add the residual scale value which is a constant number:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>(<span class="kw">sqrt</span>(meuse.grid<span class="op">$</span>se.fit<span class="op">^</span><span class="dv">2</span><span class="op">+</span>om.r<span class="op">$</span>residual.scale<span class="op">^</span><span class="dv">2</span>),
     <span class="dt">by=</span><span class="kw">list</span>(meuse.grid<span class="op">$</span>ffreq), mean, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
<span class="co">#&gt;   Group.1   x</span>
<span class="co">#&gt; 1       1 3.3</span>
<span class="co">#&gt; 2       2 3.3</span>
<span class="co">#&gt; 3       3 3.3</span></code></pre></div>
<p>and if we compare these limits to the confidence bands for the values predicted the geostatistical model fitted above:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">aggregate</span>(meuse.grid<span class="op">$</span>om.sim1, <span class="dt">by=</span><span class="kw">list</span>(meuse.grid<span class="op">$</span>ffreq), sd, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
<span class="co">#&gt;   Group.1   x</span>
<span class="co">#&gt; 1       1 3.0</span>
<span class="co">#&gt; 2       2 2.7</span>
<span class="co">#&gt; 3       3 1.7</span></code></pre></div>
<p>we can clearly see that the geostatistical model has helped us narrow down the confidence limits, especially for class <code>3</code>.</p>
</div>
<div id="universal-measures-of-mapping-accuracy" class="section level3">
<h3><span class="header-section-number">5.3.6</span> Universal measures of mapping accuracy</h3>
<p>In previous examples we have seen that mapping accuracy can be determined by running cross-validation and determining e.g. <span class="math inline">\(\it{RMSE}\)</span> and R-square. In addition to R–square, a more universal measure of prediction success is the Lin’s Concordance Correlation Coefficient (CCC) <span class="citation">(Steichen and Cox <a href="references.html#ref-steichen2002note">2002</a>)</span>:</p>
<span class="math display" id="eq:CCC">\[\begin{equation}
\rho_c = \frac{2 \cdot \rho \cdot \sigma_{\hat y} \cdot \sigma_y }{ \sigma_{\hat y}^2 + \sigma_y^2 + (\mu_{\hat y} - \mu_y)^2}
\tag{5.31}
\end{equation}\]</span>
<p>where <span class="math inline">\(\hat y\)</span> are the predicted values and <span class="math inline">\(y\)</span> are actual values at cross-validation points, <span class="math inline">\(\mu_{\hat y}\)</span> and <span class="math inline">\(\mu_y\)</span> are predicted and observed means and <span class="math inline">\(\rho\)</span> is the correlation coefficient between predicted and observed values. CCC correctly quantifies how far the observed data deviate from the line of perfect concordance (1:1 line in Fig. <a href="statistical-theory.html#fig:validation-scheme">5.25</a>). It is usually equal to or somewhat lower than R–square, depending on the amount of bias in predictions.</p>
<div class="figure" style="text-align: center"><span id="fig:validation-scheme"></span>
<img src="figures/Fig_validation_plots.png" alt="Universal plots of predictive performance: (a) 1:1 predicted vs observed plot, (b) CCC vs standard deviation of the z-scores plot, (c) nominal vs coverage probabilities, and (d) variogram of cross-validation residuals. For more detail see: @Hengl2018RFsp." width="80%" />
<p class="caption">
Figure 5.25: Universal plots of predictive performance: (a) 1:1 predicted vs observed plot, (b) CCC vs standard deviation of the z-scores plot, (c) nominal vs coverage probabilities, and (d) variogram of cross-validation residuals. For more detail see: <span class="citation">Hengl et al. (<a href="references.html#ref-Hengl2018RFsp">2018</a>)</span>.
</p>
</div>
<p>CCC and variance or standard deviation of the z-scores are two universal / scale-free parameters that can be used to put multiple spatial prediction algorithms working on multiple soil variables. Two additional measures of the predictive performance of a mapping algoritm are the spatial dependence structure in the cross-validation residuals and so called <em>“accuracy plots”</em> i.e. <span class="citation">(Goovaerts <a href="references.html#ref-goovaerts1999geostatistics">1999</a>)</span> (Fig. <a href="statistical-theory.html#fig:validation-scheme">5.25</a>). Ideally, variogram of residuals should show no spatial dependence (i.e. pure nugget effect), which is a proof that there is no spatial bias in predictions. Likewise, nominal vs coverage probabilities in the target variable should also ideally be on a 1:1 line.</p>
<p>So in summary, four universal measures to access predicitive success of any spatial prediction method are <span class="citation">(Hengl et al. <a href="references.html#ref-Hengl2018RFsp">2018</a>)</span>:</p>
<ul>
<li><strong>Concordance Correlation Coefficient</strong> (0–1): showing predictive success of a method on a 1:1 predictions vs observations plot,</li>
<li><strong>Variance of the z-scores</strong> (0–<span class="math inline">\(\infty\)</span>): showing how reliable is the modeled estimate of the prediction errors,</li>
<li><strong>Variogram of the cross-validation residuals</strong>: showing whether residuals still contain spatial dependence structure,</li>
<li><strong>Accuracy plots</strong>: showing whether the model over- or under-estimates either lower or higher values,</li>
</ul>
</div>
<div id="mapping-accuracy-and-soil-survey-costs" class="section level3">
<h3><span class="header-section-number">5.3.7</span> Mapping accuracy and soil survey costs</h3>
<p>Once the accuracy of some model have been assessed, the next measure of the mapping success of interest is the soil information production costs. Undoubtedly, producing soil information costs money. <span class="citation">Burrough, Beckett, and Jarvis (<a href="references.html#ref-Burrough1971">1971</a>)</span>, <span class="citation">Bie and Ulph (<a href="references.html#ref-BieUlph1972JAE">1972</a>)</span>, and <span class="citation">Bie, Uph, and Beckett (<a href="references.html#ref-Bie1973JSS">1973</a>)</span> postulated in the early 70s that the survey costs are a direct function of the mapping scale:</p>
<span class="math display" id="eq:burrough">\[\begin{equation}
\log \begin{Bmatrix}
{\rm cost} \; {\rm per} \; {\rm km}^2\\
{\rm or}\\
{\rm man-days} \; {\rm per} \; {\rm km}^2
\end{Bmatrix}
= a + b \cdot \log( {\rm map} \; {\rm scale} )
\tag{5.32}
\end{equation}\]</span>
<p>To produce soil information costs money. On the other hand soil information, if used properly, can lead to significant financial benefits: accurate soil information is a key to good decision making, increased crop and livestock production, it helps reducing investments risk and planning environmental conservation.</p>
<p>This model typically explains <span class="math inline">\(&gt;75\)</span>% of the survey costs <span class="citation">(Burrough, Beckett, and Jarvis <a href="references.html#ref-Burrough1971">1971</a>)</span>. Further more, for the given target scale, <em>standard soil survey costs</em> can be commonly expressed as:</p>
<span class="math display" id="eq:mappingcosts">\[\begin{equation}
\theta  = \frac{{\rm X}}{A} \qquad [{\rm USD} \; {\rm km}^{-2} ]
\tag{5.33}
\end{equation}\]</span>
<p>where <span class="math inline">\({\rm X}\)</span> is the total costs of a survey, <span class="math inline">\(A\)</span> is the size of area in km-square. So for example, according to <span class="citation">Legros (<a href="references.html#ref-Legros2006SP">2006</a>, 75)</span>, to map 1 hectare of soil at 1:200,000 scale (at the beginning of the 21st century), one needs at least 0.48 Euros (i.e. 48 EUR to map a square-km); to map soil at 1:20 would costs about 25 EUR per ha. These are the all-inclusive costs that include salaries and time in the office needed for the work of synthesis and editing.</p>
<div class="figure" style="text-align: center"><span id="fig:scale-costs-ratio"></span>
<img src="figures/Fig_scale_costs_ratio.png" alt="Some basic concepts of soil survey: (a) relationship between cartographic scale and pixel size [@Hengl2006CG], (b) soil survey costs and scale relationship based on the empirical data of @Legros2006SP." width="100%" />
<p class="caption">
Figure 5.26: Some basic concepts of soil survey: (a) relationship between cartographic scale and pixel size <span class="citation">(Hengl <a href="references.html#ref-Hengl2006CG">2006</a>)</span>, (b) soil survey costs and scale relationship based on the empirical data of <span class="citation">Legros (<a href="references.html#ref-Legros2006SP">2006</a>)</span>.
</p>
</div>
<p>Estimated standard soil survey costs per area differ from country to country. The USDA estimates that the total costs of soil mapping at their most detailed scale (1:20) costs about 1.50 USD per acre i.e. about 4 USD per ha <span class="citation">(Durana <a href="references.html#ref-eltit2008">2008</a>)</span>; in Canada, typical costs of producing soil maps at 1:20 are in the range 3–10 CAD per ha <span class="citation">(MacMillan et al. <a href="references.html#ref-MacMillan2010DSM">2010</a>)</span>; in the Netherlands 3.4 EUR per ha <span class="citation">(Kempen <a href="references.html#ref-Kempen2011PhDthesis">2011</a>, 149–54)</span>; in New Zealand 4 USD per ha <span class="citation">(Carrick, Vesely, and Hewitt <a href="references.html#ref-Carrick2010WCSS">2010</a>)</span>. Based on these national-level numbers, <span class="citation">Hengl, Nikolić, and MacMillan (<a href="references.html#ref-Hengl2013JAG">2013</a>)</span> have tried to produce a global estimate of soil survey costs. So for example, to map 1 hectare of land at 1:20 scale, one would need (at least) 5 USD, and to map soil at 1:200,000 scale globally would cost about 8 USD per square-kilometer using conventional soil mapping methods.</p>
<p>The scale of 1:200 approximately corresponds to a ground resolution of 100 m (Fig. <a href="statistical-theory.html#fig:scale-costs-ratio">5.26</a>). If we would like to open a call to map the world soils (assuming that total land area to map is about 104 millions of square-km) using contemporary methods at 100 m resolution, and if we would consider 8 USD per square-kilometer as a reasonable cost, then the total costs of mapping the total productive soil areas of the world would be about 872 million USD. Of course, many countries in the world have already been mapped at scale of 1:200 or better, so this number could be reduced by at least 30%, but even then we would still need a respectable budget. This just illustrate that soil mapping can costs an order of magnitude more than, for example, land cover mapping.</p>
<p>Producing soil information costs money, but it also leads to financial benefits. <span class="citation">Pimentel (<a href="references.html#ref-Pimentel2006Springer">2006</a>)</span> for example shows that the costs of soil erosion, measured just by the cost of replacing lost water and nutrients, is of the order of 250 billion USD annually. Soil information, if used properly, can also lead to increased crop and livestock production. <span class="citation">Carrick, Vesely, and Hewitt (<a href="references.html#ref-Carrick2010WCSS">2010</a>)</span>, for example, show that soil survey that costs (only) 3.99 USD per hectare, can lead to better management practices that help retain nitrogen in soil at rate 42.49 USD per kg (17.30 USD per kg for farmers, 25.19 USD per kg for the community). This also demonstrates that soil mapping can be a profitable business.</p>
<p>The formula in Eq. <a href="statistical-theory.html#eq:mappingcosts">(5.33)</a> is somewhat incomplete as it tells us only about the cost of mapping per unit area. Obviously, mapping efficiency has to be expressed within the context of the mapping objective. Hence, a more informative measure of <em>mapping efficiency</em> is <span class="citation">(Hengl, Nikolić, and MacMillan <a href="references.html#ref-Hengl2013JAG">2013</a>)</span>:</p>
<span class="math display" id="eq:efficiency">\[\begin{equation}
\theta  = \frac{{\rm X}}{{A \cdot {\Sigma}_{\%}}} \qquad [{\rm USD} \; {\rm km}^{-2} \; \%^{-1} ]
\tag{5.34}
\end{equation}\]</span>
<p>where <span class="math inline">\({\Sigma}_{\%}\)</span> is the amount of variation explained by the spatial prediction model (Eq. <a href="statistical-theory.html#eq:normvar">(5.28)</a>). In other words, soil mapping efficiency is total cost of explaining each percent of variation in target soil variables for a given area of interest.</p>
<div class="figure" style="text-align: center"><span id="fig:costs-RMSE-scheme"></span>
<img src="figures/Fig_costs_RMSE_scheme.png" alt="General relationship between the sampling intensity (i.e. survey costs) and amount of variation in the target variable explained by a spatial prediction model. After @Hengl2013JAG." width="80%" />
<p class="caption">
Figure 5.27: General relationship between the sampling intensity (i.e. survey costs) and amount of variation in the target variable explained by a spatial prediction model. After <span class="citation">Hengl, Nikolić, and MacMillan (<a href="references.html#ref-Hengl2013JAG">2013</a>)</span>.
</p>
</div>
<p>Even more universal measure of mapping efficiency is the Information Production Efficiency (IPE):</p>
<span class="math display" id="eq:data-efficiency">\[\begin{equation}
\Upsilon = \frac{{\rm X}}{{\rm gzip}} \qquad [{\rm EUR} \; {\rm B}^{-1}]
\tag{5.35}
\end{equation}\]</span>
<p>where <span class="math inline">\({\rm gzip}\)</span> is the size of data (in Bytes) left after compression and after recoding the values to match the effective precision (<span class="math inline">\(\delta \approx {\rm RMSE}/2\)</span>). Information Production Efficiency is scale independent as the area is not included in the equation and hence can be used to compare efficiency of various soil mapping projects.</p>
<div class="rmdnote">
<p>
Soil mapping efficiency can be expressed as the cost of producing bytes of information about the target soil variables for a given area of interest. This allows for an objective comparison of prediction efficiency for different soil variables for different study areas.
</p>
</div>
</div>
<div id="summary-points-2" class="section level3">
<h3><span class="header-section-number">5.3.8</span> Summary points</h3>
<p>Soil mapping processes are also increasingly automated, which is mainly due to advances in software for statistical computing and growing processing speed and computing capacity. Fully automated geostatistical mapping, i.e. generation of spatial predictions with little to no human interaction, is today a growing field of geoinformation science <span class="citation">(Pebesma et al. <a href="references.html#ref-Pebesma2011CompGeoSci">2011</a>; Brown <a href="references.html#ref-Brown2014JSS">2015</a>; Hengl <a href="references.html#ref-Hengl2014SoilGrids1km">2014</a>)</span>. Some key advantages of using automated soil mapping versus more conventional, traditional expert-based soil mapping are <span class="citation">(Heuvelink et al. <a href="references.html#ref-heuvelink2010implications">2010</a>; Bivand, Pebesma, and Rubio <a href="references.html#ref-Bivand2013Springer">2013</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>All rules required to produce outputs are formalized. The whole procedure is documented (the statistical model and associated computer script), enabling reproducible research.</p></li>
<li><p>Predicted surfaces can make use of various information sources and can be optimized relative to all available quantitative point and covariate data.</p></li>
<li><p>There is more flexibility in terms of the spatial extent, resolution and support of requested maps.</p></li>
<li><p>Automated mapping is more cost-effective: once the system is operational, maintenance and production of updates are an order of magnitude faster and cheaper. Consequently, prediction maps can be updated and improved at shorter and shorter time intervals.</p></li>
<li><p>Spatial prediction models typically provide quantitative measures of prediction uncertainty (for each prediction location), which are often not provided in the case of conventional soil mapping.</p></li>
</ol>
<p>A disadvantage of automated soil mapping is that many statistical and machine learning techniques are sensitive to errors and inconsistencies in input data. A few typos, misaligned spatial coordinates or misspecified models can create serious artifacts and reduce prediction accuracy, more so than with traditional methods. Also, fitting models using large and complex data sets can be time consuming and selection of the <em>‘best’</em> model is often problematic. Explicit incorporation of conceptual pedological (expert) knowledge, which can be important for prediction in new situations to address the above issues, can be challenging as well.</p>
<p>In contemporary soil mapping, traditional concepts such as soil map scale and size of delineations are becoming increasingly dated or secondary. The focus of contemporary soil mapping is on minimizing costs required to explain variation in the target variable, while support size of the output maps can be set by the user. The amount of variation explained by a given statistical model gradually increases with sampling intensity, until it reaches some physical limit and does not improve any more. The short-range variability and measurement error, e.g. the portion of the variation that cannot be captured or expressed by the model, for many soil variables is in the range 10–40% (Fig. <a href="statistical-theory.html#fig:costs-RMSE-scheme">5.27</a>). A useful thing for soil mapping teams is to compare a list of valid competing models and plot the differences for comparison studies using what we call <em>“predictograms”</em> (as illustrated in Fig. <a href="statistical-theory.html#fig:cost-methods-scheme">5.28</a>). Such comparison studies allow us to determine the best performing, and most cost effective, pedometric method for an area of interest and a list of target variables.</p>
<div class="figure" style="text-align: center"><span id="fig:cost-methods-scheme"></span>
<img src="figures/Fig_costs_RMSE_scheme-2.png" alt="An schematic example of a performance plot (*‘predictogram’*) for comparing spatial prediction models. For more details see: @Hengl2013JAG." width="80%" />
<p class="caption">
Figure 5.28: An schematic example of a performance plot (<em>‘predictogram’</em>) for comparing spatial prediction models. For more details see: <span class="citation">Hengl, Nikolić, and MacMillan (<a href="references.html#ref-Hengl2013JAG">2013</a>)</span>.
</p>
</div>
<p>In summary, gauging the success of soil mapping basically boils down to the amount of variation explained by the spatial prediction model i.e. quantity of effective bytes produced for the data users. The survey costs are mainly a function of sampling intensity i.e. field work and laboratory data analysis. As we collect more samples for an area of interest we explain more and more of the total variance, until we reach some maximum feasible <em>locked</em> variation (Fig. <a href="statistical-theory.html#fig:cost-methods-scheme">5.28</a>). For a given total budget and a list of target variables an optimal (most efficient) prediction method can be determined by deriving the mapping efficiency described in Eq. <a href="statistical-theory.html#eq:efficiency">(5.34)</a> or even better Eq. <a href="statistical-theory.html#eq:data-efficiency">(5.35)</a>.</p>
<div class="rmdnote">
<p>
Modern soil mapping is driven by the objective assessment of accuracy — emphasis is put on using methods and covariate layers that can produce the most accurate soil information given available resources, and much less on expert opinion or preference.
</p>
</div>
<p>By reporting on the RMSE, effective precision, information production efficiency, and by plotting the prediction variance estimated by the model, one gets a fairly good idea about the overall added information value in a given map. In order words, by assessing the accuracy of a map we can recommend both: ways to improve the predictions (i.e. collect additional samples), and estimate the resources needed to reach some target accuracy. By assessing how the accuracy of various methods changes for various sampling intensities (Fig. <a href="statistical-theory.html#fig:cost-methods-scheme">5.28</a>), we can distinguish between methods that are more suited for particular regions, data sets or sizes of area and optimum methods that outperform all alternatives.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="soil-covs-chapter.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="soilmapping-using-mla.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/envirometrix/PredictiveSoilMapping/edit/master/Statistical_theory.Rmd",
"text": "Edit"
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
