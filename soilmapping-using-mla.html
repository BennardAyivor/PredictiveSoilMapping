<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>6 Machine Learning Algorithms for soil mapping | Predictive Soil Mapping with R</title>
  <meta name="description" content="Predictive Soil Mapping aims to produce the most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement common soil mapping procedures within the R programming language.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="6 Machine Learning Algorithms for soil mapping | Predictive Soil Mapping with R />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="http://soilmapper.org" />
  <meta property="og:image" content="http://soilmapper.orgfigures/f0_web.png" />
  <meta property="og:description" content="Predictive Soil Mapping aims to produce the most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement common soil mapping procedures within the R programming language." />
  <meta name="github-repo" content="envirometrix/PredictiveSoilMapping" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Machine Learning Algorithms for soil mapping | Predictive Soil Mapping with R />
  <meta name="twitter:site" content="@tom_hengl" />
  <meta name="twitter:description" content="Predictive Soil Mapping aims to produce the most accurate, most objective, and most usable maps of soil variables by using state-of-the-art Statistical and Machine Learning methods. This books explains how to implement common soil mapping procedures within the R programming language." />
  <meta name="twitter:image" content="http://soilmapper.orgfigures/f0_web.png" />

<meta name="author" content="Tomislav Hengl and Robert A. MacMillan">


<meta name="date" content="2018-12-20">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="statistical-theory.html">
<link rel="next" href="SOC-chapter.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-120633517-1', 'auto');
  ga('send', 'pageview');

</script>

<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Predictive Soil Mapping with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Predictive Soil Mapping for advanced R users</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#editors"><i class="fa fa-check"></i>Editors</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#connected-publications"><i class="fa fa-check"></i>Connected publications</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#contributions"><i class="fa fa-check"></i>Contributions</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#reproducibility"><i class="fa fa-check"></i>Reproducibility</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Soil resource inventories and soil maps</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#introduction-1"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#soils-and-soil-inventories"><i class="fa fa-check"></i><b>1.2</b> Soils and soil inventories</a><ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#soil-a-definition"><i class="fa fa-check"></i><b>1.2.1</b> Soil: a definition</a></li>
<li class="chapter" data-level="1.2.2" data-path="introduction.html"><a href="introduction.html#soil-variables"><i class="fa fa-check"></i><b>1.2.2</b> Soil variables</a></li>
<li class="chapter" data-level="1.2.3" data-path="introduction.html"><a href="introduction.html#primary-and-secondary-soil-variables"><i class="fa fa-check"></i><b>1.2.3</b> Primary and secondary soil variables</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#soil-mapping"><i class="fa fa-check"></i><b>1.3</b> Soil mapping</a><ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#what-are-soil-resource-inventories"><i class="fa fa-check"></i><b>1.3.1</b> What are soil resource inventories?</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#soil-mapping-approaches-and-concepts"><i class="fa fa-check"></i><b>1.3.2</b> Soil mapping approaches and concepts</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#soil-mapping-theory"><i class="fa fa-check"></i><b>1.3.3</b> Theoretical basis of soil mapping: in context of the universal model of spatial variation</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#conventional-mapping"><i class="fa fa-check"></i><b>1.3.4</b> Traditional (conventional) soil mapping</a></li>
<li class="chapter" data-level="1.3.5" data-path="introduction.html"><a href="introduction.html#variants-of-soil-maps"><i class="fa fa-check"></i><b>1.3.5</b> Variants of soil maps</a></li>
<li class="chapter" data-level="1.3.6" data-path="introduction.html"><a href="introduction.html#pedometric-mapping"><i class="fa fa-check"></i><b>1.3.6</b> Predictive and automated soil mapping</a></li>
<li class="chapter" data-level="1.3.7" data-path="introduction.html"><a href="introduction.html#comparison-conventional-pm"><i class="fa fa-check"></i><b>1.3.7</b> Comparison of conventional and pedometric or predictive soil mapping</a></li>
<li class="chapter" data-level="1.3.8" data-path="introduction.html"><a href="introduction.html#top-down"><i class="fa fa-check"></i><b>1.3.8</b> Top-down versus bottom-up approaches: subdivision versus agglomeration</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#sources-of-soil-data-for-soil-mapping"><i class="fa fa-check"></i><b>1.4</b> Sources of soil data for soil mapping</a><ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#soil-data-sources-targeted-by-psm"><i class="fa fa-check"></i><b>1.4.1</b> Soil data sources targeted by PSM</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#field-observations"><i class="fa fa-check"></i><b>1.4.2</b> Field observations of soil properties</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#legacy-soil-profile-data"><i class="fa fa-check"></i><b>1.4.3</b> Legacy soil profile data</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#soil-covariates"><i class="fa fa-check"></i><b>1.4.4</b> Soil covariates</a></li>
<li class="chapter" data-level="1.4.5" data-path="introduction.html"><a href="introduction.html#soil-delineations"><i class="fa fa-check"></i><b>1.4.5</b> Soil delineations</a></li>
<li class="chapter" data-level="1.4.6" data-path="introduction.html"><a href="introduction.html#advantages-and-disadvantages-of-using-soil-delineations"><i class="fa fa-check"></i><b>1.4.6</b> Advantages and disadvantages of using soil delineations</a></li>
<li class="chapter" data-level="1.4.7" data-path="introduction.html"><a href="introduction.html#accuracy-of-conventional-soil-polygon-maps"><i class="fa fa-check"></i><b>1.4.7</b> Accuracy of conventional soil polygon maps</a></li>
<li class="chapter" data-level="1.4.8" data-path="introduction.html"><a href="introduction.html#tacit-knowledge"><i class="fa fa-check"></i><b>1.4.8</b> Legacy soil expertise (tacit knowledge)</a></li>
<li class="chapter" data-level="1.4.9" data-path="introduction.html"><a href="introduction.html#pseudo-observations"><i class="fa fa-check"></i><b>1.4.9</b> Pseudo-observations</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#soil-databases"><i class="fa fa-check"></i><b>1.5</b> Soil databases and soil information systems</a><ul>
<li class="chapter" data-level="1.5.1" data-path="introduction.html"><a href="introduction.html#soil-databases-1"><i class="fa fa-check"></i><b>1.5.1</b> Soil databases</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction.html"><a href="introduction.html#a-soil-information-system"><i class="fa fa-check"></i><b>1.5.2</b> A Soil Information System</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction.html"><a href="introduction.html#soil-information-users"><i class="fa fa-check"></i><b>1.5.3</b> Soil information users</a></li>
<li class="chapter" data-level="1.5.4" data-path="introduction.html"><a href="introduction.html#usability-of-soil-geographical-database"><i class="fa fa-check"></i><b>1.5.4</b> Usability of soil geographical database</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#uncertainty-soil-variables"><i class="fa fa-check"></i><b>1.6</b> Uncertainty of soil variables</a><ul>
<li class="chapter" data-level="1.6.1" data-path="introduction.html"><a href="introduction.html#basic-concepts"><i class="fa fa-check"></i><b>1.6.1</b> Basic concepts</a></li>
<li class="chapter" data-level="1.6.2" data-path="introduction.html"><a href="introduction.html#sources-uncertainty"><i class="fa fa-check"></i><b>1.6.2</b> Sources of uncertainty</a></li>
<li class="chapter" data-level="1.6.3" data-path="introduction.html"><a href="introduction.html#quantifying-the-uncertainty-in-soil-data-products"><i class="fa fa-check"></i><b>1.6.3</b> Quantifying the uncertainty in soil data products</a></li>
<li class="chapter" data-level="1.6.4" data-path="introduction.html"><a href="introduction.html#common-uncertainty-levels-in-soil-maps"><i class="fa fa-check"></i><b>1.6.4</b> Common uncertainty levels in soil maps</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#summary-and-conclusions"><i class="fa fa-check"></i><b>1.7</b> Summary and conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="software.html"><a href="software.html"><i class="fa fa-check"></i><b>2</b> Software installation and first steps</a><ul>
<li class="chapter" data-level="2.1" data-path="software.html"><a href="software.html#list-of-software-in-use"><i class="fa fa-check"></i><b>2.1</b> List of software in use</a></li>
<li class="chapter" data-level="2.2" data-path="software.html"><a href="software.html#installing-software-on-ubuntu-os"><i class="fa fa-check"></i><b>2.2</b> Installing software on Ubuntu OS</a></li>
<li class="chapter" data-level="2.3" data-path="software.html"><a href="software.html#installing-gis-software"><i class="fa fa-check"></i><b>2.3</b> Installing GIS software</a></li>
<li class="chapter" data-level="2.4" data-path="software.html"><a href="software.html#Whitebox"><i class="fa fa-check"></i><b>2.4</b> WhiteboxTools</a></li>
<li class="chapter" data-level="2.5" data-path="software.html"><a href="software.html#Rstudio"><i class="fa fa-check"></i><b>2.5</b> RStudio</a></li>
<li class="chapter" data-level="2.6" data-path="software.html"><a href="software.html#plotkml-and-gsif-packages"><i class="fa fa-check"></i><b>2.6</b> plotKML and GSIF packages</a></li>
<li class="chapter" data-level="2.7" data-path="software.html"><a href="software.html#connecting-r-and-saga-gis"><i class="fa fa-check"></i><b>2.7</b> Connecting R and SAGA GIS</a></li>
<li class="chapter" data-level="2.8" data-path="software.html"><a href="software.html#connecting-r-and-gdal"><i class="fa fa-check"></i><b>2.8</b> Connecting R and GDAL</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html"><i class="fa fa-check"></i><b>3</b> Soil observations and variables</a><ul>
<li class="chapter" data-level="3.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#basic-concepts-1"><i class="fa fa-check"></i><b>3.1</b> Basic concepts</a><ul>
<li class="chapter" data-level="3.1.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#types-of-soil-observations"><i class="fa fa-check"></i><b>3.1.1</b> Types of soil observations</a></li>
<li class="chapter" data-level="3.1.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-properties-of-interest-for-global-soil-mapping"><i class="fa fa-check"></i><b>3.1.2</b> Soil properties of interest for global soil mapping</a></li>
<li class="chapter" data-level="3.1.3" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#reference-methods"><i class="fa fa-check"></i><b>3.1.3</b> Reference methods</a></li>
<li class="chapter" data-level="3.1.4" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#standard-soil-variables-of-interest-for-soil-mapping"><i class="fa fa-check"></i><b>3.1.4</b> Standard soil variables of interest for soil mapping</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#descriptive-soil-profile-observations"><i class="fa fa-check"></i><b>3.2</b> Descriptive soil profile observations</a><ul>
<li class="chapter" data-level="3.2.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#depth-to-bedrock"><i class="fa fa-check"></i><b>3.2.1</b> Depth to bedrock</a></li>
<li class="chapter" data-level="3.2.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#effective-soil-depth-and-rooting-depth"><i class="fa fa-check"></i><b>3.2.2</b> Effective soil depth and rooting depth</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#chemical-soil-properties"><i class="fa fa-check"></i><b>3.3</b> Chemical soil properties</a><ul>
<li class="chapter" data-level="3.3.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-organic-carbon"><i class="fa fa-check"></i><b>3.3.1</b> Soil organic carbon</a></li>
<li class="chapter" data-level="3.3.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-ph"><i class="fa fa-check"></i><b>3.3.2</b> Soil pH</a></li>
<li class="chapter" data-level="3.3.3" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-nutrients"><i class="fa fa-check"></i><b>3.3.3</b> Soil nutrients</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#physical-and-hydrological-soil-properties"><i class="fa fa-check"></i><b>3.4</b> Physical and hydrological soil properties</a><ul>
<li class="chapter" data-level="3.4.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#coarse-fragments"><i class="fa fa-check"></i><b>3.4.1</b> Coarse fragments</a></li>
<li class="chapter" data-level="3.4.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#particle-size-class-distribution-sand-silt-and-clay"><i class="fa fa-check"></i><b>3.4.2</b> Particle size class distribution: sand, silt and clay</a></li>
<li class="chapter" data-level="3.4.3" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#bulk-density"><i class="fa fa-check"></i><b>3.4.3</b> Bulk density</a></li>
<li class="chapter" data-level="3.4.4" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-organic-carbon-stock"><i class="fa fa-check"></i><b>3.4.4</b> Soil organic carbon stock</a></li>
<li class="chapter" data-level="3.4.5" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#available-water-capacity"><i class="fa fa-check"></i><b>3.4.5</b> Available Water Capacity</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#harmonisation-of-soil-data-and-pedo-transfer-functions"><i class="fa fa-check"></i><b>3.5</b> Harmonisation of soil data and pedo-transfer functions</a><ul>
<li class="chapter" data-level="3.5.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#basic-concepts-of-harmonisation-of-soil-property-values"><i class="fa fa-check"></i><b>3.5.1</b> Basic concepts of harmonisation of soil property values</a></li>
<li class="chapter" data-level="3.5.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#example-of-harmonization-using-texture-by-hand-classes"><i class="fa fa-check"></i><b>3.5.2</b> Example of harmonization using texture-by-hand classes</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-class-data"><i class="fa fa-check"></i><b>3.6</b> Soil class data</a><ul>
<li class="chapter" data-level="3.6.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#soil-types"><i class="fa fa-check"></i><b>3.6.1</b> Soil types</a></li>
<li class="chapter" data-level="3.6.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#other-factor-type-variables"><i class="fa fa-check"></i><b>3.6.2</b> Other factor-type variables</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#importing-and-formatting-soil-data-in-r"><i class="fa fa-check"></i><b>3.7</b> Importing and formatting soil data in R</a><ul>
<li class="chapter" data-level="3.7.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#converting-texture-by-hand-classes-to-fractions"><i class="fa fa-check"></i><b>3.7.1</b> Converting texture-by-hand classes to fractions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#converting-munsell-color-codes-to-other-color-systems"><i class="fa fa-check"></i><b>3.8</b> Converting Munsell color codes to other color systems</a></li>
<li class="chapter" data-level="3.9" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#mla-ptfs"><i class="fa fa-check"></i><b>3.9</b> Using Machine Learning to build Pedo-Transfer-Functions</a><ul>
<li class="chapter" data-level="3.9.1" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#ptf-for-bulk-density"><i class="fa fa-check"></i><b>3.9.1</b> PTF for Bulk Density</a></li>
<li class="chapter" data-level="3.9.2" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#ptf-for-correlating-classification-systems"><i class="fa fa-check"></i><b>3.9.2</b> PTF for correlating classification systems</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="soil-variables-chapter.html"><a href="soil-variables-chapter.html#summary-points"><i class="fa fa-check"></i><b>3.10</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html"><i class="fa fa-check"></i><b>4</b> Preparation of soil covariates for soil mapping</a><ul>
<li class="chapter" data-level="4.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covariate-data-sources"><i class="fa fa-check"></i><b>4.1</b> Soil covariate data sources</a><ul>
<li class="chapter" data-level="4.1.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#types-of-soil-covariates"><i class="fa fa-check"></i><b>4.1.1</b> Types of soil covariates</a></li>
<li class="chapter" data-level="4.1.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covs-30m"><i class="fa fa-check"></i><b>4.1.2</b> Soil covariate data sources (30–100 m resolution)</a></li>
<li class="chapter" data-level="4.1.3" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#soil-covs-250m"><i class="fa fa-check"></i><b>4.1.3</b> Soil covariate data sources (250 m resolution or coarser)</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#preparing-soil-covariate-layers"><i class="fa fa-check"></i><b>4.2</b> Preparing soil covariate layers</a><ul>
<li class="chapter" data-level="4.2.1" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#converting-polygon-maps-to-rasters"><i class="fa fa-check"></i><b>4.2.1</b> Converting polygon maps to rasters</a></li>
<li class="chapter" data-level="4.2.2" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#downscaling-upscaling"><i class="fa fa-check"></i><b>4.2.2</b> Downscaling or upscaling (aggregating) rasters</a></li>
<li class="chapter" data-level="4.2.3" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#deriving-dem-parameters-using-saga-gis"><i class="fa fa-check"></i><b>4.2.3</b> Deriving DEM parameters using SAGA GIS</a></li>
<li class="chapter" data-level="4.2.4" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#filtering-out-missing-pixels-and-artifacts"><i class="fa fa-check"></i><b>4.2.4</b> Filtering out missing pixels and artifacts</a></li>
<li class="chapter" data-level="4.2.5" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#overlaying-and-subsetting-raster-stacks-and-points"><i class="fa fa-check"></i><b>4.2.5</b> Overlaying and subsetting raster stacks and points</a></li>
<li class="chapter" data-level="4.2.6" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#working-with-larger-rasters"><i class="fa fa-check"></i><b>4.2.6</b> Working with large(r) rasters</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="soil-covs-chapter.html"><a href="soil-covs-chapter.html#summary-points-1"><i class="fa fa-check"></i><b>4.3</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="statistical-theory.html"><a href="statistical-theory.html"><i class="fa fa-check"></i><b>5</b> Statistical theory for predictive soil mapping</a><ul>
<li class="chapter" data-level="5.1" data-path="statistical-theory.html"><a href="statistical-theory.html#aspects-variability"><i class="fa fa-check"></i><b>5.1</b> Aspects of spatial variability of soil variables</a><ul>
<li class="chapter" data-level="5.1.1" data-path="statistical-theory.html"><a href="statistical-theory.html#modelling-soil-variability"><i class="fa fa-check"></i><b>5.1.1</b> Modelling soil variability</a></li>
<li class="chapter" data-level="5.1.2" data-path="statistical-theory.html"><a href="statistical-theory.html#umsv"><i class="fa fa-check"></i><b>5.1.2</b> Universal model of soil variation</a></li>
<li class="chapter" data-level="5.1.3" data-path="statistical-theory.html"><a href="statistical-theory.html#soil-depth-models"><i class="fa fa-check"></i><b>5.1.3</b> Modelling the variation of soil with depth</a></li>
<li class="chapter" data-level="5.1.4" data-path="statistical-theory.html"><a href="statistical-theory.html#vertical-aggregation"><i class="fa fa-check"></i><b>5.1.4</b> Vertical aggregation of soil properties</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="statistical-theory.html"><a href="statistical-theory.html#spatial-prediction-of-soil-variables"><i class="fa fa-check"></i><b>5.2</b> Spatial prediction of soil variables</a><ul>
<li class="chapter" data-level="5.2.1" data-path="statistical-theory.html"><a href="statistical-theory.html#main-principles"><i class="fa fa-check"></i><b>5.2.1</b> Main principles</a></li>
<li class="chapter" data-level="5.2.2" data-path="statistical-theory.html"><a href="statistical-theory.html#soil-sampling"><i class="fa fa-check"></i><b>5.2.2</b> Soil sampling</a></li>
<li class="chapter" data-level="5.2.3" data-path="statistical-theory.html"><a href="statistical-theory.html#sec:expertsystems"><i class="fa fa-check"></i><b>5.2.3</b> Knowledge-driven soil mapping</a></li>
<li class="chapter" data-level="5.2.4" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging"><i class="fa fa-check"></i><b>5.2.4</b> Geostatistics-driven soil mapping (pedometric mapping)</a></li>
<li class="chapter" data-level="5.2.5" data-path="statistical-theory.html"><a href="statistical-theory.html#RK-generic"><i class="fa fa-check"></i><b>5.2.5</b> Regression-kriging (generic model)</a></li>
<li class="chapter" data-level="5.2.6" data-path="statistical-theory.html"><a href="statistical-theory.html#spatial-prediction-using-multiple-linear-regression"><i class="fa fa-check"></i><b>5.2.6</b> Spatial Prediction using multiple linear regression</a></li>
<li class="chapter" data-level="5.2.7" data-path="statistical-theory.html"><a href="statistical-theory.html#universal-kriging-prediction-error"><i class="fa fa-check"></i><b>5.2.7</b> Universal kriging prediction error</a></li>
<li class="chapter" data-level="5.2.8" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-examples"><i class="fa fa-check"></i><b>5.2.8</b> Regression-kriging examples</a></li>
<li class="chapter" data-level="5.2.9" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-examples-using-the-gsif-package"><i class="fa fa-check"></i><b>5.2.9</b> Regression-kriging examples using the GSIF package</a></li>
<li class="chapter" data-level="5.2.10" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-and-polygon-averaging"><i class="fa fa-check"></i><b>5.2.10</b> Regression-kriging and polygon averaging</a></li>
<li class="chapter" data-level="5.2.11" data-path="statistical-theory.html"><a href="statistical-theory.html#block-support"><i class="fa fa-check"></i><b>5.2.11</b> Predictions at point vs block support</a></li>
<li class="chapter" data-level="5.2.12" data-path="statistical-theory.html"><a href="statistical-theory.html#gstat-sims"><i class="fa fa-check"></i><b>5.2.12</b> Geostatistical simulations</a></li>
<li class="chapter" data-level="5.2.13" data-path="statistical-theory.html"><a href="statistical-theory.html#automated-mapping"><i class="fa fa-check"></i><b>5.2.13</b> Automated mapping</a></li>
<li class="chapter" data-level="5.2.14" data-path="statistical-theory.html"><a href="statistical-theory.html#selecting-spatial-prediction-models"><i class="fa fa-check"></i><b>5.2.14</b> Selecting spatial prediction models</a></li>
<li class="chapter" data-level="5.2.15" data-path="statistical-theory.html"><a href="statistical-theory.html#regression-kriging-3D"><i class="fa fa-check"></i><b>5.2.15</b> 3D regression-kriging</a></li>
<li class="chapter" data-level="5.2.16" data-path="statistical-theory.html"><a href="statistical-theory.html#multiscale"><i class="fa fa-check"></i><b>5.2.16</b> Predicting with multiscale and multisource data</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-assessment"><i class="fa fa-check"></i><b>5.3</b> Accuracy assessment and the mapping efficiency</a><ul>
<li class="chapter" data-level="5.3.1" data-path="statistical-theory.html"><a href="statistical-theory.html#mapping-accuracy"><i class="fa fa-check"></i><b>5.3.1</b> Mapping accuracy and numeric resolution</a></li>
<li class="chapter" data-level="5.3.2" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-assessment-methods"><i class="fa fa-check"></i><b>5.3.2</b> Accuracy assessment methods</a></li>
<li class="chapter" data-level="5.3.3" data-path="statistical-theory.html"><a href="statistical-theory.html#cross-validation-and-its-limitations"><i class="fa fa-check"></i><b>5.3.3</b> Cross-validation and its limitations</a></li>
<li class="chapter" data-level="5.3.4" data-path="statistical-theory.html"><a href="statistical-theory.html#accuracy-of-the-predicted-model-uncertainty"><i class="fa fa-check"></i><b>5.3.4</b> Accuracy of the predicted model uncertainty</a></li>
<li class="chapter" data-level="5.3.5" data-path="statistical-theory.html"><a href="statistical-theory.html#derivation-and-interpretation-of-prediction-interval"><i class="fa fa-check"></i><b>5.3.5</b> Derivation and interpretation of prediction interval</a></li>
<li class="chapter" data-level="5.3.6" data-path="statistical-theory.html"><a href="statistical-theory.html#universal-measures-of-mapping-accuracy"><i class="fa fa-check"></i><b>5.3.6</b> Universal measures of mapping accuracy</a></li>
<li class="chapter" data-level="5.3.7" data-path="statistical-theory.html"><a href="statistical-theory.html#mapping-accuracy-and-soil-survey-costs"><i class="fa fa-check"></i><b>5.3.7</b> Mapping accuracy and soil survey costs</a></li>
<li class="chapter" data-level="5.3.8" data-path="statistical-theory.html"><a href="statistical-theory.html#summary-points-2"><i class="fa fa-check"></i><b>5.3.8</b> Summary points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html"><i class="fa fa-check"></i><b>6</b> Machine Learning Algorithms for soil mapping</a><ul>
<li class="chapter" data-level="6.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-properties-and-classes-using-mlas"><i class="fa fa-check"></i><b>6.1</b> Spatial prediction of soil properties and classes using MLA’s</a><ul>
<li class="chapter" data-level="6.1.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#loading-the-packages-and-data"><i class="fa fa-check"></i><b>6.1.1</b> Loading the packages and data</a></li>
<li class="chapter" data-level="6.1.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-classes-using-mlas"><i class="fa fa-check"></i><b>6.1.2</b> Spatial prediction of soil classes using MLA’s</a></li>
<li class="chapter" data-level="6.1.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#modelling-numeric-soil-properties-using-h2o"><i class="fa fa-check"></i><b>6.1.3</b> Modelling numeric soil properties using h2o</a></li>
<li class="chapter" data-level="6.1.4" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#prediction-3D"><i class="fa fa-check"></i><b>6.1.4</b> Spatial prediction of 3D (numeric) variables</a></li>
<li class="chapter" data-level="6.1.5" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#ensemble-predictions-using-h2oensemble"><i class="fa fa-check"></i><b>6.1.5</b> Ensemble predictions using h2oEnsemble</a></li>
<li class="chapter" data-level="6.1.6" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#ensemble-predictions-using-superlearner-package"><i class="fa fa-check"></i><b>6.1.6</b> Ensemble predictions using SuperLearner package</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#a-generic-framework-for-spatial-prediction-using-random-forest"><i class="fa fa-check"></i><b>6.2</b> A generic framework for spatial prediction using Random Forest</a><ul>
<li class="chapter" data-level="6.2.1" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#general-principle-of-rfsp"><i class="fa fa-check"></i><b>6.2.1</b> General principle of RFsp</a></li>
<li class="chapter" data-level="6.2.2" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#geographical-covariates"><i class="fa fa-check"></i><b>6.2.2</b> Geographical covariates</a></li>
<li class="chapter" data-level="6.2.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-2d-continuous-variable-using-rfsp"><i class="fa fa-check"></i><b>6.2.3</b> Spatial prediction 2D continuous variable using RFsp</a></li>
<li class="chapter" data-level="6.2.4" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-2d-variable-with-covariates-using-rfsp"><i class="fa fa-check"></i><b>6.2.4</b> Spatial prediction 2D variable with covariates using RFsp</a></li>
<li class="chapter" data-level="6.2.5" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-binomial-variables"><i class="fa fa-check"></i><b>6.2.5</b> Spatial prediction of binomial variables</a></li>
<li class="chapter" data-level="6.2.6" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#spatial-prediction-of-soil-types"><i class="fa fa-check"></i><b>6.2.6</b> Spatial prediction of soil types</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="soilmapping-using-mla.html"><a href="soilmapping-using-mla.html#summary-points-3"><i class="fa fa-check"></i><b>6.3</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="SOC-chapter.html"><a href="SOC-chapter.html"><i class="fa fa-check"></i><b>7</b> Spatial prediction and assessment of Soil Organic Carbon</a><ul>
<li class="chapter" data-level="7.1" data-path="SOC-chapter.html"><a href="SOC-chapter.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="SOC-chapter.html"><a href="SOC-chapter.html#measurement-and-derivation-of-soil-organic-carbon"><i class="fa fa-check"></i><b>7.2</b> Measurement and derivation of soil organic carbon</a></li>
<li class="chapter" data-level="7.3" data-path="SOC-chapter.html"><a href="SOC-chapter.html#derivation-of-ocs-and-ocd-using-soil-profile-data"><i class="fa fa-check"></i><b>7.3</b> Derivation of OCS and OCD using soil profile data</a></li>
<li class="chapter" data-level="7.4" data-path="SOC-chapter.html"><a href="SOC-chapter.html#estimation-of-bulk-density-using-a-globally-calibrated-ptf"><i class="fa fa-check"></i><b>7.4</b> Estimation of Bulk Density using a globally-calibrated PTF</a></li>
<li class="chapter" data-level="7.5" data-path="SOC-chapter.html"><a href="SOC-chapter.html#generating-maps-of-ocs"><i class="fa fa-check"></i><b>7.5</b> Generating maps of OCS</a></li>
<li class="chapter" data-level="7.6" data-path="SOC-chapter.html"><a href="SOC-chapter.html#predicting-ocs-from-point-data-the-2d-approach"><i class="fa fa-check"></i><b>7.6</b> Predicting OCS from point data (the 2D approach)</a></li>
<li class="chapter" data-level="7.7" data-path="SOC-chapter.html"><a href="SOC-chapter.html#ocs-3d-approach"><i class="fa fa-check"></i><b>7.7</b> Deriving OCS from soil profile data (the 3D approach)</a></li>
<li class="chapter" data-level="7.8" data-path="SOC-chapter.html"><a href="SOC-chapter.html#deriving-ocs-using-spatiotemporal-models"><i class="fa fa-check"></i><b>7.8</b> Deriving OCS using spatiotemporal models</a></li>
<li class="chapter" data-level="7.9" data-path="SOC-chapter.html"><a href="SOC-chapter.html#summary-points-4"><i class="fa fa-check"></i><b>7.9</b> Summary points</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="practical-tips.html"><a href="practical-tips.html"><i class="fa fa-check"></i><b>8</b> Practical tips for organizing Predictive Soil Mapping</a><ul>
<li class="chapter" data-level="8.1" data-path="practical-tips.html"><a href="practical-tips.html#critical-aspects-of-predictive-soil-mapping"><i class="fa fa-check"></i><b>8.1</b> Critical aspects of Predictive Soil Mapping</a><ul>
<li class="chapter" data-level="8.1.1" data-path="practical-tips.html"><a href="practical-tips.html#psm-main-steps"><i class="fa fa-check"></i><b>8.1.1</b> PSM main steps</a></li>
<li class="chapter" data-level="8.1.2" data-path="practical-tips.html"><a href="practical-tips.html#psm-input-and-output-spatial-data-layers"><i class="fa fa-check"></i><b>8.1.2</b> PSM input and output spatial data layers</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="practical-tips.html"><a href="practical-tips.html#technical-specifications-affecting-the-majority-of-production-costs"><i class="fa fa-check"></i><b>8.2</b> Technical specifications affecting the majority of production costs</a><ul>
<li class="chapter" data-level="8.2.1" data-path="practical-tips.html"><a href="practical-tips.html#field-observations-and-measurements"><i class="fa fa-check"></i><b>8.2.1</b> Field observations and measurements</a></li>
<li class="chapter" data-level="8.2.2" data-path="practical-tips.html"><a href="practical-tips.html#preparation-of-point-data"><i class="fa fa-check"></i><b>8.2.2</b> Preparation of point data</a></li>
<li class="chapter" data-level="8.2.3" data-path="practical-tips.html"><a href="practical-tips.html#preparation-of-covariates"><i class="fa fa-check"></i><b>8.2.3</b> Preparation of covariates</a></li>
<li class="chapter" data-level="8.2.4" data-path="practical-tips.html"><a href="practical-tips.html#soil-mask-and-the-grid-system"><i class="fa fa-check"></i><b>8.2.4</b> Soil mask and the grid system</a></li>
<li class="chapter" data-level="8.2.5" data-path="practical-tips.html"><a href="practical-tips.html#uncertainty-of-psm-maps"><i class="fa fa-check"></i><b>8.2.5</b> Uncertainty of PSM maps</a></li>
<li class="chapter" data-level="8.2.6" data-path="practical-tips.html"><a href="practical-tips.html#computing-costs"><i class="fa fa-check"></i><b>8.2.6</b> Computing costs</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="practical-tips.html"><a href="practical-tips.html#final-delivery-of-maps"><i class="fa fa-check"></i><b>8.3</b> Final delivery of maps</a><ul>
<li class="chapter" data-level="8.3.1" data-path="practical-tips.html"><a href="practical-tips.html#delivery-data-formats"><i class="fa fa-check"></i><b>8.3.1</b> Delivery data formats</a></li>
<li class="chapter" data-level="8.3.2" data-path="practical-tips.html"><a href="practical-tips.html#general-recommendations"><i class="fa fa-check"></i><b>8.3.2</b> General recommendations</a></li>
<li class="chapter" data-level="8.3.3" data-path="practical-tips.html"><a href="practical-tips.html#technical-specifications-psm-project"><i class="fa fa-check"></i><b>8.3.3</b> Technical specifications PSM project</a></li>
<li class="chapter" data-level="8.3.4" data-path="practical-tips.html"><a href="practical-tips.html#standard-soil-data-production-costs"><i class="fa fa-check"></i><b>8.3.4</b> Standard soil data production costs</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="practical-tips.html"><a href="practical-tips.html#summary-notes"><i class="fa fa-check"></i><b>8.4</b> Summary notes</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html"><i class="fa fa-check"></i><b>9</b> The future of predictive soil mapping</a><ul>
<li class="chapter" data-level="9.1" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#introduction-3"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#past-conventional-terrestrial-resource-inventories"><i class="fa fa-check"></i><b>9.2</b> Past conventional terrestrial resource inventories</a><ul>
<li class="chapter" data-level="9.2.1" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#why-have-most-national-resource-inventories-been-discontinued"><i class="fa fa-check"></i><b>9.2.1</b> Why have most national resource inventories been discontinued?</a></li>
<li class="chapter" data-level="9.2.2" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#is-there-a-future-for-conventional-terrestrial-inventory-programs"><i class="fa fa-check"></i><b>9.2.2</b> Is there a future for conventional terrestrial inventory programs ?</a></li>
<li class="chapter" data-level="9.2.3" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#can-terrestrial-inventory-programs-be-renewed-and-revived"><i class="fa fa-check"></i><b>9.2.3</b> Can terrestrial inventory programs be renewed and revived?</a></li>
<li class="chapter" data-level="9.2.4" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#how-can-terrestrial-inventory-programs-be-renewed-and-revived-and-by-whom"><i class="fa fa-check"></i><b>9.2.4</b> How can terrestrial inventory programs be renewed and revived and by whom?</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#the-future-of-psm-embracing-scientific-and-technical-advances"><i class="fa fa-check"></i><b>9.3</b> The future of PSM: Embracing scientific and technical advances</a><ul>
<li class="chapter" data-level="9.3.1" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#overview"><i class="fa fa-check"></i><b>9.3.1</b> Overview</a></li>
<li class="chapter" data-level="9.3.2" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#collection-of-field-observations-and-samples"><i class="fa fa-check"></i><b>9.3.2</b> Collection of field observations and samples</a></li>
<li class="chapter" data-level="9.3.3" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#collecting-new-field-om-data"><i class="fa fa-check"></i><b>9.3.3</b> Collecting New Field O&amp;M Data</a></li>
<li class="chapter" data-level="9.3.4" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#characterization-of-soils-in-the-field-and-the-laboratory"><i class="fa fa-check"></i><b>9.3.4</b> Characterization of soils in the field and the laboratory</a></li>
<li class="chapter" data-level="9.3.5" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#creation-collation-and-distribution-of-effective-environmental-covariates"><i class="fa fa-check"></i><b>9.3.5</b> Creation, collation and distribution of effective environmental covariates,</a></li>
<li class="chapter" data-level="9.3.6" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#automated-spatial-prediction-models-psm"><i class="fa fa-check"></i><b>9.3.6</b> Automated spatial prediction models (PSM)</a></li>
<li class="chapter" data-level="9.3.7" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#hosting-publishing-sharing-and-using-spatial-data"><i class="fa fa-check"></i><b>9.3.7</b> Hosting, publishing, sharing and using spatial data</a></li>
<li class="chapter" data-level="9.3.8" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#new-visualization-and-data-analysis-tools"><i class="fa fa-check"></i><b>9.3.8</b> New visualization and data analysis tools</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#the-future-of-psm-embracing-new-organizational-and-governance-models"><i class="fa fa-check"></i><b>9.4</b> The future of PSM: Embracing new organizational and governance models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#overview-1"><i class="fa fa-check"></i><b>9.4.1</b> Overview</a></li>
<li class="chapter" data-level="9.4.2" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#open-data-and-platforms-and-procedures-for-acquiring-and-sharing-it"><i class="fa fa-check"></i><b>9.4.2</b> Open data and platforms and procedures for acquiring and sharing it</a></li>
<li class="chapter" data-level="9.4.3" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#open-cloud-based-processing-capabilities"><i class="fa fa-check"></i><b>9.4.3</b> Open cloud-based processing capabilities</a></li>
<li class="chapter" data-level="9.4.4" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#collaborative-production-of-inputs-and-new-outputs"><i class="fa fa-check"></i><b>9.4.4</b> Collaborative production of inputs and new outputs</a></li>
<li class="chapter" data-level="9.4.5" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#crowdsourcing-and-voluntary-collaboration"><i class="fa fa-check"></i><b>9.4.5</b> Crowdsourcing and voluntary collaboration,</a></li>
<li class="chapter" data-level="9.4.6" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#sponsorship-subscription-crowdfunding-and-blockchain-funding-systems"><i class="fa fa-check"></i><b>9.4.6</b> Sponsorship, subscription, crowdfunding and blockchain funding systems,</a></li>
<li class="chapter" data-level="9.4.7" data-path="the-future-of-predictive-soil-mapping.html"><a href="the-future-of-predictive-soil-mapping.html#a-proposal-for-organizing-and-managing-a-new-open-collective"><i class="fa fa-check"></i><b>9.4.7</b> A proposal for organizing and managing a new open collective</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://opengeohub.org/about">T. (Tom) Hengl and R.A. (Bob) MacMillan</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Predictive Soil Mapping with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="soilmapping-using-mla" class="section level1">
<h1><span class="header-section-number">6</span> Machine Learning Algorithms for soil mapping</h1>
<p><em>Edited by: T. Hengl</em></p>
<div id="spatial-prediction-of-soil-properties-and-classes-using-mlas" class="section level2">
<h2><span class="header-section-number">6.1</span> Spatial prediction of soil properties and classes using MLA’s</h2>
<p>This chapter looks at some common Machine learning algorithms (MLA’s) that are potentially of interest for soil mapping projects i.e. for generating spatial predictions. We put special focus on using tree-based algorithms such as <a href="https://en.wikipedia.org/wiki/Random_forest">random forest</a>, <a href="https://en.wikipedia.org/wiki/Gradient_boosting">gradient boosting</a> and <a href="https://cran.r-project.org/package=Cubist">Cubist</a>. For a more in-depth overview of machine learning algorithms used in statistics refer to the CRAN Task View on <a href="https://cran.r-project.org/web/views/MachineLearning.html">Machine Learning &amp; Statistical Learning</a>. Some other examples of how MLA’s can be used to fit Pedo-Transfer-Functions can be found in section <a href="soil-variables-chapter.html#mla-ptfs">3.9</a>.</p>
<div id="loading-the-packages-and-data" class="section level3">
<h3><span class="header-section-number">6.1.1</span> Loading the packages and data</h3>
<p>We start by loading all required packages:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plotKML)
<span class="co">#&gt; plotKML version 0.5-8 (2017-05-12)</span>
<span class="co">#&gt; URL: http://plotkml.r-forge.r-project.org/</span>
<span class="kw">library</span>(sp)
<span class="kw">library</span>(randomForest)
<span class="co">#&gt; randomForest 4.6-14</span>
<span class="co">#&gt; Type rfNews() to see new features/changes/bug fixes.</span>
<span class="kw">library</span>(nnet)
<span class="kw">library</span>(e1071)
<span class="kw">library</span>(GSIF)
<span class="co">#&gt; GSIF version 0.5-4 (2017-04-25)</span>
<span class="co">#&gt; URL: http://gsif.r-forge.r-project.org/</span>
<span class="kw">library</span>(plyr)
<span class="kw">library</span>(raster)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;raster&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:e1071&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     interpolate</span>
<span class="kw">library</span>(caret)
<span class="co">#&gt; Loading required package: lattice</span>
<span class="co">#&gt; Loading required package: ggplot2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;ggplot2&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:randomForest&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     margin</span>
<span class="kw">library</span>(Cubist)
<span class="kw">library</span>(GSIF)
<span class="kw">library</span>(xgboost)</code></pre>
<p>Next, we load the (<a href="http://plotkml.r-forge.r-project.org/eberg.html">Ebergotzen</a>) data set which consists of point data collected using a soil auger and a stack of rasters containing all covariates:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(plotKML)
<span class="kw">data</span>(eberg)
<span class="kw">data</span>(eberg_grid)
<span class="kw">coordinates</span>(eberg) &lt;-<span class="st"> </span><span class="er">~</span>X<span class="op">+</span>Y
<span class="kw">proj4string</span>(eberg) &lt;-<span class="st"> </span><span class="kw">CRS</span>(<span class="st">&quot;+init=epsg:31467&quot;</span>)
<span class="kw">gridded</span>(eberg_grid) &lt;-<span class="st"> </span><span class="er">~</span>x<span class="op">+</span>y
<span class="kw">proj4string</span>(eberg_grid) &lt;-<span class="st"> </span><span class="kw">CRS</span>(<span class="st">&quot;+init=epsg:31467&quot;</span>)</code></pre>
<p>The covariates are then converted to principal components to reduce covariance and dimensionality:</p>
<pre class="sourceCode r"><code class="sourceCode r">eberg_spc &lt;-<span class="st"> </span><span class="kw">spc</span>(eberg_grid, <span class="op">~</span><span class="st"> </span>PRMGEO6<span class="op">+</span>DEMSRT6<span class="op">+</span>TWISRT6<span class="op">+</span>TIRAST6)
<span class="co">#&gt; Converting PRMGEO6 to indicators...</span>
<span class="co">#&gt; Converting covariates to principal components...</span>
eberg_grid<span class="op">@</span>data &lt;-<span class="st"> </span><span class="kw">cbind</span>(eberg_grid<span class="op">@</span>data, eberg_spc<span class="op">@</span>predicted<span class="op">@</span>data)</code></pre>
<p>All further analysis is run using the so-called <em>regression matrix</em> (matrix produced using the overlay of points and grids), which contains values of the target variable and all covariates for all training points:</p>
<pre class="sourceCode r"><code class="sourceCode r">ov &lt;-<span class="st"> </span><span class="kw">over</span>(eberg, eberg_grid)
m &lt;-<span class="st"> </span><span class="kw">cbind</span>(ov, eberg<span class="op">@</span>data)
<span class="kw">dim</span>(m)
<span class="co">#&gt; [1] 3670   44</span></code></pre>
<p>In this case the regression matrix consists of 3670 observations and has 44 columns.</p>
</div>
<div id="spatial-prediction-of-soil-classes-using-mlas" class="section level3">
<h3><span class="header-section-number">6.1.2</span> Spatial prediction of soil classes using MLA’s</h3>
<p>In the first example, we focus on mapping soil types using the auger point data. First, we need to filter out some classes that do not occur frequently enough to support statistical modelling. As a rule of thumb, a class to be modelled should have at least 5 observations:</p>
<pre class="sourceCode r"><code class="sourceCode r">xg &lt;-<span class="st"> </span><span class="kw">summary</span>(m<span class="op">$</span>TAXGRSC, <span class="dt">maxsum=</span>(<span class="dv">1</span><span class="op">+</span><span class="kw">length</span>(<span class="kw">levels</span>(m<span class="op">$</span>TAXGRSC))))
<span class="kw">str</span>(xg)
<span class="co">#&gt;  Named int [1:14] 71 790 86 1 186 1 704 215 252 487 ...</span>
<span class="co">#&gt;  - attr(*, &quot;names&quot;)= chr [1:14] &quot;Auenboden&quot; &quot;Braunerde&quot; &quot;Gley&quot; &quot;HMoor&quot; ...</span>
selg.levs &lt;-<span class="st"> </span><span class="kw">attr</span>(xg, <span class="st">&quot;names&quot;</span>)[xg <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>]
<span class="kw">attr</span>(xg, <span class="st">&quot;names&quot;</span>)[xg <span class="op">&lt;=</span><span class="st"> </span><span class="dv">5</span>]
<span class="co">#&gt; [1] &quot;HMoor&quot; &quot;Moor&quot;</span></code></pre>
<p>this shows that two classes probably have too few observations and should be excluded from further modeling:</p>
<pre class="sourceCode r"><code class="sourceCode r">m<span class="op">$</span>soiltype &lt;-<span class="st"> </span>m<span class="op">$</span>TAXGRSC
m<span class="op">$</span>soiltype[<span class="kw">which</span>(<span class="op">!</span>m<span class="op">$</span>TAXGRSC <span class="op">%in%</span><span class="st"> </span>selg.levs)] &lt;-<span class="st"> </span><span class="ot">NA</span>
m<span class="op">$</span>soiltype &lt;-<span class="st"> </span><span class="kw">droplevels</span>(m<span class="op">$</span>soiltype)
<span class="kw">str</span>(<span class="kw">summary</span>(m<span class="op">$</span>soiltype, <span class="dt">maxsum=</span><span class="kw">length</span>(<span class="kw">levels</span>(m<span class="op">$</span>soiltype))))
<span class="co">#&gt;  Named int [1:11] 790 704 487 376 252 215 186 86 71 43 ...</span>
<span class="co">#&gt;  - attr(*, &quot;names&quot;)= chr [1:11] &quot;Braunerde&quot; &quot;Parabraunerde&quot; &quot;Pseudogley&quot; &quot;Regosol&quot; ...</span></code></pre>
<p>We can also remove all points that contain missing values for any combination of covariates and target variable:</p>
<pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span>m[<span class="kw">complete.cases</span>(m[,<span class="dv">1</span><span class="op">:</span>(<span class="kw">ncol</span>(eberg_grid)<span class="op">+</span><span class="dv">2</span>)]),]
m<span class="op">$</span>soiltype &lt;-<span class="st"> </span><span class="kw">as.factor</span>(m<span class="op">$</span>soiltype)
<span class="kw">summary</span>(m<span class="op">$</span>soiltype)
<span class="co">#&gt;     Auenboden     Braunerde          Gley    Kolluvisol Parabraunerde </span>
<span class="co">#&gt;            48           669            68           138           513 </span>
<span class="co">#&gt;  Pararendzina       Pelosol    Pseudogley        Ranker       Regosol </span>
<span class="co">#&gt;           176           177           411            17           313 </span>
<span class="co">#&gt;      Rendzina </span>
<span class="co">#&gt;            22</span></code></pre>
<p>We can now test fitting a MLA i.e. a random forest model using four covariate layers (parent material map, elevation, TWI and Aster thermal band):</p>
<pre class="sourceCode r"><code class="sourceCode r">## subset to speed-up:
s &lt;-<span class="st"> </span><span class="kw">sample.int</span>(<span class="kw">nrow</span>(m), <span class="dv">500</span>)
TAXGRSC.rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(<span class="dt">x=</span>m[<span class="op">-</span>s,<span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)], <span class="dt">y=</span>m<span class="op">$</span>soiltype[<span class="op">-</span>s],
                           <span class="dt">xtest=</span>m[s,<span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)], <span class="dt">ytest=</span>m<span class="op">$</span>soiltype[s])
## accuracy:
TAXGRSC.rf<span class="op">$</span>test<span class="op">$</span>confusion[,<span class="st">&quot;class.error&quot;</span>]
<span class="co">#&gt;     Auenboden     Braunerde          Gley    Kolluvisol Parabraunerde </span>
<span class="co">#&gt;         0.750         0.479         0.846         0.652         0.571 </span>
<span class="co">#&gt;  Pararendzina       Pelosol    Pseudogley        Ranker       Regosol </span>
<span class="co">#&gt;         0.571         0.696         0.690         1.000         0.625 </span>
<span class="co">#&gt;      Rendzina </span>
<span class="co">#&gt;         0.500</span></code></pre>
<p>Note that, by specifying <code>xtest</code> and <code>ytest</code>, we run both model fitting and cross-validation with 500 excluded points. The results show relatively high prediction error of about 60% i.e. relative classification accuracy of about 40%.</p>
<p>We can also test some other MLA’s that are suited for this data — multinom from the <a href="https://cran.r-project.org/package=nnet">nnet</a> package, and svm (Support Vector Machine) from the <a href="https://cran.r-project.org/package=e1071">e1071</a> package:</p>
<pre class="sourceCode r"><code class="sourceCode r">TAXGRSC.rf &lt;-<span class="st"> </span><span class="kw">randomForest</span>(<span class="dt">x=</span>m[,<span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)], <span class="dt">y=</span>m<span class="op">$</span>soiltype)
fm &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;soiltype~&quot;</span>, <span class="kw">paste</span>(<span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>), <span class="dt">collapse=</span><span class="st">&quot;+&quot;</span>)))
TAXGRSC.mn &lt;-<span class="st"> </span>nnet<span class="op">::</span><span class="kw">multinom</span>(fm, m)
<span class="co">#&gt; # weights:  132 (110 variable)</span>
<span class="co">#&gt; initial  value 6119.428736 </span>
<span class="co">#&gt; iter  10 value 4161.338634</span>
<span class="co">#&gt; iter  20 value 4118.296050</span>
<span class="co">#&gt; iter  30 value 4054.454486</span>
<span class="co">#&gt; iter  40 value 4020.653949</span>
<span class="co">#&gt; iter  50 value 3995.113270</span>
<span class="co">#&gt; iter  60 value 3980.172669</span>
<span class="co">#&gt; iter  70 value 3975.188371</span>
<span class="co">#&gt; iter  80 value 3973.743572</span>
<span class="co">#&gt; iter  90 value 3973.073564</span>
<span class="co">#&gt; iter 100 value 3973.064186</span>
<span class="co">#&gt; final  value 3973.064186 </span>
<span class="co">#&gt; stopped after 100 iterations</span>
TAXGRSC.svm &lt;-<span class="st"> </span>e1071<span class="op">::</span><span class="kw">svm</span>(fm, m, <span class="dt">probability=</span><span class="ot">TRUE</span>, <span class="dt">cross=</span><span class="dv">5</span>)
TAXGRSC.svm<span class="op">$</span>tot.accuracy
<span class="co">#&gt; [1] 40.1</span></code></pre>
<p>This produces about the same accuracy levels as for random forest. Because all three methods produce comparable accuracy, we can also merge predictions by calculating a simple average:</p>
<pre class="sourceCode r"><code class="sourceCode r">probs1 &lt;-<span class="st"> </span><span class="kw">predict</span>(TAXGRSC.mn, eberg_grid<span class="op">@</span>data, <span class="dt">type=</span><span class="st">&quot;probs&quot;</span>, <span class="dt">na.action =</span> na.pass) 
probs2 &lt;-<span class="st"> </span><span class="kw">predict</span>(TAXGRSC.rf, eberg_grid<span class="op">@</span>data, <span class="dt">type=</span><span class="st">&quot;prob&quot;</span>, <span class="dt">na.action =</span> na.pass)
probs3 &lt;-<span class="st"> </span><span class="kw">attr</span>(<span class="kw">predict</span>(TAXGRSC.svm, eberg_grid<span class="op">@</span>data, 
                       <span class="dt">probability=</span><span class="ot">TRUE</span>, <span class="dt">na.action =</span> na.pass), <span class="st">&quot;probabilities&quot;</span>)</code></pre>
<p>derive average prediction:</p>
<pre class="sourceCode r"><code class="sourceCode r">leg &lt;-<span class="st"> </span><span class="kw">levels</span>(m<span class="op">$</span>soiltype)
lt &lt;-<span class="st"> </span><span class="kw">list</span>(probs1[,leg], probs2[,leg], probs3[,leg])
probs &lt;-<span class="st"> </span><span class="kw">Reduce</span>(<span class="st">&quot;+&quot;</span>, lt) <span class="op">/</span><span class="st"> </span><span class="kw">length</span>(lt)
## copy and make new raster object:
eberg_soiltype &lt;-<span class="st"> </span>eberg_grid
eberg_soiltype<span class="op">@</span>data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(probs)</code></pre>
<p>Check that all predictions sum up to 100%:</p>
<pre class="sourceCode r"><code class="sourceCode r">ch &lt;-<span class="st"> </span><span class="kw">rowSums</span>(eberg_soiltype<span class="op">@</span>data)
<span class="kw">summary</span>(ch)
<span class="co">#&gt;    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. </span>
<span class="co">#&gt;       1       1       1       1       1       1</span></code></pre>
<p>To plot the result we can use the raster package (Fig. <a href="soilmapping-using-mla.html#fig:plot-eberg-soiltype">6.1</a>):</p>
<div class="figure" style="text-align: center"><span id="fig:plot-eberg-soiltype"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/plot-eberg-soiltype-1.png" alt="Predicted soil types for the Ebergotzen case study." width="100%" />
<p class="caption">
Figure 6.1: Predicted soil types for the Ebergotzen case study.
</p>
</div>
<p>By using the produced predictions we can further derive Confusion Index (to map thematic uncertainty) and see if some classes should be aggregated. We can also generate a factor-type map by selecting the most probable class for each pixel, by using e.g.:</p>
<pre class="sourceCode r"><code class="sourceCode r">eberg_soiltype<span class="op">$</span>cl &lt;-<span class="st"> </span><span class="kw">as.factor</span>(<span class="kw">apply</span>(eberg_soiltype<span class="op">@</span>data,<span class="dv">1</span>,which.max)) 
<span class="kw">levels</span>(eberg_soiltype<span class="op">$</span>cl) =<span class="st"> </span><span class="kw">attr</span>(probs, <span class="st">&quot;dimnames&quot;</span>)[[<span class="dv">2</span>]][<span class="kw">as.integer</span>(<span class="kw">levels</span>(eberg_soiltype<span class="op">$</span>cl))]
<span class="kw">summary</span>(eberg_soiltype<span class="op">$</span>cl)
<span class="co">#&gt;     Auenboden     Braunerde          Gley    Kolluvisol Parabraunerde </span>
<span class="co">#&gt;            36          2286           146            68          2253 </span>
<span class="co">#&gt;  Pararendzina       Pelosol    Pseudogley       Regosol      Rendzina </span>
<span class="co">#&gt;           821           439          1310           317          2324</span></code></pre>
</div>
<div id="modelling-numeric-soil-properties-using-h2o" class="section level3">
<h3><span class="header-section-number">6.1.3</span> Modelling numeric soil properties using h2o</h3>
<p>Random forest is suited for both classification and regression problems (it is one of the most popular MLA’s for soil mapping). Consequently, we can use it also for modelling numeric soil properties i.e. to fit models and generate predictions. However, because the randomForest package in R is not suited for large data sets, we can also use some parallelized version of random forest (or more scalable) i.e. the one implemented in the <a href="http://www.h2o.ai/">h2o package</a> <span class="citation">(Richter et al. <a href="#ref-richter2015multi">2015</a>)</span>. h2o is a Java-based implementation, therefore installing the package requires Java libraries (size of package is about 80MB so it might take some to download and install) and all computing is in principle run outside of R i.e. within the JVM (Java Virtual Machine).</p>
<p>In the following example we look at mapping sand content for the upper horizons. To initiate h2o we run:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(h2o)
localH2O =<span class="st"> </span><span class="kw">h2o.init</span>(<span class="dt">startH2O=</span><span class="ot">TRUE</span>)
<span class="co">#&gt;  Connection successful!</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; R is connected to the H2O cluster: </span>
<span class="co">#&gt;     H2O cluster uptime:         22 minutes 58 seconds </span>
<span class="co">#&gt;     H2O cluster timezone:       UTC </span>
<span class="co">#&gt;     H2O data parsing timezone:  UTC </span>
<span class="co">#&gt;     H2O cluster version:        3.20.0.8 </span>
<span class="co">#&gt;     H2O cluster version age:    2 months and 29 days  </span>
<span class="co">#&gt;     H2O cluster name:           H2O_started_from_R_travis_lqb476 </span>
<span class="co">#&gt;     H2O cluster total nodes:    1 </span>
<span class="co">#&gt;     H2O cluster total memory:   1.46 GB </span>
<span class="co">#&gt;     H2O cluster total cores:    2 </span>
<span class="co">#&gt;     H2O cluster allowed cores:  2 </span>
<span class="co">#&gt;     H2O cluster healthy:        TRUE </span>
<span class="co">#&gt;     H2O Connection ip:          localhost </span>
<span class="co">#&gt;     H2O Connection port:        54321 </span>
<span class="co">#&gt;     H2O Connection proxy:       NA </span>
<span class="co">#&gt;     H2O Internal Security:      FALSE </span>
<span class="co">#&gt;     H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4 </span>
<span class="co">#&gt;     R Version:                  R version 3.5.1 (2018-12-12)</span></code></pre>
<p>This shows that multiple cores will be used for computing (to control the number of cores you can use the <code>nthreads</code> argument). Next, we need to prepare the regression matrix and prediction locations using the <code>as.h2o</code> function so that they are visible to h2o:</p>
<pre class="sourceCode r"><code class="sourceCode r">eberg.hex &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(m, <span class="dt">destination_frame =</span> <span class="st">&quot;eberg.hex&quot;</span>)
eberg.grid &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(eberg_grid<span class="op">@</span>data, <span class="dt">destination_frame =</span> <span class="st">&quot;eberg.grid&quot;</span>)</code></pre>
<p>We can now fit a random forest model by using all the computing power available to us:</p>
<pre class="sourceCode r"><code class="sourceCode r">RF.m &lt;-<span class="st"> </span><span class="kw">h2o.randomForest</span>(<span class="dt">y =</span> <span class="kw">which</span>(<span class="kw">names</span>(m)<span class="op">==</span><span class="st">&quot;SNDMHT_A&quot;</span>), 
                        <span class="dt">x =</span> <span class="kw">which</span>(<span class="kw">names</span>(m) <span class="op">%in%</span><span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)), 
                        <span class="dt">training_frame =</span> eberg.hex, <span class="dt">ntree =</span> <span class="dv">50</span>)
RF.m
<span class="co">#&gt; Model Details:</span>
<span class="co">#&gt; ==============</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2ORegressionModel: drf</span>
<span class="co">#&gt; Model ID:  DRF_model_R_1545332371665_21 </span>
<span class="co">#&gt; Model Summary: </span>
<span class="co">#&gt;   number_of_trees number_of_internal_trees model_size_in_bytes min_depth</span>
<span class="co">#&gt; 1              50                       50              645810        20</span>
<span class="co">#&gt;   max_depth mean_depth min_leaves max_leaves mean_leaves</span>
<span class="co">#&gt; 1        20   20.00000        900       1097  1024.40000</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2ORegressionMetrics: drf</span>
<span class="co">#&gt; ** Reported on training data. **</span>
<span class="co">#&gt; ** Metrics reported on Out-Of-Bag training samples **</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; MSE:  219</span>
<span class="co">#&gt; RMSE:  14.8</span>
<span class="co">#&gt; MAE:  10</span>
<span class="co">#&gt; RMSLE:  0.428</span>
<span class="co">#&gt; Mean Residual Deviance :  219</span></code></pre>
<p>This shows that the model fitting R-square is about 50%. This is also indicated by the predicted vs observed plot:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(scales)
<span class="kw">library</span>(lattice)
SDN.pred &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">h2o.predict</span>(RF.m, eberg.hex, <span class="dt">na.action=</span>na.pass))<span class="op">$</span>predict
plt1 &lt;-<span class="st"> </span><span class="kw">xyplot</span>(m<span class="op">$</span>SNDMHT_A <span class="op">~</span><span class="st"> </span>SDN.pred, <span class="dt">asp=</span><span class="dv">1</span>, 
               <span class="dt">par.settings=</span><span class="kw">list</span>(
                 <span class="dt">plot.symbol =</span> <span class="kw">list</span>(<span class="dt">col=</span>scales<span class="op">::</span><span class="kw">alpha</span>(<span class="st">&quot;black&quot;</span>, <span class="fl">0.6</span>), 
                 <span class="dt">fill=</span>scales<span class="op">::</span><span class="kw">alpha</span>(<span class="st">&quot;red&quot;</span>, <span class="fl">0.6</span>), <span class="dt">pch=</span><span class="dv">21</span>, <span class="dt">cex=</span><span class="fl">0.8</span>)),
                 <span class="dt">ylab=</span><span class="st">&quot;measured&quot;</span>, <span class="dt">xlab=</span><span class="st">&quot;predicted (machine learning)&quot;</span>)
plt1</code></pre>
<div class="figure" style="text-align: center"><span id="fig:obs-pred-snd"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/obs-pred-snd-1.png" alt="Measured vs predicted SAND content based on the Random Forest model." width="100%" />
<p class="caption">
Figure 6.2: Measured vs predicted SAND content based on the Random Forest model.
</p>
</div>
<p>To produce a map based on these predictions we use:</p>
<pre class="sourceCode r"><code class="sourceCode r">eberg_grid<span class="op">$</span>RFx &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">h2o.predict</span>(RF.m, eberg.grid, <span class="dt">na.action=</span>na.pass))<span class="op">$</span>predict</code></pre>
<div class="figure" style="text-align: center"><span id="fig:map-snd"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/map-snd-1.png" alt="Predicted sand content based on random forest." width="100%" />
<p class="caption">
Figure 6.3: Predicted sand content based on random forest.
</p>
</div>
<p>h2o has another MLA of interest for soil mapping called <em>deep learning</em> (a feed-forward multilayer artificial neural network). Fitting the model is equivalent to using random forest:</p>
<pre class="sourceCode r"><code class="sourceCode r">DL.m &lt;-<span class="st"> </span><span class="kw">h2o.deeplearning</span>(<span class="dt">y =</span> <span class="kw">which</span>(<span class="kw">names</span>(m)<span class="op">==</span><span class="st">&quot;SNDMHT_A&quot;</span>), 
                         <span class="dt">x =</span> <span class="kw">which</span>(<span class="kw">names</span>(m) <span class="op">%in%</span><span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;PC&quot;</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)), 
                         <span class="dt">training_frame =</span> eberg.hex)
DL.m
<span class="co">#&gt; Model Details:</span>
<span class="co">#&gt; ==============</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2ORegressionModel: deeplearning</span>
<span class="co">#&gt; Model ID:  DeepLearning_model_R_1545332371665_22 </span>
<span class="co">#&gt; Status of Neuron Layers: predicting SNDMHT_A, regression, gaussian distribution, Quadratic loss, 42,601 weights/biases, 508.3 KB, 25,520 training samples, mini-batch size 1</span>
<span class="co">#&gt;   layer units      type dropout       l1       l2 mean_rate rate_rms</span>
<span class="co">#&gt; 1     1    10     Input  0.00 %       NA       NA        NA       NA</span>
<span class="co">#&gt; 2     2   200 Rectifier  0.00 % 0.000000 0.000000  0.013351 0.007673</span>
<span class="co">#&gt; 3     3   200 Rectifier  0.00 % 0.000000 0.000000  0.140411 0.172171</span>
<span class="co">#&gt; 4     4     1    Linear      NA 0.000000 0.000000  0.002114 0.009781</span>
<span class="co">#&gt;   momentum mean_weight weight_rms mean_bias bias_rms</span>
<span class="co">#&gt; 1       NA          NA         NA        NA       NA</span>
<span class="co">#&gt; 2 0.000000   -0.003341   0.101637  0.353629 0.069579</span>
<span class="co">#&gt; 3 0.000000   -0.018373   0.071495  0.953456 0.018432</span>
<span class="co">#&gt; 4 0.000000   -0.000810   0.043960  0.068725 0.000000</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2ORegressionMetrics: deeplearning</span>
<span class="co">#&gt; ** Reported on training data. **</span>
<span class="co">#&gt; ** Metrics reported on full training frame **</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; MSE:  281</span>
<span class="co">#&gt; RMSE:  16.8</span>
<span class="co">#&gt; MAE:  12.6</span>
<span class="co">#&gt; RMSLE:  0.514</span>
<span class="co">#&gt; Mean Residual Deviance :  281</span></code></pre>
<p>Which delivers performance comparable to the random forest model. The output prediction map does show somewhat different patterns than the random forest predictions (compare Fig. <a href="soilmapping-using-mla.html#fig:map-snd">6.3</a> and Fig. <a href="soilmapping-using-mla.html#fig:map-snd-dl">6.4</a>).</p>
<pre class="sourceCode r"><code class="sourceCode r">## predictions:
eberg_grid<span class="op">$</span>DLx &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">h2o.predict</span>(DL.m, eberg.grid, <span class="dt">na.action=</span>na.pass))<span class="op">$</span>predict</code></pre>
<div class="figure" style="text-align: center"><span id="fig:map-snd-dl"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/map-snd-dl-1.png" alt="Predicted SAND content based on deep learning." width="100%" />
<p class="caption">
Figure 6.4: Predicted SAND content based on deep learning.
</p>
</div>
<p>Which of the two methods should we use? Since they both have comparable performance, the most logical option is to generate ensemble (merged) predictions i.e. to produce a map that shows patterns averaged between the two methods (note: many sophisticated MLA such as random forest, neural nets, SVM and similar will often produce comparable results i.e. they are often equally applicable and there is no clear <em>winner</em>). We can use weighted average i.e. R-square as a simple approach to produce merged predictions:</p>
<pre class="sourceCode r"><code class="sourceCode r">rf.R2 &lt;-<span class="st"> </span>RF.m<span class="op">@</span>model<span class="op">$</span>training_metrics<span class="op">@</span>metrics<span class="op">$</span>r2
dl.R2 &lt;-<span class="st"> </span>DL.m<span class="op">@</span>model<span class="op">$</span>training_metrics<span class="op">@</span>metrics<span class="op">$</span>r2
eberg_grid<span class="op">$</span>SNDMHT_A &lt;-<span class="st"> </span><span class="kw">rowSums</span>(<span class="kw">cbind</span>(eberg_grid<span class="op">$</span>RFx<span class="op">*</span>rf.R2, 
                         eberg_grid<span class="op">$</span>DLx<span class="op">*</span>dl.R2), <span class="dt">na.rm=</span><span class="ot">TRUE</span>)<span class="op">/</span>(rf.R2<span class="op">+</span>dl.R2)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:map-snd-ensemble"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/map-snd-ensemble-1.png" alt="Predicted SAND content based on ensemble predictions." width="100%" />
<p class="caption">
Figure 6.5: Predicted SAND content based on ensemble predictions.
</p>
</div>
<p>Indeed, the output map now shows patterns of both methods and is more likely slightly more accurate than any of the individual MLA’s <span class="citation">(Sollich and Krogh <a href="#ref-krogh1996learning">1996</a>)</span>.</p>
</div>
<div id="prediction-3D" class="section level3">
<h3><span class="header-section-number">6.1.4</span> Spatial prediction of 3D (numeric) variables</h3>
<p>In the final exercise, we look at another two ML-based packages that are also of interest for soil mapping projects — cubist <span class="citation">(Kuhn et al. <a href="#ref-kuhn2012cubist">2012</a>; Kuhn and Johnson <a href="#ref-kuhn2013applied">2013</a>)</span> and xgboost <span class="citation">(Chen and Guestrin <a href="#ref-2016arXiv160302754C">2016</a>)</span>. The object is now to fit models and predict continuous soil properties in 3D. To fine-tune some of the models we will also use the <a href="http://topepo.github.io/caret/">caret</a> package, which is highly recommended for optimizing model fitting and cross-validation. Read more about how to derive soil organic carbon stock using 3D soil mapping in section <a href="SOC-chapter.html#ocs-3d-approach">7.7</a>.</p>
<p>We now look at another soil mapping data set from Australia called <a href="http://gsif.r-forge.r-project.org/edgeroi.html">“Edgeroi”</a>, which is described in detail in <span class="citation">Malone et al. (<a href="#ref-Malone2009Geoderma">2009</a>)</span>. We can load the profile data and covariates by using:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(edgeroi)
edgeroi.sp &lt;-<span class="st"> </span>edgeroi<span class="op">$</span>sites
<span class="kw">coordinates</span>(edgeroi.sp) &lt;-<span class="st"> </span><span class="er">~</span><span class="st"> </span>LONGDA94 <span class="op">+</span><span class="st"> </span>LATGDA94
<span class="kw">proj4string</span>(edgeroi.sp) &lt;-<span class="st"> </span><span class="kw">CRS</span>(<span class="st">&quot;+proj=longlat +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +no_defs&quot;</span>)
edgeroi.sp &lt;-<span class="st"> </span><span class="kw">spTransform</span>(edgeroi.sp, <span class="kw">CRS</span>(<span class="st">&quot;+init=epsg:28355&quot;</span>))
<span class="kw">load</span>(<span class="st">&quot;extdata/edgeroi.grids.rda&quot;</span>)
<span class="kw">gridded</span>(edgeroi.grids) &lt;-<span class="st"> </span><span class="er">~</span>x<span class="op">+</span>y
<span class="kw">proj4string</span>(edgeroi.grids) &lt;-<span class="st"> </span><span class="kw">CRS</span>(<span class="st">&quot;+init=epsg:28355&quot;</span>)</code></pre>
<p>Here we are interested in modelling soil organic carbon content in g/kg for different depths. We again start by producing the regression matrix:</p>
<pre class="sourceCode r"><code class="sourceCode r">ov2 &lt;-<span class="st"> </span><span class="kw">over</span>(edgeroi.sp, edgeroi.grids)
ov2<span class="op">$</span>SOURCEID &lt;-<span class="st"> </span>edgeroi.sp<span class="op">$</span>SOURCEID
<span class="kw">str</span>(ov2)
<span class="co">#&gt; &#39;data.frame&#39;:    359 obs. of  7 variables:</span>
<span class="co">#&gt;  $ DEMSRT5 : num  208 199 203 202 195 201 198 210 190 195 ...</span>
<span class="co">#&gt;  $ TWISRT5 : num  19.8 19.9 19.7 19.3 19.3 19.7 19.5 19.6 19.6 19.2 ...</span>
<span class="co">#&gt;  $ PMTGEO5 : Factor w/ 7 levels &quot;Qd&quot;,&quot;Qrs&quot;,&quot;Qrt/Jp&quot;,..: 2 2 2 2 2 2 2 2 2 2 ...</span>
<span class="co">#&gt;  $ EV1MOD5 : num  -0.08 2.41 2.62 -0.39 -0.78 -0.75 1.14 5.16 -0.48 -0.84 ...</span>
<span class="co">#&gt;  $ EV2MOD5 : num  -2.47 -2.84 -2.43 5.2 1.27 -4.96 1.62 1.33 -2.66 1.01 ...</span>
<span class="co">#&gt;  $ EV3MOD5 : num  -1.59 -0.31 1.43 1.96 -0.44 2.47 -5.74 -6.78 2.29 -1.59 ...</span>
<span class="co">#&gt;  $ SOURCEID: Factor w/ 359 levels &quot;199_CAN_CP111_1&quot;,..: 1 2 3 4 5 6 7 8 9 10 ...</span></code></pre>
<p>Because we will run 3D modelling, we also need to add depth of horizons. We use a small function to assign depth values as the center depth of each horizon (as shown in figure below). Because we know where the horizons start and stop, we can copy the values of target variables two times so that the model knows at which depth values of properties change.</p>
<pre class="sourceCode r"><code class="sourceCode r">## Convert soil horizon data to x,y,d regression matrix for 3D modeling:
hor2xyd &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">U=</span><span class="st">&quot;UHDICM&quot;</span>, <span class="dt">L=</span><span class="st">&quot;LHDICM&quot;</span>, <span class="dt">treshold.T=</span><span class="dv">15</span>){
  x<span class="op">$</span>DEPTH &lt;-<span class="st"> </span>x[,U] <span class="op">+</span><span class="st"> </span>(x[,L] <span class="op">-</span><span class="st"> </span>x[,U])<span class="op">/</span><span class="dv">2</span>
  x<span class="op">$</span>THICK &lt;-<span class="st"> </span>x[,L] <span class="op">-</span><span class="st"> </span>x[,U]
  sel &lt;-<span class="st"> </span>x<span class="op">$</span>THICK <span class="op">&lt;</span><span class="st"> </span>treshold.T
  ## begin and end of the horizon:
  x1 &lt;-<span class="st"> </span>x[<span class="op">!</span>sel,]; x1<span class="op">$</span>DEPTH =<span class="st"> </span>x1[,L]
  x2 &lt;-<span class="st"> </span>x[<span class="op">!</span>sel,]; x2<span class="op">$</span>DEPTH =<span class="st"> </span>x1[,U]
  y &lt;-<span class="st"> </span><span class="kw">do.call</span>(rbind, <span class="kw">list</span>(x, x1, x2))
  <span class="kw">return</span>(y)
}</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hor-3d-scheme"></span>
<img src="figures/horizon_depths_for_3d_modeling_scheme.png" alt="Training points assigned to a soil profile with 3 horizons. Using the function from above, we assign a total of 7 training points i.e. about 2 times more training points than there are horizons." width="75%" />
<p class="caption">
Figure 6.6: Training points assigned to a soil profile with 3 horizons. Using the function from above, we assign a total of 7 training points i.e. about 2 times more training points than there are horizons.
</p>
</div>
<pre class="sourceCode r"><code class="sourceCode r">h2 &lt;-<span class="st"> </span><span class="kw">hor2xyd</span>(edgeroi<span class="op">$</span>horizons)
## regression matrix:
m2 &lt;-<span class="st"> </span>plyr<span class="op">::</span><span class="kw">join_all</span>(<span class="dt">dfs =</span> <span class="kw">list</span>(edgeroi<span class="op">$</span>sites, h2, ov2))
<span class="co">#&gt; Joining by: SOURCEID</span>
<span class="co">#&gt; Joining by: SOURCEID</span>
## spatial prediction model:
formulaStringP2 &lt;-<span class="st"> </span>ORCDRC <span class="op">~</span><span class="st"> </span>DEMSRT5<span class="op">+</span>TWISRT5<span class="op">+</span>PMTGEO5<span class="op">+</span>
<span class="st">                            </span>EV1MOD5<span class="op">+</span>EV2MOD5<span class="op">+</span>EV3MOD5<span class="op">+</span>DEPTH
mP2 &lt;-<span class="st"> </span>m2[<span class="kw">complete.cases</span>(m2[,<span class="kw">all.vars</span>(formulaStringP2)]),]</code></pre>
<p>Note that <code>DEPTH</code> is used as a covariate, which makes this model 3D as one can predict anywhere in 3D space. To improve random forest modelling, we use the caret package that tries to identify also the optimal <code>mtry</code> parameter i.e. based on the cross-validation performance:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)
ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">number=</span><span class="dv">5</span>, <span class="dt">repeats=</span><span class="dv">1</span>)
sel &lt;-<span class="st"> </span><span class="kw">sample.int</span>(<span class="kw">nrow</span>(mP2), <span class="dv">500</span>)
tr.ORCDRC.rf &lt;-<span class="st"> </span><span class="kw">train</span>(formulaStringP2, <span class="dt">data=</span>mP2[sel,], 
                      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">trControl =</span> ctrl, <span class="dt">tuneLength =</span> <span class="dv">3</span>)
tr.ORCDRC.rf
<span class="co">#&gt; Random Forest </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; 500 samples</span>
<span class="co">#&gt;   7 predictor</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; No pre-processing</span>
<span class="co">#&gt; Resampling: Cross-Validated (5 fold, repeated 1 times) </span>
<span class="co">#&gt; Summary of sample sizes: 400, 400, 400, 401, 399 </span>
<span class="co">#&gt; Resampling results across tuning parameters:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;   mtry  RMSE  Rsquared  MAE </span>
<span class="co">#&gt;    2    3.58  0.580     2.41</span>
<span class="co">#&gt;    7    3.14  0.630     2.04</span>
<span class="co">#&gt;   12    3.21  0.609     2.06</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; RMSE was used to select the optimal model using the smallest value.</span>
<span class="co">#&gt; The final value used for the model was mtry = 7.</span></code></pre>
<p>In this case, <code>mtry = 12</code> seems to achieve the best performance. Note that we sub-set the initial matrix to speed up fine-tuning of the parameters (otherwise the computing time could easily become too great). Next, we can fit the final model by using all data (this time we also turn cross-validation off):</p>
<pre class="sourceCode r"><code class="sourceCode r">ORCDRC.rf &lt;-<span class="st"> </span><span class="kw">train</span>(formulaStringP2, <span class="dt">data=</span>mP2, 
                   <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">mtry=</span><span class="dv">7</span>),
                   <span class="dt">trControl=</span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;none&quot;</span>))
w1 &lt;-<span class="st"> </span><span class="dv">100</span><span class="op">*</span><span class="kw">max</span>(tr.ORCDRC.rf<span class="op">$</span>results<span class="op">$</span>Rsquared)</code></pre>
<p>The variable importance plot indicates that DEPTH is by far the most important predictor:</p>
<div class="figure" style="text-align: center"><span id="fig:varimp-plot-edgeroi"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/varimp-plot-edgeroi-1.png" alt="Variable importance plot for predicting soil organic carbon content (ORC) in 3D." width="70%" />
<p class="caption">
Figure 6.7: Variable importance plot for predicting soil organic carbon content (ORC) in 3D.
</p>
</div>
<p>We can also try fitting models using the xgboost package and the cubist packages:</p>
<pre class="sourceCode r"><code class="sourceCode r">tr.ORCDRC.cb &lt;-<span class="st"> </span><span class="kw">train</span>(formulaStringP2, <span class="dt">data=</span>mP2[sel,], 
                      <span class="dt">method =</span> <span class="st">&quot;cubist&quot;</span>, <span class="dt">trControl =</span> ctrl, <span class="dt">tuneLength =</span> <span class="dv">3</span>)
ORCDRC.cb &lt;-<span class="st"> </span><span class="kw">train</span>(formulaStringP2, <span class="dt">data=</span>mP2, 
                   <span class="dt">method =</span> <span class="st">&quot;cubist&quot;</span>, 
                   <span class="dt">tuneGrid=</span><span class="kw">data.frame</span>(<span class="dt">committees =</span> <span class="dv">1</span>, <span class="dt">neighbors =</span> <span class="dv">0</span>),
                   <span class="dt">trControl=</span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;none&quot;</span>))
w2 &lt;-<span class="st"> </span><span class="dv">100</span><span class="op">*</span><span class="kw">max</span>(tr.ORCDRC.cb<span class="op">$</span>results<span class="op">$</span>Rsquared)
## &quot;XGBoost&quot; package:
ORCDRC.gb &lt;-<span class="st"> </span><span class="kw">train</span>(formulaStringP2, <span class="dt">data=</span>mP2, <span class="dt">method =</span> <span class="st">&quot;xgbTree&quot;</span>, <span class="dt">trControl=</span>ctrl)
w3 &lt;-<span class="st"> </span><span class="dv">100</span><span class="op">*</span><span class="kw">max</span>(ORCDRC.gb<span class="op">$</span>results<span class="op">$</span>Rsquared)
<span class="kw">c</span>(w1, w2, w3)
<span class="co">#&gt; [1] 63.0 65.9 66.6</span></code></pre>
<p>At the end of the statistical modelling process, we can merge the predictions by using the CV R-square estimates:</p>
<pre class="sourceCode r"><code class="sourceCode r">edgeroi.grids<span class="op">$</span>DEPTH =<span class="st"> </span><span class="fl">2.5</span>
edgeroi.grids<span class="op">$</span>Random_forest &lt;-<span class="st"> </span><span class="kw">predict</span>(ORCDRC.rf, edgeroi.grids<span class="op">@</span>data, <span class="dt">na.action =</span> na.pass) 
edgeroi.grids<span class="op">$</span>Cubist &lt;-<span class="st"> </span><span class="kw">predict</span>(ORCDRC.cb, edgeroi.grids<span class="op">@</span>data, <span class="dt">na.action =</span> na.pass)
edgeroi.grids<span class="op">$</span>XGBoost &lt;-<span class="st"> </span><span class="kw">predict</span>(ORCDRC.gb, edgeroi.grids<span class="op">@</span>data, <span class="dt">na.action =</span> na.pass)
edgeroi.grids<span class="op">$</span>ORCDRC_5cm &lt;-<span class="st"> </span>(edgeroi.grids<span class="op">$</span>Random_forest<span class="op">*</span>w1 <span class="op">+</span><span class="st"> </span>
<span class="st">                               </span>edgeroi.grids<span class="op">$</span>Cubist<span class="op">*</span>w2 <span class="op">+</span><span class="st"> </span>
<span class="st">                               </span>edgeroi.grids<span class="op">$</span>XGBoost<span class="op">*</span>w3)<span class="op">/</span>(w1<span class="op">+</span>w2<span class="op">+</span>w3)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:maps-soc-edgeroi"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/maps-soc-edgeroi-1.png" alt="Comparison of three MLA's and final ensemble prediction (ORCDRC 5cm) of soil organic carbon content for 2.5 cm depth." width="100%" />
<p class="caption">
Figure 6.8: Comparison of three MLA’s and final ensemble prediction (ORCDRC 5cm) of soil organic carbon content for 2.5 cm depth.
</p>
</div>
<p>The final plot shows that xgboost possibly over-predicts and that cubist possibly under-predicts values of <code>ORCDRC</code>, while random forest is somewhere in-between the two. Again, merged predictions are probably the safest option considering that all three MLA’s have similar measures of performance.</p>
<p>We can quickly test the overall performance using a script on github prepared for testing performance of merged predictions:</p>
<pre class="sourceCode r"><code class="sourceCode r">source_https &lt;-<span class="st"> </span><span class="cf">function</span>(url, ...) {
  <span class="kw">require</span>(RCurl)
  <span class="cf">if</span>(<span class="op">!</span><span class="kw">file.exists</span>(<span class="kw">paste0</span>(<span class="st">&quot;R/&quot;</span>, <span class="kw">basename</span>(url)))){
    <span class="kw">cat</span>(<span class="kw">getURL</span>(url, <span class="dt">followlocation =</span> <span class="ot">TRUE</span>,
               <span class="dt">cainfo =</span> <span class="kw">system.file</span>(<span class="st">&quot;CurlSSL&quot;</span>, <span class="st">&quot;cacert.pem&quot;</span>, <span class="dt">package =</span> <span class="st">&quot;RCurl&quot;</span>)), 
        <span class="dt">file =</span> <span class="kw">paste0</span>(<span class="st">&quot;R/&quot;</span>, <span class="kw">basename</span>(url)))
  }
  <span class="kw">source</span>(<span class="kw">paste0</span>(<span class="st">&quot;R/&quot;</span>, <span class="kw">basename</span>(url)))
}
wdir =<span class="st"> &quot;https://raw.githubusercontent.com/ISRICWorldSoil/SoilGrids250m/&quot;</span>
<span class="kw">source_https</span>(<span class="kw">paste0</span>(wdir, <span class="st">&quot;master/grids/cv/cv_functions.R&quot;</span>))
<span class="co">#&gt; Loading required package: RCurl</span>
<span class="co">#&gt; Loading required package: bitops</span></code></pre>
<p>We can hence run 5-fold cross validation:</p>
<pre class="sourceCode r"><code class="sourceCode r">mP2<span class="op">$</span>SOURCEID =<span class="st"> </span><span class="kw">paste</span>(mP2<span class="op">$</span>SOURCEID)
test.ORC &lt;-<span class="st"> </span><span class="kw">cv_numeric</span>(formulaStringP2, <span class="dt">rmatrix=</span>mP2, 
                       <span class="dt">nfold=</span><span class="dv">5</span>, <span class="dt">idcol=</span><span class="st">&quot;SOURCEID&quot;</span>, <span class="dt">Log=</span><span class="ot">TRUE</span>)
<span class="co">#&gt; Running 5-fold cross validation with model re-fitting method ranger ...</span>
<span class="co">#&gt; Subsetting observations by unique location</span>
<span class="co">#&gt; Loading required package: snowfall</span>
<span class="co">#&gt; Loading required package: snow</span>
<span class="co">#&gt; Warning in searchCommandline(parallel, cpus = cpus, type = type,</span>
<span class="co">#&gt; socketHosts = socketHosts, : Unknown option on commandline: --file</span>
<span class="co">#&gt; R Version:  R version 3.5.1 (2018-12-12)</span>
<span class="co">#&gt; snowfall 1.84-6.1 initialized (using snow 0.4-3): parallel execution on 2 CPUs.</span>
<span class="co">#&gt; Library plyr loaded.</span>
<span class="co">#&gt; Library plyr loaded in cluster.</span>
<span class="co">#&gt; Library ranger loaded.</span>
<span class="co">#&gt; Library ranger loaded in cluster.</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;ranger&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:randomForest&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     importance</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Stopping cluster</span>
<span class="kw">str</span>(test.ORC)
<span class="co">#&gt; List of 2</span>
<span class="co">#&gt;  $ CV_residuals:&#39;data.frame&#39;:    4972 obs. of  4 variables:</span>
<span class="co">#&gt;   ..$ Observed : num [1:4972] 6.5 5.1 4.9 3.3 2.2 ...</span>
<span class="co">#&gt;   ..$ Predicted: num [1:4972] 11.68 7.41 7.05 5.05 3.25 ...</span>
<span class="co">#&gt;   ..$ SOURCEID : chr [1:4972] &quot;399_EDGEROI_ed005_1&quot; &quot;399_EDGEROI_ed005_1&quot; &quot;399_EDGEROI_ed005_1&quot; &quot;399_EDGEROI_ed005_1&quot; ...</span>
<span class="co">#&gt;   ..$ fold     : int [1:4972] 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;  $ Summary     :&#39;data.frame&#39;:    1 obs. of  6 variables:</span>
<span class="co">#&gt;   ..$ ME          : num -0.117</span>
<span class="co">#&gt;   ..$ MAE         : num 2.18</span>
<span class="co">#&gt;   ..$ RMSE        : num 3.68</span>
<span class="co">#&gt;   ..$ R.squared   : num 0.558</span>
<span class="co">#&gt;   ..$ logRMSE     : num 0.496</span>
<span class="co">#&gt;   ..$ logR.squared: num 0.633</span></code></pre>
<p>Which shows that the R-squared based on cross-validation is about 65% i.e. the average error of predicting soil organic carbon content using ensemble method is about <span class="math inline">\(\pm 4\)</span> g/kg. The final observed-vs-predict plot shows that the model is unbiased and that the predictions generally match cross-validation points:</p>
<div class="figure" style="text-align: center"><span id="fig:plot-measured-predicted"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/plot-measured-predicted-1.png" alt="Predicted vs observed plot for soil organic carbon ML-based model (Edgeroi data set)." width="100%" />
<p class="caption">
Figure 6.9: Predicted vs observed plot for soil organic carbon ML-based model (Edgeroi data set).
</p>
</div>
</div>
<div id="ensemble-predictions-using-h2oensemble" class="section level3">
<h3><span class="header-section-number">6.1.5</span> Ensemble predictions using h2oEnsemble</h3>
<p>Ensemble models often outperform single models. There is certainly opportunity for increasing mapping accuracy by combining the power of 3–4 MLA’s. The h2o environment for ML offers automation of ensemble model fitting and predictions <span class="citation">(LeDell <a href="#ref-ledell2015scalable">2015</a>)</span>.</p>
<pre><code>#&gt; h2oEnsemble R package for H2O-3
#&gt; Version: 0.2.1
#&gt; Package created on 2017-08-02</code></pre>
<p>we first specify all learners (MLA methods) of interest:</p>
<pre class="sourceCode r"><code class="sourceCode r">k.f =<span class="st"> </span>dismo<span class="op">::</span><span class="kw">kfold</span>(mP2, <span class="dt">k=</span><span class="dv">4</span>)
<span class="kw">summary</span>(<span class="kw">as.factor</span>(k.f))
<span class="co">#&gt;    1    2    3    4 </span>
<span class="co">#&gt; 1243 1243 1243 1243</span>
## split data into training and validation:
edgeroi_v.hex =<span class="st"> </span><span class="kw">as.h2o</span>(mP2[k.f<span class="op">==</span><span class="dv">1</span>,], <span class="dt">destination_frame =</span> <span class="st">&quot;eberg_v.hex&quot;</span>)
edgeroi_t.hex =<span class="st"> </span><span class="kw">as.h2o</span>(mP2[<span class="op">!</span>k.f<span class="op">==</span><span class="dv">1</span>,], <span class="dt">destination_frame =</span> <span class="st">&quot;eberg_t.hex&quot;</span>)
learner &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;h2o.randomForest.wrapper&quot;</span>, <span class="st">&quot;h2o.gbm.wrapper&quot;</span>)
fit &lt;-<span class="st"> </span><span class="kw">h2o.ensemble</span>(<span class="dt">x =</span> <span class="kw">which</span>(<span class="kw">names</span>(m2) <span class="op">%in%</span><span class="st"> </span><span class="kw">all.vars</span>(formulaStringP2)[<span class="op">-</span><span class="dv">1</span>]), 
                    <span class="dt">y =</span> <span class="kw">which</span>(<span class="kw">names</span>(m2)<span class="op">==</span><span class="st">&quot;ORCDRC&quot;</span>), 
                    <span class="dt">training_frame =</span> edgeroi_t.hex, <span class="dt">learner =</span> learner, 
                    <span class="dt">cvControl =</span> <span class="kw">list</span>(<span class="dt">V =</span> <span class="dv">5</span>))
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 1: h2o.randomForest.wrapper&quot;</span>
<span class="co">#&gt; Warning in h2o.randomForest(x = x, y = y, training_frame =</span>
<span class="co">#&gt; training_frame, : Argument offset_column is deprecated and has no use for</span>
<span class="co">#&gt; Random Forest.</span>
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 2: h2o.gbm.wrapper&quot;</span>
<span class="co">#&gt; [1] &quot;Metalearning&quot;</span>
perf &lt;-<span class="st"> </span><span class="kw">h2o.ensemble_performance</span>(fit, <span class="dt">newdata =</span> edgeroi_v.hex)
<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>
<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>
perf
<span class="co">#&gt; </span>
<span class="co">#&gt; Base learner performance, sorted by specified metric:</span>
<span class="co">#&gt;                    learner  MSE</span>
<span class="co">#&gt; 1 h2o.randomForest.wrapper 13.1</span>
<span class="co">#&gt; 2          h2o.gbm.wrapper 12.8</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2O Ensemble Performance on &lt;newdata&gt;:</span>
<span class="co">#&gt; ----------------</span>
<span class="co">#&gt; Family: gaussian</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Ensemble performance (MSE): 12.5814277895713</span></code></pre>
<p>which shows that, in this specific case, the ensemble model is only slightly better than a single model. Note that we would need to repeat testing the ensemble modeling several times until we can be certain any actual actual gain in accuracy.</p>
<p>We can also test ensemble predictions using the cookfarm data set <span class="citation">(Gasch et al. <a href="#ref-Gasch2015SPASTA">2015</a>)</span>. This data set consists of 183 profiles, each consisting of multiple soil horizons (1050 in total). To create a regression matrix we use:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(cookfarm)
cookfarm.hor &lt;-<span class="st"> </span>cookfarm<span class="op">$</span>profiles
<span class="kw">str</span>(cookfarm.hor)
<span class="co">#&gt; &#39;data.frame&#39;:    1050 obs. of  9 variables:</span>
<span class="co">#&gt;  $ SOURCEID: Factor w/ 369 levels &quot;CAF001&quot;,&quot;CAF002&quot;,..: 3 3 3 3 3 5 5 5 5 5 ...</span>
<span class="co">#&gt;  $ Easting : num  493383 493383 493383 493383 493383 ...</span>
<span class="co">#&gt;  $ Northing: num  5180586 5180586 5180586 5180586 5180586 ...</span>
<span class="co">#&gt;  $ TAXSUSDA: Factor w/ 6 levels &quot;Caldwell&quot;,&quot;Latah&quot;,..: 3 3 3 3 3 4 4 4 4 4 ...</span>
<span class="co">#&gt;  $ HZDUSD  : Factor w/ 67 levels &quot;2R&quot;,&quot;A&quot;,&quot;A1&quot;,..: 12 2 7 35 36 12 2 16 43 44 ...</span>
<span class="co">#&gt;  $ UHDICM  : num  0 21 39 65 98 0 17 42 66 97 ...</span>
<span class="co">#&gt;  $ LHDICM  : num  21 39 65 98 153 17 42 66 97 153 ...</span>
<span class="co">#&gt;  $ BLD     : num  1.46 1.37 1.52 1.72 1.72 1.56 1.33 1.36 1.37 1.48 ...</span>
<span class="co">#&gt;  $ PHIHOX  : num  4.69 5.9 6.25 6.54 6.75 4.12 5.73 6.26 6.59 6.85 ...</span>
cookfarm.hor<span class="op">$</span>depth &lt;-<span class="st"> </span>cookfarm.hor<span class="op">$</span>UHDICM <span class="op">+</span>
<span class="st">  </span>(cookfarm.hor<span class="op">$</span>LHDICM <span class="op">-</span><span class="st"> </span>cookfarm.hor<span class="op">$</span>UHDICM)<span class="op">/</span><span class="dv">2</span>
sel.id &lt;-<span class="st"> </span><span class="op">!</span><span class="kw">duplicated</span>(cookfarm.hor<span class="op">$</span>SOURCEID)
cookfarm.xy &lt;-<span class="st"> </span>cookfarm.hor[sel.id,<span class="kw">c</span>(<span class="st">&quot;SOURCEID&quot;</span>,<span class="st">&quot;Easting&quot;</span>,<span class="st">&quot;Northing&quot;</span>)]
<span class="kw">str</span>(cookfarm.xy)
<span class="co">#&gt; &#39;data.frame&#39;:    183 obs. of  3 variables:</span>
<span class="co">#&gt;  $ SOURCEID: Factor w/ 369 levels &quot;CAF001&quot;,&quot;CAF002&quot;,..: 3 5 7 9 11 13 15 17 19 21 ...</span>
<span class="co">#&gt;  $ Easting : num  493383 493447 493511 493575 493638 ...</span>
<span class="co">#&gt;  $ Northing: num  5180586 5180572 5180568 5180573 5180571 ...</span>
<span class="kw">coordinates</span>(cookfarm.xy) &lt;-<span class="st"> </span><span class="er">~</span><span class="st"> </span>Easting <span class="op">+</span><span class="st"> </span>Northing
grid10m &lt;-<span class="st"> </span>cookfarm<span class="op">$</span>grids
<span class="kw">coordinates</span>(grid10m) &lt;-<span class="st"> </span><span class="er">~</span><span class="st"> </span>x <span class="op">+</span><span class="st"> </span>y
<span class="kw">gridded</span>(grid10m) =<span class="st"> </span><span class="ot">TRUE</span>
ov.cf &lt;-<span class="st"> </span><span class="kw">over</span>(cookfarm.xy, grid10m)
rm.cookfarm &lt;-<span class="st"> </span>plyr<span class="op">::</span><span class="kw">join</span>(cookfarm.hor, <span class="kw">cbind</span>(cookfarm.xy<span class="op">@</span>data, ov.cf))
<span class="co">#&gt; Joining by: SOURCEID</span></code></pre>
<p>Here, we are interested in predicting soil pH in 3D, hence we will use a model of form:</p>
<pre class="sourceCode r"><code class="sourceCode r">fm.PHI &lt;-<span class="st"> </span>PHIHOX<span class="op">~</span>DEM<span class="op">+</span>TWI<span class="op">+</span>NDRE.M<span class="op">+</span>Cook_fall_ECa<span class="op">+</span>Cook_spr_ECa<span class="op">+</span>depth
rc &lt;-<span class="st"> </span><span class="kw">complete.cases</span>(rm.cookfarm[,<span class="kw">all.vars</span>(fm.PHI)])
mP3 &lt;-<span class="st"> </span>rm.cookfarm[rc,<span class="kw">all.vars</span>(fm.PHI)]
<span class="kw">str</span>(mP3)
<span class="co">#&gt; &#39;data.frame&#39;:    997 obs. of  7 variables:</span>
<span class="co">#&gt;  $ PHIHOX       : num  4.69 5.9 6.25 6.54 6.75 4.12 5.73 6.26 6.59 6.85 ...</span>
<span class="co">#&gt;  $ DEM          : num  788 788 788 788 788 ...</span>
<span class="co">#&gt;  $ TWI          : num  4.3 4.3 4.3 4.3 4.3 ...</span>
<span class="co">#&gt;  $ NDRE.M       : num  -0.0512 -0.0512 -0.0512 -0.0512 -0.0512 ...</span>
<span class="co">#&gt;  $ Cook_fall_ECa: num  7.7 7.7 7.7 7.7 7.7 ...</span>
<span class="co">#&gt;  $ Cook_spr_ECa : num  33 33 33 33 33 ...</span>
<span class="co">#&gt;  $ depth        : num  10.5 30 52 81.5 125.5 ...</span></code></pre>
<p>We can again test fitting an ensemble model using two MLA’s:</p>
<pre class="sourceCode r"><code class="sourceCode r">k.f3 &lt;-<span class="st"> </span>dismo<span class="op">::</span><span class="kw">kfold</span>(mP3, <span class="dt">k=</span><span class="dv">4</span>)
## split data into training and validation:
cookfarm_v.hex &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(mP3[k.f3<span class="op">==</span><span class="dv">1</span>,], <span class="dt">destination_frame =</span> <span class="st">&quot;cookfarm_v.hex&quot;</span>)
cookfarm_t.hex &lt;-<span class="st"> </span><span class="kw">as.h2o</span>(mP3[<span class="op">!</span>k.f3<span class="op">==</span><span class="dv">1</span>,], <span class="dt">destination_frame =</span> <span class="st">&quot;cookfarm_t.hex&quot;</span>)
learner3 =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;h2o.glm.wrapper&quot;</span>, <span class="st">&quot;h2o.randomForest.wrapper&quot;</span>,
            <span class="st">&quot;h2o.gbm.wrapper&quot;</span>, <span class="st">&quot;h2o.deeplearning.wrapper&quot;</span>)
fit3 &lt;-<span class="st"> </span><span class="kw">h2o.ensemble</span>(<span class="dt">x =</span> <span class="kw">which</span>(<span class="kw">names</span>(mP3) <span class="op">%in%</span><span class="st"> </span><span class="kw">all.vars</span>(fm.PHI)[<span class="op">-</span><span class="dv">1</span>]), 
                    <span class="dt">y =</span> <span class="kw">which</span>(<span class="kw">names</span>(mP3)<span class="op">==</span><span class="st">&quot;PHIHOX&quot;</span>), 
                    <span class="dt">training_frame =</span> cookfarm_t.hex, <span class="dt">learner =</span> learner3, 
                    <span class="dt">cvControl =</span> <span class="kw">list</span>(<span class="dt">V =</span> <span class="dv">5</span>))
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 1: h2o.glm.wrapper&quot;</span>
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 2: h2o.randomForest.wrapper&quot;</span>
<span class="co">#&gt; Warning in h2o.randomForest(x = x, y = y, training_frame =</span>
<span class="co">#&gt; training_frame, : Argument offset_column is deprecated and has no use for</span>
<span class="co">#&gt; Random Forest.</span>
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 3: h2o.gbm.wrapper&quot;</span>
<span class="co">#&gt; [1] &quot;Cross-validating and training base learner 4: h2o.deeplearning.wrapper&quot;</span>
<span class="co">#&gt; [1] &quot;Metalearning&quot;</span>
perf3 &lt;-<span class="st"> </span><span class="kw">h2o.ensemble_performance</span>(fit3, <span class="dt">newdata =</span> cookfarm_v.hex)
<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>
<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>

<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>

<span class="co">#&gt; Warning in doTryCatch(return(expr), name, parentenv, handler): Test/</span>
<span class="co">#&gt; Validation dataset is missing column &#39;fold_id&#39;: substituting in a column of</span>
<span class="co">#&gt; 0.0</span>
perf3
<span class="co">#&gt; </span>
<span class="co">#&gt; Base learner performance, sorted by specified metric:</span>
<span class="co">#&gt;                    learner    MSE</span>
<span class="co">#&gt; 1          h2o.glm.wrapper 0.2827</span>
<span class="co">#&gt; 4 h2o.deeplearning.wrapper 0.1506</span>
<span class="co">#&gt; 3          h2o.gbm.wrapper 0.0971</span>
<span class="co">#&gt; 2 h2o.randomForest.wrapper 0.0786</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; H2O Ensemble Performance on &lt;newdata&gt;:</span>
<span class="co">#&gt; ----------------</span>
<span class="co">#&gt; Family: gaussian</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Ensemble performance (MSE): 0.0767331223023685</span></code></pre>
<p>In this case Ensemble performance (MSE) seems to be <em>as bad</em> as the single best spatial predictor (random forest in this case). This illustrates that ensemble predictions are sometimes not beneficial.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">h2o.shutdown</span>()
<span class="co">#&gt; Are you sure you want to shutdown the H2O instance running at http://localhost:54321/ (Y/N)?</span></code></pre>
</div>
<div id="ensemble-predictions-using-superlearner-package" class="section level3">
<h3><span class="header-section-number">6.1.6</span> Ensemble predictions using SuperLearner package</h3>
<p>Another interesting package to generate ensemble predictions of soil properties and classes is the SuperLearner package <span class="citation">(Polley and Van Der Laan <a href="#ref-polley2010super">2010</a>)</span>. This package has many more options than <code>h2o.ensemble</code> considering the number of methods available for consideration:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(SuperLearner)
<span class="co">#&gt; Loading required package: nnls</span>
<span class="co">#&gt; Super Learner</span>
<span class="co">#&gt; Version: 2.0-24</span>
<span class="co">#&gt; Package created on 2018-08-10</span>
<span class="co"># List available models:</span>
<span class="kw">listWrappers</span>()
<span class="co">#&gt; All prediction algorithm wrappers in SuperLearner:</span>
<span class="co">#&gt;  [1] &quot;SL.bartMachine&quot;      &quot;SL.bayesglm&quot;         &quot;SL.biglasso&quot;        </span>
<span class="co">#&gt;  [4] &quot;SL.caret&quot;            &quot;SL.caret.rpart&quot;      &quot;SL.cforest&quot;         </span>
<span class="co">#&gt;  [7] &quot;SL.dbarts&quot;           &quot;SL.earth&quot;            &quot;SL.extraTrees&quot;      </span>
<span class="co">#&gt; [10] &quot;SL.gam&quot;              &quot;SL.gbm&quot;              &quot;SL.glm&quot;             </span>
<span class="co">#&gt; [13] &quot;SL.glm.interaction&quot;  &quot;SL.glmnet&quot;           &quot;SL.ipredbagg&quot;       </span>
<span class="co">#&gt; [16] &quot;SL.kernelKnn&quot;        &quot;SL.knn&quot;              &quot;SL.ksvm&quot;            </span>
<span class="co">#&gt; [19] &quot;SL.lda&quot;              &quot;SL.leekasso&quot;         &quot;SL.lm&quot;              </span>
<span class="co">#&gt; [22] &quot;SL.loess&quot;            &quot;SL.logreg&quot;           &quot;SL.mean&quot;            </span>
<span class="co">#&gt; [25] &quot;SL.nnet&quot;             &quot;SL.nnls&quot;             &quot;SL.polymars&quot;        </span>
<span class="co">#&gt; [28] &quot;SL.qda&quot;              &quot;SL.randomForest&quot;     &quot;SL.ranger&quot;          </span>
<span class="co">#&gt; [31] &quot;SL.ridge&quot;            &quot;SL.rpart&quot;            &quot;SL.rpartPrune&quot;      </span>
<span class="co">#&gt; [34] &quot;SL.speedglm&quot;         &quot;SL.speedlm&quot;          &quot;SL.step&quot;            </span>
<span class="co">#&gt; [37] &quot;SL.step.forward&quot;     &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot;         </span>
<span class="co">#&gt; [40] &quot;SL.svm&quot;              &quot;SL.template&quot;         &quot;SL.xgboost&quot;</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; All screening algorithm wrappers in SuperLearner:</span>
<span class="co">#&gt; [1] &quot;All&quot;</span>
<span class="co">#&gt; [1] &quot;screen.corP&quot;           &quot;screen.corRank&quot;        &quot;screen.glmnet&quot;        </span>
<span class="co">#&gt; [4] &quot;screen.randomForest&quot;   &quot;screen.SIS&quot;            &quot;screen.template&quot;      </span>
<span class="co">#&gt; [7] &quot;screen.ttest&quot;          &quot;write.screen.template&quot;</span></code></pre>
<p>where <code>SL.</code> refers to an imported method from a package e.g. <code>&quot;SL.ranger&quot;</code> is the SuperLearner method from the package ranger.</p>
<p>A useful functionality of the SuperLearner package is that it displays how model average weights are estimated and which methods can safely be excluded from predictions. When using SuperLearner, however, it is highly recommended to use the parallelized / multicore version, otherwise the computing time might be quite extensive. For example, to prepare ensemble predictions using the five standard prediction techniques used in this tutorial we would run:</p>
<pre class="sourceCode r"><code class="sourceCode r">## detach snowfall package otherwise possible conflicts
<span class="co">#detach(&quot;package:snowfall&quot;, unload=TRUE)</span>
<span class="kw">library</span>(parallel)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;parallel&#39;</span>
<span class="co">#&gt; The following objects are masked from &#39;package:snow&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,</span>
<span class="co">#&gt;     clusterExport, clusterMap, clusterSplit, makeCluster,</span>
<span class="co">#&gt;     parApply, parCapply, parLapply, parRapply, parSapply,</span>
<span class="co">#&gt;     splitIndices, stopCluster</span>
sl.l =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.mean&quot;</span>, <span class="st">&quot;SL.xgboost&quot;</span>, <span class="st">&quot;SL.ksvm&quot;</span>, <span class="st">&quot;SL.glmnet&quot;</span>, <span class="st">&quot;SL.ranger&quot;</span>)
cl &lt;-<span class="st"> </span>parallel<span class="op">::</span><span class="kw">makeCluster</span>(<span class="kw">detectCores</span>())
x &lt;-<span class="st"> </span>parallel<span class="op">::</span><span class="kw">clusterEvalQ</span>(cl, <span class="kw">library</span>(SuperLearner))
sl &lt;-<span class="st"> </span><span class="kw">snowSuperLearner</span>(<span class="dt">Y =</span> mP3<span class="op">$</span>PHIHOX, 
                       <span class="dt">X =</span> mP3[,<span class="kw">all.vars</span>(fm.PHI)[<span class="op">-</span><span class="dv">1</span>]],
                       <span class="dt">cluster =</span> cl, 
                       <span class="dt">SL.library =</span> sl.l)
<span class="co">#&gt; Loading required package: glmnet</span>
<span class="co">#&gt; Loading required package: Matrix</span>
<span class="co">#&gt; Loading required package: foreach</span>
<span class="co">#&gt; Loaded glmnet 2.0-16</span>
sl
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  </span>
<span class="co">#&gt; snowSuperLearner(cluster = cl, Y = mP3$PHIHOX, X = mP3[, all.vars(fm.PHI)[-1]],  </span>
<span class="co">#&gt;     SL.library = sl.l) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                  Risk   Coef</span>
<span class="co">#&gt; SL.mean_All    0.7540 0.0000</span>
<span class="co">#&gt; SL.xgboost_All 0.0598 0.8127</span>
<span class="co">#&gt; SL.ksvm_All    0.1289 0.0105</span>
<span class="co">#&gt; SL.glmnet_All  0.3080 0.0000</span>
<span class="co">#&gt; SL.ranger_All  0.0850 0.1768</span></code></pre>
<p>This shows that <code>SL.xgboost_All</code> outperforms the competition by a large margin. Since this is a relatively small data set, RMSE produced by <code>SL.xgboost_All</code> is probably unrealistically small. If we only use the top three models (XGboost, ranger and ksvm) in comparison we get:</p>
<pre class="sourceCode r"><code class="sourceCode r">sl.l2 =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;SL.xgboost&quot;</span>, <span class="st">&quot;SL.ranger&quot;</span>, <span class="st">&quot;SL.ksvm&quot;</span>)
sl2 &lt;-<span class="st"> </span><span class="kw">snowSuperLearner</span>(<span class="dt">Y =</span> mP3<span class="op">$</span>PHIHOX, 
                       <span class="dt">X =</span> mP3[,<span class="kw">all.vars</span>(fm.PHI)[<span class="op">-</span><span class="dv">1</span>]],
                       <span class="dt">cluster =</span> cl, 
                       <span class="dt">SL.library =</span> sl.l2)
sl2
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  </span>
<span class="co">#&gt; snowSuperLearner(cluster = cl, Y = mP3$PHIHOX, X = mP3[, all.vars(fm.PHI)[-1]],  </span>
<span class="co">#&gt;     SL.library = sl.l2) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                  Risk  Coef</span>
<span class="co">#&gt; SL.xgboost_All 0.0603 0.813</span>
<span class="co">#&gt; SL.ranger_All  0.0834 0.187</span>
<span class="co">#&gt; SL.ksvm_All    0.1308 0.000</span></code></pre>
<p>again <code>SL.xgboost</code> dominates the ensemble model, which is most likely unrealistic because most of the training data is spatially clustered and hence XGboost is probably over-fitting. To estimate actual accuracy of predicting soil pH using these two techniques we can run cross-validation where entire profiles are taken out of the training dataset:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(rm.cookfarm<span class="op">$</span>SOURCEID)
<span class="co">#&gt;  Factor w/ 369 levels &quot;CAF001&quot;,&quot;CAF002&quot;,..: 3 3 3 3 3 5 5 5 5 5 ...</span>
cv_sl &lt;-<span class="st"> </span><span class="kw">CV.SuperLearner</span>(<span class="dt">Y =</span> mP3<span class="op">$</span>PHIHOX, 
                       <span class="dt">X =</span> mP3[,<span class="kw">all.vars</span>(fm.PHI)[<span class="op">-</span><span class="dv">1</span>]],
                       <span class="dt">parallel =</span> cl, 
                       <span class="dt">SL.library =</span> sl.l2, 
                       <span class="dt">V=</span><span class="dv">5</span>, <span class="dt">id=</span>rm.cookfarm<span class="op">$</span>SOURCEID[rc], 
                       <span class="dt">verbose=</span><span class="ot">TRUE</span>)
<span class="kw">summary</span>(cv_sl)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  </span>
<span class="co">#&gt; CV.SuperLearner(Y = mP3$PHIHOX, X = mP3[, all.vars(fm.PHI)[-1]], V = 5,  </span>
<span class="co">#&gt;     SL.library = sl.l2, id = rm.cookfarm$SOURCEID[rc], verbose = TRUE,  </span>
<span class="co">#&gt;     parallel = cl) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Risk is based on: Mean Squared Error</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; All risk estimates are based on V =  5 </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;       Algorithm  Ave    se   Min  Max</span>
<span class="co">#&gt;   Super Learner 0.16 0.014 0.095 0.26</span>
<span class="co">#&gt;     Discrete SL 0.17 0.014 0.117 0.25</span>
<span class="co">#&gt;  SL.xgboost_All 0.19 0.016 0.135 0.27</span>
<span class="co">#&gt;   SL.ranger_All 0.16 0.015 0.103 0.25</span>
<span class="co">#&gt;     SL.ksvm_All 0.18 0.015 0.109 0.30</span></code></pre>
<p>where <code>V=5</code> specifies number of folds, and <code>id=rm.cookfarm$SOURCEID</code> forces that entire profiles are removed from training and cross-validation. This gives a more realistic RMSE of about ±0.35. Note that this time <code>SL.xgboost_All</code> is even somewhat worse than the random forest model, and the ensemble model (<code>Super Learner</code>) is slightly better than each individual model. This matches our previous results with <code>h20.ensemble</code>.</p>
<p>To produce predictions of soil pH at 10 cm depth we can finally use:</p>
<pre class="sourceCode r"><code class="sourceCode r">sl2 &lt;-<span class="st"> </span><span class="kw">snowSuperLearner</span>(<span class="dt">Y =</span> mP3<span class="op">$</span>PHIHOX, 
                       <span class="dt">X =</span> mP3[,<span class="kw">all.vars</span>(fm.PHI)[<span class="op">-</span><span class="dv">1</span>]],
                       <span class="dt">cluster =</span> cl, 
                       <span class="dt">SL.library =</span> sl.l2,
                       <span class="dt">id=</span>rm.cookfarm<span class="op">$</span>SOURCEID[rc],
                       <span class="dt">cvControl=</span><span class="kw">list</span>(<span class="dt">V=</span><span class="dv">5</span>))
sl2
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:  </span>
<span class="co">#&gt; snowSuperLearner(cluster = cl, Y = mP3$PHIHOX, X = mP3[, all.vars(fm.PHI)[-1]],  </span>
<span class="co">#&gt;     SL.library = sl.l2, id = rm.cookfarm$SOURCEID[rc], cvControl = list(V = 5)) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; </span>
<span class="co">#&gt;                 Risk  Coef</span>
<span class="co">#&gt; SL.xgboost_All 0.215 0.000</span>
<span class="co">#&gt; SL.ranger_All  0.164 0.478</span>
<span class="co">#&gt; SL.ksvm_All    0.163 0.522</span>
new.data &lt;-<span class="st"> </span>grid10m<span class="op">@</span>data
pred.PHI &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="ot">NULL</span>)
depths =<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">30</span>,<span class="dv">50</span>,<span class="dv">70</span>,<span class="dv">90</span>)
<span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(depths)){
  new.data<span class="op">$</span>depth =<span class="st"> </span>depths[j]
  pred.PHI[[j]] &lt;-<span class="st"> </span><span class="kw">predict</span>(sl2, new.data[,sl2<span class="op">$</span>varNames])
}
<span class="co">#&gt; Loading required package: kernlab</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;kernlab&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:scales&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     alpha</span>
<span class="co">#&gt; The following object is masked from &#39;package:ggplot2&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     alpha</span>
<span class="co">#&gt; The following objects are masked from &#39;package:raster&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     buffer, rotated</span>
<span class="kw">str</span>(pred.PHI[[<span class="dv">1</span>]])
<span class="co">#&gt; List of 2</span>
<span class="co">#&gt;  $ pred           : num [1:3865, 1] 4.67 4.75 4.87 4.84 4.77 ...</span>
<span class="co">#&gt;  $ library.predict: num [1:3865, 1:3] 4.15 4.11 4.45 4.75 4.78 ...</span>
<span class="co">#&gt;   ..- attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   .. ..$ : NULL</span>
<span class="co">#&gt;   .. ..$ : chr [1:3] &quot;SL.xgboost_All&quot; &quot;SL.ranger_All&quot; &quot;SL.ksvm_All&quot;</span></code></pre>
<p>this yields two outputs:</p>
<ul>
<li>ensemble prediction in the <code>pred</code> matrix,</li>
<li>list of individual predictions in the <code>library.predict</code> matrix,</li>
</ul>
<p>To visualize the predictions (at six depths) we can run:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="cf">for</span>(j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(depths)){
  grid10m<span class="op">@</span>data[,<span class="kw">paste0</span>(<span class="st">&quot;PHI.&quot;</span>, depths[j],<span class="st">&quot;cm&quot;</span>)] &lt;-<span class="st"> </span>pred.PHI[[j]]<span class="op">$</span>pred[,<span class="dv">1</span>]
}
<span class="kw">spplot</span>(grid10m, <span class="kw">paste0</span>(<span class="st">&quot;PHI.&quot;</span>, depths,<span class="st">&quot;cm&quot;</span>), 
       <span class="dt">col.regions=</span>R_pal[[<span class="st">&quot;pH_pal&quot;</span>]], <span class="dt">as.table=</span><span class="ot">TRUE</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ph-cookfarm"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/ph-cookfarm-1.png" alt="Predicted soil pH using 3D ensemble model." width="100%" />
<p class="caption">
Figure 6.10: Predicted soil pH using 3D ensemble model.
</p>
</div>
<p>The second prediction matrix can be used to determine <em>model uncertainty</em>:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(matrixStats)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: &#39;matrixStats&#39;</span>
<span class="co">#&gt; The following object is masked from &#39;package:plyr&#39;:</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     count</span>
grid10m<span class="op">$</span>PHI<span class="fl">.10</span>cm.sd &lt;-<span class="st"> </span><span class="kw">rowSds</span>(pred.PHI[[<span class="dv">1</span>]]<span class="op">$</span>library.predict, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
pts =<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;sp.points&quot;</span>, cookfarm.xy, <span class="dt">pch=</span><span class="st">&quot;+&quot;</span>, <span class="dt">col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">cex=</span><span class="fl">1.4</span>)
<span class="kw">spplot</span>(grid10m, <span class="st">&quot;PHI.10cm.sd&quot;</span>, <span class="dt">sp.layout =</span> <span class="kw">list</span>(pts), <span class="dt">col.regions=</span><span class="kw">rev</span>(<span class="kw">bpy.colors</span>()))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ph-cookfarm-var"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/ph-cookfarm-var-1.png" alt="Example of variance of prediction models for soil pH." width="100%" />
<p class="caption">
Figure 6.11: Example of variance of prediction models for soil pH.
</p>
</div>
<p>which highlights the especially problematic areas, in this case most likely correlated with extrapolation in feature space. Before we stop computing, we need to close the cluster session by using:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">stopCluster</span>(cl)</code></pre>
</div>
</div>
<div id="a-generic-framework-for-spatial-prediction-using-random-forest" class="section level2">
<h2><span class="header-section-number">6.2</span> A generic framework for spatial prediction using Random Forest</h2>
<p>We have seen, in the above examples, that MLA’s can be used efficiently to
map soil properties and classes. Most currently used MLA’s, however, ignore the spatial
locations of the observations and hence overlook any spatial autocorrelation in
the data not accounted for by the covariates. Spatial auto-correlation,
especially if it remains visible in the cross-validation residuals, indicates
that the predictions are perhaps biased, and this is sub-optimal.
To account for this, <span class="citation">T. Hengl, Nussbaum, et al. (<a href="#ref-Hengl2018RFsp">2018</a>)</span> describe a framework for using Random Forest
(as implemented in the ranger package) in combination with geographical
distances to sampling locations (which provide measures of relative spatial location)
to fit models and predict values (RFsp).</p>
<div id="general-principle-of-rfsp" class="section level3">
<h3><span class="header-section-number">6.2.1</span> General principle of RFsp</h3>
<p>RF is, in essence, a non-spatial approach to spatial prediction, as
the sampling locations and general sampling pattern are both ignored during
the estimation of MLA model parameters. This can potentially lead to
sub-optimal predictions and possibly systematic over- or
under-prediction, especially where the spatial autocorrelation in the
target variable is high and where point patterns show clear sampling
bias. To overcome this problem <span class="citation">T. Hengl, Nussbaum, et al. (<a href="#ref-Hengl2018RFsp">2018</a>)</span> propose the following generic <em>“RFsp”</em>
system:</p>

<p>where <span class="math inline">\({{\bf X}_G}\)</span> are covariates accounting for geographical proximity
and spatial relations between observations (to mimic spatial correlation
used in kriging):</p>

<p>where <span class="math inline">\(d_{pi}\)</span> is the buffer distance (or any other complex proximity
upslope/downslope distance, as explained in the next section) to the
observed location <span class="math inline">\(pi\)</span> from <span class="math inline">\({\bf s}\)</span> and <span class="math inline">\(N\)</span> is the total number of
training points. <span class="math inline">\({{\bf X}_R}\)</span> are surface reflectance covariates,
i.e. usually spectral bands of remote sensing images, and <span class="math inline">\({{\bf X}_P}\)</span> are
process-based covariates. For example, the Landsat infrared band is a
surface reflectance covariate, while the topographic wetness index and
soil weathering index are process-based covariates. Geographic
covariates are often smooth and reflect geometric composition of points,
reflectance-based covariates can exhibit a significant amount of noise and
usually provide information only about the surface of objects. Process-based
covariates require specialized knowledge and rethinking of how to
best represent processes. Assuming that the RFsp is fitted only using the
<span class="math inline">\({\bf {X}_G}\)</span>, the predictions would resemble ordinary kriging (OK). If All covariates are
used Eq. <a href="#eq:rf-BUGP">(<strong>??</strong>)</a>, RFsp would resemble regression-kriging (RK).</p>
</div>
<div id="geographical-covariates" class="section level3">
<h3><span class="header-section-number">6.2.2</span> Geographical covariates</h3>
<p>One of the key principles of geography is that <em>“everything is related
to everything else, but near things are more related than distant
things”</em> <span class="citation">(Miller <a href="#ref-miller2004tobler">2004</a>)</span>. This principle forms the basis of
geostatistics, which converts this rule into a mathematical model, i.e.,
through spatial autocorrelation functions or variograms. The key to
making RF applicable to spatial statistics problems, therefore, lies also in
preparing geographical (spatial) measures of proximity and connectivity between
observations, so that spatial autocorrelation is accounted for. There
are multiple options for variables that quantify proximity and geographical
connection (Fig. <a href="soilmapping-using-mla.html#fig:distances-examples">6.12</a>):</p>
<ol style="list-style-type: decimal">
<li><p>Geographical coordinates <span class="math inline">\(s_1\)</span> and <span class="math inline">\(s_2\)</span>, i.e., easting
and northing.</p></li>
<li><p>Euclidean distances to reference points in the study area. For
example, distance to the center and edges of the study area, etc.</p></li>
<li><p>Euclidean distances to sampling locations, i.e., distances from
observation locations. Here one buffer distance map can be generated
per observation point or group of points. These are also the same distance
measures as used in geostatistics.</p></li>
<li><p>Downslope distances, i.e., distances within a watershed: for each
sampling point one can derive upslope/downslope distances to the
ridges and hydrological network and/or downslope or upslope areas
<span class="citation">(Gruber and Peckham <a href="#ref-GRUBER2009171">2009</a>)</span>. This requires, in addition to using a Digital Elevation
Model, implementing a hydrological analysis of the terrain.</p></li>
<li><p>Resistance distances or weighted buffer distances, i.e., distances
of the cumulative effort derived using terrain ruggedness and/or
natural obstacles.</p></li>
</ol>
<p>The package (<strong><em>WHICH PACKAGE?</em></strong>), for example, provides a framework to derive complex
distances based on terrain complexity <span class="citation">(van Etten <a href="#ref-vanEtten2017r">2017</a>)</span>. Here additional
inputs required to compute complex distances are the Digital Elevation Model (DEM)
and DEM-derivatives, such as slope (Fig. <a href="soilmapping-using-mla.html#fig:distances-examples">6.12</a>b).
SAGA GIS <span class="citation">(Conrad et al. <a href="#ref-gmd-8-1991-2015">2015</a>)</span> offers a wide variety of DEM derivatives
that can be derived per location of interest.</p>
<div class="figure" style="text-align: center"><span id="fig:distances-examples"></span>
<img src="figures/Fig_distances_examples.png" alt="Examples of distance maps to some location in space (yellow dot) based on different derivation algorithms: (a) simple Euclidean distances, (b) complex speed-based distances based on the package and Digital Elevation Model (DEM), and (c) upslope area derived based on the DEM in SAGA GIS. Image source: Hengl et al. (2018) doi: 10.7717/peerj.5518." width="100%" />
<p class="caption">
Figure 6.12: Examples of distance maps to some location in space (yellow dot) based on different derivation algorithms: (a) simple Euclidean distances, (b) complex speed-based distances based on the package and Digital Elevation Model (DEM), and (c) upslope area derived based on the DEM in SAGA GIS. Image source: Hengl et al. (2018) doi: 10.7717/peerj.5518.
</p>
</div>
<p>Here, we only illustrate predictive performance using Euclidean buffer distances
(to all sampling points), but the code could be adopted to
include other families of geographical covariates (as shown in
Fig. <a href="soilmapping-using-mla.html#fig:distances-examples">6.12</a>). Note also that RF tolerates a high
number of covariates and multicolinearity <span class="citation">(Biau and Scornet <a href="#ref-Biau2016">2016</a>)</span>, hence multiple
types of geographical covariates (Euclidean buffer distances, upslope
and downslope areas) could be used at the same time.</p>
</div>
<div id="spatial-prediction-2d-continuous-variable-using-rfsp" class="section level3">
<h3><span class="header-section-number">6.2.3</span> Spatial prediction 2D continuous variable using RFsp</h3>
<p>To run these examples, it is recommended to install <a href="https://github.com/imbs-hl/ranger">ranger</a> <span class="citation">(Wright and Ziegler <a href="#ref-wright2017ranger">2017</a>)</span> directly from github:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="cf">if</span>(<span class="op">!</span><span class="kw">require</span>(ranger)){ devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;imbs-hl/ranger&quot;</span>) }</code></pre>
<p>Quantile regression random forest and derivation of standard errors using Jackknifing is available from ranger version &gt;0.9.4. Other packages that we use here include:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(GSIF)
<span class="kw">library</span>(rgdal)
<span class="co">#&gt; rgdal: version: 1.3-6, (SVN revision 773)</span>
<span class="co">#&gt;  Geospatial Data Abstraction Library extensions to R successfully loaded</span>
<span class="co">#&gt;  Loaded GDAL runtime: GDAL 2.2.2, released 2017/09/15</span>
<span class="co">#&gt;  Path to GDAL shared files: /usr/share/gdal/2.2</span>
<span class="co">#&gt;  GDAL binary built with GEOS: TRUE </span>
<span class="co">#&gt;  Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]</span>
<span class="co">#&gt;  Path to PROJ.4 shared files: (autodetected)</span>
<span class="co">#&gt;  Linking to sp version: 1.3-1</span>
<span class="kw">library</span>(raster)
<span class="kw">library</span>(geoR)
<span class="co">#&gt; Warning: no DISPLAY variable so Tk is not available</span>
<span class="co">#&gt; --------------------------------------------------------------</span>
<span class="co">#&gt;  Analysis of Geostatistical Data</span>
<span class="co">#&gt;  For an Introduction to geoR go to http://www.leg.ufpr.br/geoR</span>
<span class="co">#&gt;  geoR version 1.7-5.2.1 (built on 2016-05-02) is now loaded</span>
<span class="co">#&gt; --------------------------------------------------------------</span>
<span class="kw">library</span>(ranger)</code></pre>
<pre><code>#&gt; 
#&gt; Attaching package: &#39;gridExtra&#39;
#&gt; The following object is masked from &#39;package:randomForest&#39;:
#&gt; 
#&gt;     combine</code></pre>
<p>If no other information is available, we can use buffer distances to all points as covariates to predict values of some continuous or categorical variable in the RFsp framework. These can be derived with the help of the <a href="https://cran.r-project.org/package=raster">raster</a> package <span class="citation">(Hijmans and van Etten <a href="#ref-raster">2017</a>)</span>. Consider for example the meuse data set from the <a href="https://github.com/edzer/gstat">gstat</a> package:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">demo</span>(meuse, <span class="dt">echo=</span><span class="ot">FALSE</span>)</code></pre>
<p>We can derive buffer distance by using:</p>
<pre class="sourceCode r"><code class="sourceCode r">grid.dist0 &lt;-<span class="st"> </span>GSIF<span class="op">::</span><span class="kw">buffer.dist</span>(meuse[<span class="st">&quot;zinc&quot;</span>], meuse.grid[<span class="dv">1</span>], <span class="kw">as.factor</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(meuse)))</code></pre>
<p>which requires a few seconds, as it generates 155 individual gridded maps. The value of the target variable <code>zinc</code> can be now modeled as a function of these computed buffer distances:</p>
<pre class="sourceCode r"><code class="sourceCode r">dn0 &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">names</span>(grid.dist0), <span class="dt">collapse=</span><span class="st">&quot;+&quot;</span>)
fm0 &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;zinc ~ &quot;</span>, dn0))
fm0
<span class="co">#&gt; zinc ~ layer.1 + layer.2 + layer.3 + layer.4 + layer.5 + layer.6 + </span>
<span class="co">#&gt;     layer.7 + layer.8 + layer.9 + layer.10 + layer.11 + layer.12 + </span>
<span class="co">#&gt;     layer.13 + layer.14 + layer.15 + layer.16 + layer.17 + layer.18 + </span>
<span class="co">#&gt;     layer.19 + layer.20 + layer.21 + layer.22 + layer.23 + layer.24 + </span>
<span class="co">#&gt;     layer.25 + layer.26 + layer.27 + layer.28 + layer.29 + layer.30 + </span>
<span class="co">#&gt;     layer.31 + layer.32 + layer.33 + layer.34 + layer.35 + layer.36 + </span>
<span class="co">#&gt;     layer.37 + layer.38 + layer.39 + layer.40 + layer.41 + layer.42 + </span>
<span class="co">#&gt;     layer.43 + layer.44 + layer.45 + layer.46 + layer.47 + layer.48 + </span>
<span class="co">#&gt;     layer.49 + layer.50 + layer.51 + layer.52 + layer.53 + layer.54 + </span>
<span class="co">#&gt;     layer.55 + layer.56 + layer.57 + layer.58 + layer.59 + layer.60 + </span>
<span class="co">#&gt;     layer.61 + layer.62 + layer.63 + layer.64 + layer.65 + layer.66 + </span>
<span class="co">#&gt;     layer.67 + layer.68 + layer.69 + layer.70 + layer.71 + layer.72 + </span>
<span class="co">#&gt;     layer.73 + layer.74 + layer.75 + layer.76 + layer.77 + layer.78 + </span>
<span class="co">#&gt;     layer.79 + layer.80 + layer.81 + layer.82 + layer.83 + layer.84 + </span>
<span class="co">#&gt;     layer.85 + layer.86 + layer.87 + layer.88 + layer.89 + layer.90 + </span>
<span class="co">#&gt;     layer.91 + layer.92 + layer.93 + layer.94 + layer.95 + layer.96 + </span>
<span class="co">#&gt;     layer.97 + layer.98 + layer.99 + layer.100 + layer.101 + </span>
<span class="co">#&gt;     layer.102 + layer.103 + layer.104 + layer.105 + layer.106 + </span>
<span class="co">#&gt;     layer.107 + layer.108 + layer.109 + layer.110 + layer.111 + </span>
<span class="co">#&gt;     layer.112 + layer.113 + layer.114 + layer.115 + layer.116 + </span>
<span class="co">#&gt;     layer.117 + layer.118 + layer.119 + layer.120 + layer.121 + </span>
<span class="co">#&gt;     layer.122 + layer.123 + layer.124 + layer.125 + layer.126 + </span>
<span class="co">#&gt;     layer.127 + layer.128 + layer.129 + layer.130 + layer.131 + </span>
<span class="co">#&gt;     layer.132 + layer.133 + layer.134 + layer.135 + layer.136 + </span>
<span class="co">#&gt;     layer.137 + layer.138 + layer.139 + layer.140 + layer.141 + </span>
<span class="co">#&gt;     layer.142 + layer.143 + layer.144 + layer.145 + layer.146 + </span>
<span class="co">#&gt;     layer.147 + layer.148 + layer.149 + layer.150 + layer.151 + </span>
<span class="co">#&gt;     layer.152 + layer.153 + layer.154 + layer.155</span></code></pre>
<p>Subsequent analysis is similar to any regression analysis using the <a href="https://github.com/imbs-hl/ranger">ranger package</a>. First we overlay points and grids to create a regression matrix:</p>
<pre class="sourceCode r"><code class="sourceCode r">ov.zinc &lt;-<span class="st"> </span><span class="kw">over</span>(meuse[<span class="st">&quot;zinc&quot;</span>], grid.dist0)
rm.zinc &lt;-<span class="st"> </span><span class="kw">cbind</span>(meuse<span class="op">@</span>data[<span class="st">&quot;zinc&quot;</span>], ov.zinc)</code></pre>
<p>to estimate also the prediction error variance i.e. prediction intervals we set <code>quantreg=TRUE</code> which initiates the Quantile Regression RF approach <span class="citation">(Meinshausen <a href="#ref-meinshausen2006quantile">2006</a>)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">m.zinc &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm0, rm.zinc, <span class="dt">quantreg=</span><span class="ot">TRUE</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>)
m.zinc
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm0, rm.zinc, quantreg = TRUE, num.trees = 150, seed = 1) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Regression </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  155 </span>
<span class="co">#&gt; Mtry:                             12 </span>
<span class="co">#&gt; Target node size:                 5 </span>
<span class="co">#&gt; Variable importance mode:         none </span>
<span class="co">#&gt; Splitrule:                        variance </span>
<span class="co">#&gt; OOB prediction error (MSE):       67501 </span>
<span class="co">#&gt; R squared (OOB):                  0.499</span></code></pre>
<p>This shows that, using only buffer distance explains almost 50% of the variation in the target variable. To generate predictions for the <code>zinc</code> variable and using the RFsp model, we use:</p>
<pre class="sourceCode r"><code class="sourceCode r">q &lt;-<span class="st"> </span><span class="kw">c</span>((<span class="dv">1</span><span class="fl">-.682</span>)<span class="op">/</span><span class="dv">2</span>, <span class="fl">0.5</span>, <span class="dv">1</span><span class="op">-</span>(<span class="dv">1</span><span class="fl">-.682</span>)<span class="op">/</span><span class="dv">2</span>)
zinc.rfd &lt;-<span class="st"> </span><span class="kw">predict</span>(m.zinc, grid.dist0<span class="op">@</span>data, 
                    <span class="dt">type=</span><span class="st">&quot;quantiles&quot;</span>, <span class="dt">quantiles=</span>q)<span class="op">$</span>predictions
<span class="kw">str</span>(zinc.rfd)
<span class="co">#&gt;  num [1:3103, 1:3] 257 257 257 257 257 ...</span>
<span class="co">#&gt;  - attr(*, &quot;dimnames&quot;)=List of 2</span>
<span class="co">#&gt;   ..$ : NULL</span>
<span class="co">#&gt;   ..$ : chr [1:3] &quot;quantile= 0.159&quot; &quot;quantile= 0.5&quot; &quot;quantile= 0.841&quot;</span></code></pre>
<p>this will estimate 67% probability lower and upper limits and median value. Note that “median” can often be different from the “mean”, so, if you prefer to derive mean, then the <code>quantreg=FALSE</code> needs to be used as the Quantile Regression Forests approach can only derive median.</p>
<p>To be able to plot or export the predicted values as maps, we add them to the spatial pixels object:</p>
<pre class="sourceCode r"><code class="sourceCode r">meuse.grid<span class="op">$</span>zinc_rfd =<span class="st"> </span>zinc.rfd[,<span class="dv">2</span>]
meuse.grid<span class="op">$</span>zinc_rfd_range =<span class="st"> </span>(zinc.rfd[,<span class="dv">3</span>]<span class="op">-</span>zinc.rfd[,<span class="dv">1</span>])<span class="op">/</span><span class="dv">2</span></code></pre>
<p>We can compare the RFsp approach with the model-based geostatistics approach (see e.g. <a href="http://leg.ufpr.br/geoR/geoRdoc/geoRintro.html">geoR package</a>), where we first decide about the transformation, then fit the variogram of the target variable <span class="citation">(Diggle and Ribeiro Jr <a href="#ref-Diggle2007Springer">2007</a>; Brown <a href="#ref-Brown2014JSS">2015</a>)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">zinc.geo &lt;-<span class="st"> </span><span class="kw">as.geodata</span>(meuse[<span class="st">&quot;zinc&quot;</span>])
ini.v &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">var</span>(<span class="kw">log1p</span>(zinc.geo<span class="op">$</span>data)),<span class="dv">500</span>)
zinc.vgm &lt;-<span class="st"> </span><span class="kw">likfit</span>(zinc.geo, <span class="dt">lambda=</span><span class="dv">0</span>, <span class="dt">ini=</span>ini.v, <span class="dt">cov.model=</span><span class="st">&quot;exponential&quot;</span>)
<span class="co">#&gt; kappa not used for the exponential correlation function</span>
<span class="co">#&gt; ---------------------------------------------------------------</span>
<span class="co">#&gt; likfit: likelihood maximisation using the function optim.</span>
<span class="co">#&gt; likfit: Use control() to pass additional</span>
<span class="co">#&gt;          arguments for the maximisation function.</span>
<span class="co">#&gt;         For further details see documentation for optim.</span>
<span class="co">#&gt; likfit: It is highly advisable to run this function several</span>
<span class="co">#&gt;         times with different initial values for the parameters.</span>
<span class="co">#&gt; likfit: </span><span class="al">WARNING</span><span class="co">: This step can be time demanding!</span>
<span class="co">#&gt; ---------------------------------------------------------------</span>
<span class="co">#&gt; likfit: end of numerical maximisation.</span>
zinc.vgm
<span class="co">#&gt; likfit: estimated model parameters:</span>
<span class="co">#&gt;       beta      tausq    sigmasq        phi </span>
<span class="co">#&gt; &quot;  6.1553&quot; &quot;  0.0164&quot; &quot;  0.5928&quot; &quot;500.0001&quot; </span>
<span class="co">#&gt; Practical Range with cor=0.05 for asymptotic range: 1498</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; likfit: maximised log-likelihood = -1014</span></code></pre>
<p>where <code>likfit</code> function fits a log-likelihood based variogram. Note that here we need to manually specify log-transformation via the <code>lambda</code> parameter. To generate predictions and kriging variance using geoR we run:</p>
<pre class="sourceCode r"><code class="sourceCode r">locs &lt;-<span class="st"> </span>meuse.grid<span class="op">@</span>coords
zinc.ok &lt;-<span class="st"> </span><span class="kw">krige.conv</span>(zinc.geo, <span class="dt">locations=</span>locs, <span class="dt">krige=</span><span class="kw">krige.control</span>(<span class="dt">obj.model=</span>zinc.vgm))
<span class="co">#&gt; krige.conv: model with constant mean</span>
<span class="co">#&gt; krige.conv: performing the Box-Cox data transformation</span>
<span class="co">#&gt; krige.conv: back-transforming the predicted mean and variance</span>
<span class="co">#&gt; krige.conv: Kriging performed using global neighbourhood</span>
meuse.grid<span class="op">$</span>zinc_ok &lt;-<span class="st"> </span>zinc.ok<span class="op">$</span>predict
meuse.grid<span class="op">$</span>zinc_ok_range &lt;-<span class="st"> </span><span class="kw">sqrt</span>(zinc.ok<span class="op">$</span>krige.var)</code></pre>
<p>in this case geoR automatically back-transforms values to the original scale, which is a recommended feature. Comparison of predictions and prediction error maps produced using geoR (ordinary kriging) and RFsp (with buffer distances and by just using coordinates) is given in Fig. <a href="soilmapping-using-mla.html#fig:comparison-OK-RF-zinc-meuse">6.13</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:comparison-OK-RF-zinc-meuse"></span>
<img src="figures/Fig_comparison_OK_RF_zinc_meuse.png" alt="Comparison of predictions based on ordinary kriging as implemented in the geoR package (left) and random forest (right) for Zinc concentrations, Meuse data set: (first row) predicted concentrations in log-scale and (second row) standard deviation of the prediction errors for OK and RF methods. Image source: Hengl et al. (2018) doi: 10.7717/peerj.5518." width="100%" />
<p class="caption">
Figure 6.13: Comparison of predictions based on ordinary kriging as implemented in the geoR package (left) and random forest (right) for Zinc concentrations, Meuse data set: (first row) predicted concentrations in log-scale and (second row) standard deviation of the prediction errors for OK and RF methods. Image source: Hengl et al. (2018) doi: 10.7717/peerj.5518.
</p>
</div>
<p>From the plot above, it can be concluded that RFsp yields very similar results to those produced using ordinary kriging via geoR. There are differences between geoR and RFsp, however. These are:</p>
<ul>
<li>RF requires no transformation i.e. works equally well with skewed and normally distributed variables; in general RF, requires fewer statistical assumptions than model-based geostatistics,</li>
<li>RF prediction error variance on average shows somewhat stronger contrast than OK variance map i.e. it emphasizes isolated, less probable, local points much more than geoR,</li>
<li>RFsp is significantly more computationally demanding as distances need to be derived from each sampling point to all new prediction locations,</li>
<li>geoR uses global model parameters and, as such, prediction patterns are also relatively uniform, RFsp on the other hand (being tree-based) will produce patterns that match the data as much as possible.</li>
</ul>
</div>
<div id="spatial-prediction-2d-variable-with-covariates-using-rfsp" class="section level3">
<h3><span class="header-section-number">6.2.4</span> Spatial prediction 2D variable with covariates using RFsp</h3>
<p>Next, we can also consider adding additional covariates that describe soil forming processes or characteristics of the land to the list of buffer distances. For example, we can add covariates for surface water occurrence <span class="citation">(Pekel et al. <a href="#ref-pekel2016high">2016</a>)</span> and elevation (<a href="http://ahn.nl">AHN</a>):</p>
<pre class="sourceCode r"><code class="sourceCode r">f1 =<span class="st"> &quot;extdata/Meuse_GlobalSurfaceWater_occurrence.tif&quot;</span>
f2 =<span class="st"> &quot;extdata/ahn.asc&quot;</span>
meuse.grid<span class="op">$</span>SW_occurrence &lt;-<span class="st"> </span><span class="kw">readGDAL</span>(f1)<span class="op">$</span>band1[meuse.grid<span class="op">@</span>grid.index]
<span class="co">#&gt; extdata/Meuse_GlobalSurfaceWater_occurrence.tif has GDAL driver GTiff </span>
<span class="co">#&gt; and has 104 rows and 78 columns</span>
meuse.grid<span class="op">$</span>AHN =<span class="st"> </span><span class="kw">readGDAL</span>(f2)<span class="op">$</span>band1[meuse.grid<span class="op">@</span>grid.index]
<span class="co">#&gt; extdata/ahn.asc has GDAL driver AAIGrid </span>
<span class="co">#&gt; and has 104 rows and 78 columns</span></code></pre>
<p>to convert all covariates to numeric values and fill in all missing pixels we use Principal Component transformation:</p>
<pre class="sourceCode r"><code class="sourceCode r">grids.spc =<span class="st"> </span>GSIF<span class="op">::</span><span class="kw">spc</span>(meuse.grid, <span class="kw">as.formula</span>(<span class="st">&quot;~ SW_occurrence + AHN + ffreq + dist&quot;</span>))
<span class="co">#&gt; Converting ffreq to indicators...</span>
<span class="co">#&gt; Converting covariates to principal components...</span></code></pre>
<p>so that we can fit a ranger model using both geographical covariates (buffer distances) and environmental covariates imported previously:</p>
<pre class="sourceCode r"><code class="sourceCode r">nms &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="kw">names</span>(grids.spc<span class="op">@</span>predicted), <span class="dt">collapse =</span> <span class="st">&quot;+&quot;</span>)
fm1 &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;zinc ~ &quot;</span>, dn0, <span class="st">&quot; + &quot;</span>, nms))
fm1
<span class="co">#&gt; zinc ~ layer.1 + layer.2 + layer.3 + layer.4 + layer.5 + layer.6 + </span>
<span class="co">#&gt;     layer.7 + layer.8 + layer.9 + layer.10 + layer.11 + layer.12 + </span>
<span class="co">#&gt;     layer.13 + layer.14 + layer.15 + layer.16 + layer.17 + layer.18 + </span>
<span class="co">#&gt;     layer.19 + layer.20 + layer.21 + layer.22 + layer.23 + layer.24 + </span>
<span class="co">#&gt;     layer.25 + layer.26 + layer.27 + layer.28 + layer.29 + layer.30 + </span>
<span class="co">#&gt;     layer.31 + layer.32 + layer.33 + layer.34 + layer.35 + layer.36 + </span>
<span class="co">#&gt;     layer.37 + layer.38 + layer.39 + layer.40 + layer.41 + layer.42 + </span>
<span class="co">#&gt;     layer.43 + layer.44 + layer.45 + layer.46 + layer.47 + layer.48 + </span>
<span class="co">#&gt;     layer.49 + layer.50 + layer.51 + layer.52 + layer.53 + layer.54 + </span>
<span class="co">#&gt;     layer.55 + layer.56 + layer.57 + layer.58 + layer.59 + layer.60 + </span>
<span class="co">#&gt;     layer.61 + layer.62 + layer.63 + layer.64 + layer.65 + layer.66 + </span>
<span class="co">#&gt;     layer.67 + layer.68 + layer.69 + layer.70 + layer.71 + layer.72 + </span>
<span class="co">#&gt;     layer.73 + layer.74 + layer.75 + layer.76 + layer.77 + layer.78 + </span>
<span class="co">#&gt;     layer.79 + layer.80 + layer.81 + layer.82 + layer.83 + layer.84 + </span>
<span class="co">#&gt;     layer.85 + layer.86 + layer.87 + layer.88 + layer.89 + layer.90 + </span>
<span class="co">#&gt;     layer.91 + layer.92 + layer.93 + layer.94 + layer.95 + layer.96 + </span>
<span class="co">#&gt;     layer.97 + layer.98 + layer.99 + layer.100 + layer.101 + </span>
<span class="co">#&gt;     layer.102 + layer.103 + layer.104 + layer.105 + layer.106 + </span>
<span class="co">#&gt;     layer.107 + layer.108 + layer.109 + layer.110 + layer.111 + </span>
<span class="co">#&gt;     layer.112 + layer.113 + layer.114 + layer.115 + layer.116 + </span>
<span class="co">#&gt;     layer.117 + layer.118 + layer.119 + layer.120 + layer.121 + </span>
<span class="co">#&gt;     layer.122 + layer.123 + layer.124 + layer.125 + layer.126 + </span>
<span class="co">#&gt;     layer.127 + layer.128 + layer.129 + layer.130 + layer.131 + </span>
<span class="co">#&gt;     layer.132 + layer.133 + layer.134 + layer.135 + layer.136 + </span>
<span class="co">#&gt;     layer.137 + layer.138 + layer.139 + layer.140 + layer.141 + </span>
<span class="co">#&gt;     layer.142 + layer.143 + layer.144 + layer.145 + layer.146 + </span>
<span class="co">#&gt;     layer.147 + layer.148 + layer.149 + layer.150 + layer.151 + </span>
<span class="co">#&gt;     layer.152 + layer.153 + layer.154 + layer.155 + PC1 + PC2 + </span>
<span class="co">#&gt;     PC3 + PC4 + PC5 + PC6</span>
ov.zinc1 &lt;-<span class="st"> </span><span class="kw">over</span>(meuse[<span class="st">&quot;zinc&quot;</span>], grids.spc<span class="op">@</span>predicted)
rm.zinc1 &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">list</span>(meuse<span class="op">@</span>data[<span class="st">&quot;zinc&quot;</span>], ov.zinc, ov.zinc1))</code></pre>
<p>this finally gives:</p>
<pre class="sourceCode r"><code class="sourceCode r">m1.zinc &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm1, rm.zinc1, <span class="dt">importance=</span><span class="st">&quot;impurity&quot;</span>, 
                  <span class="dt">quantreg=</span><span class="ot">TRUE</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>)
m1.zinc
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm1, rm.zinc1, importance = &quot;impurity&quot;, quantreg = TRUE,      num.trees = 150, seed = 1) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Regression </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  161 </span>
<span class="co">#&gt; Mtry:                             12 </span>
<span class="co">#&gt; Target node size:                 5 </span>
<span class="co">#&gt; Variable importance mode:         impurity </span>
<span class="co">#&gt; Splitrule:                        variance </span>
<span class="co">#&gt; OOB prediction error (MSE):       56350 </span>
<span class="co">#&gt; R squared (OOB):                  0.582</span></code></pre>
<p>which demonstrates that there is a slight improvement relative to using only buffer distances as covariates.
We can further evaluate this model to see which specific points and covariates are
most important for spatial predictions:</p>
<pre class="sourceCode r"><code class="sourceCode r">xl &lt;-<span class="st"> </span><span class="kw">as.list</span>(ranger<span class="op">::</span><span class="kw">importance</span>(m1.zinc))
<span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),<span class="dt">oma=</span><span class="kw">c</span>(<span class="fl">0.7</span>,<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">4</span>,<span class="fl">3.5</span>,<span class="dv">1</span>,<span class="dv">0</span>))
<span class="kw">plot</span>(vv &lt;-<span class="st"> </span><span class="kw">t</span>(<span class="kw">data.frame</span>(xl[<span class="kw">order</span>(<span class="kw">unlist</span>(xl), <span class="dt">decreasing=</span><span class="ot">TRUE</span>)[<span class="dv">10</span><span class="op">:</span><span class="dv">1</span>]])), <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, 
     <span class="dt">type =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;&quot;</span>, <span class="dt">yaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">xlab =</span> <span class="st">&quot;Variable Importance (Node Impurity)&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">lty =</span> <span class="st">&quot;dotted&quot;</span>, <span class="dt">col =</span> <span class="st">&quot;grey60&quot;</span>)
<span class="kw">points</span>(vv, <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>)
<span class="kw">axis</span>(<span class="dv">2</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>, <span class="dt">labels =</span> <span class="kw">dimnames</span>(vv)[[<span class="dv">1</span>]], <span class="dt">las =</span> <span class="dv">2</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:rf-variableImportance"></span>
<img src="06-Soilmapping_using_mla_files/figure-html/rf-variableImportance-1.png" alt="Variable importance plot for mapping zinc content based on the Meuse data set." width="100%" />
<p class="caption">
Figure 6.14: Variable importance plot for mapping zinc content based on the Meuse data set.
</p>
</div>
<p>which shows, for example, that locations 54, 59 and 53 are the most influential points,
and these are almost equally as important as the environmental covariates (PC2–PC4).</p>
<p>This type of modeling can be best compared to using Universal Kriging or Regression-Kriging in the geoR package:</p>
<pre class="sourceCode r"><code class="sourceCode r">zinc.geo<span class="op">$</span>covariate =<span class="st"> </span>ov.zinc1
sic.t =<span class="st"> </span><span class="er">~</span><span class="st"> </span>PC1 <span class="op">+</span><span class="st"> </span>PC2 <span class="op">+</span><span class="st"> </span>PC3 <span class="op">+</span><span class="st"> </span>PC4 <span class="op">+</span><span class="st"> </span>PC5
zinc1.vgm &lt;-<span class="st"> </span><span class="kw">likfit</span>(zinc.geo, <span class="dt">trend =</span> sic.t, <span class="dt">lambda=</span><span class="dv">0</span>, <span class="dt">ini=</span>ini.v, <span class="dt">cov.model=</span><span class="st">&quot;exponential&quot;</span>)
<span class="co">#&gt; kappa not used for the exponential correlation function</span>
<span class="co">#&gt; ---------------------------------------------------------------</span>
<span class="co">#&gt; likfit: likelihood maximisation using the function optim.</span>
<span class="co">#&gt; likfit: Use control() to pass additional</span>
<span class="co">#&gt;          arguments for the maximisation function.</span>
<span class="co">#&gt;         For further details see documentation for optim.</span>
<span class="co">#&gt; likfit: It is highly advisable to run this function several</span>
<span class="co">#&gt;         times with different initial values for the parameters.</span>
<span class="co">#&gt; likfit: </span><span class="al">WARNING</span><span class="co">: This step can be time demanding!</span>
<span class="co">#&gt; ---------------------------------------------------------------</span>
<span class="co">#&gt; likfit: end of numerical maximisation.</span>
zinc1.vgm
<span class="co">#&gt; likfit: estimated model parameters:</span>
<span class="co">#&gt;      beta0      beta1      beta2      beta3      beta4      beta5 </span>
<span class="co">#&gt; &quot;  5.6929&quot; &quot; -0.4351&quot; &quot;  0.0002&quot; &quot; -0.0791&quot; &quot; -0.0485&quot; &quot; -0.3725&quot; </span>
<span class="co">#&gt;      tausq    sigmasq        phi </span>
<span class="co">#&gt; &quot;  0.0566&quot; &quot;  0.1992&quot; &quot;499.9990&quot; </span>
<span class="co">#&gt; Practical Range with cor=0.05 for asymptotic range: 1498</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; likfit: maximised log-likelihood = -980</span></code></pre>
<p>this time geostatistical modeling produces an estimate of beta (regression coefficients) and variogram parameters (all estimated at once). Predictions using this Universal Kriging model can be generated by:</p>
<pre class="sourceCode r"><code class="sourceCode r">KC =<span class="st"> </span><span class="kw">krige.control</span>(<span class="dt">trend.d =</span> sic.t, 
                   <span class="dt">trend.l =</span> <span class="op">~</span><span class="st"> </span>grids.spc<span class="op">@</span>predicted<span class="op">$</span>PC1 <span class="op">+</span><span class="st"> </span>
<span class="st">                     </span>grids.spc<span class="op">@</span>predicted<span class="op">$</span>PC2 <span class="op">+</span><span class="st"> </span>grids.spc<span class="op">@</span>predicted<span class="op">$</span>PC3 <span class="op">+</span><span class="st"> </span>
<span class="st">                     </span>grids.spc<span class="op">@</span>predicted<span class="op">$</span>PC4 <span class="op">+</span><span class="st"> </span>grids.spc<span class="op">@</span>predicted<span class="op">$</span>PC5, 
                   <span class="dt">obj.model =</span> zinc1.vgm)
zinc.uk &lt;-<span class="st"> </span><span class="kw">krige.conv</span>(zinc.geo, <span class="dt">locations=</span>locs, <span class="dt">krige=</span>KC)
<span class="co">#&gt; krige.conv: model with mean defined by covariates provided by the user</span>
<span class="co">#&gt; krige.conv: performing the Box-Cox data transformation</span>
<span class="co">#&gt; krige.conv: back-transforming the predicted mean and variance</span>
<span class="co">#&gt; krige.conv: Kriging performed using global neighbourhood</span>
meuse.grid<span class="op">$</span>zinc_UK =<span class="st"> </span>zinc.uk<span class="op">$</span>predict</code></pre>
<div class="figure" style="text-align: center"><span id="fig:RF-covs-bufferdist-zinc-meuse"></span>
<img src="figures/Fig_RF_covs_bufferdist_zinc_meuse.png" alt="Comparison of predictions (median values) produced using random forest and covariates only (left), and random forest with combined covariates and buffer distances (right)." width="100%" />
<p class="caption">
Figure 6.15: Comparison of predictions (median values) produced using random forest and covariates only (left), and random forest with combined covariates and buffer distances (right).
</p>
</div>
<p>again, overall predictions (the spatial patterns) look fairly similar (Fig. <a href="soilmapping-using-mla.html#fig:RF-covs-bufferdist-zinc-meuse">6.15</a>).
The difference between using geoR and RFsp is that, in the case of RFsp, there are fewer choices
and fewer assumptions required. Also, RFsp permits the relationship between covariates
and geographical distances to be fitted all at once. This makes RFsp, in general, less
cumbersome than model-based geostatistics, but then also more of a “black-box” system
to a geostatistician.</p>
</div>
<div id="spatial-prediction-of-binomial-variables" class="section level3">
<h3><span class="header-section-number">6.2.5</span> Spatial prediction of binomial variables</h3>
<p>RFsp can also be used to predict (map the distribution of) binomial variables i.e. variables having only two states (TRUE or FALSE). In the model-based geostatistics equivalent methods are indicator kriging and similar. Consider for example soil type 1 from the meuse data set:</p>
<pre class="sourceCode r"><code class="sourceCode r">meuse<span class="op">@</span>data =<span class="st"> </span><span class="kw">cbind</span>(meuse<span class="op">@</span>data, <span class="kw">data.frame</span>(<span class="kw">model.matrix</span>(<span class="op">~</span>soil<span class="dv">-1</span>, meuse<span class="op">@</span>data)))
<span class="kw">summary</span>(<span class="kw">as.factor</span>(meuse<span class="op">$</span>soil1))
<span class="co">#&gt;  0  1 </span>
<span class="co">#&gt; 58 97</span></code></pre>
<p>in this case class <code>soil1</code> is the dominant soil type in the area. To produce a map of <code>soil1</code> using RFsp we have now two options:</p>
<ul>
<li><em>Option 1</em>: treat the binomial variable as numeric variable with 0 / 1 values (thus a regression problem),</li>
<li><em>Option 2</em>: treat the binomial variable as a factor variable with a single class (thus a classification problem),</li>
</ul>
<p>In the case of Option 1, we model <code>soil1</code> as:</p>
<pre class="sourceCode r"><code class="sourceCode r">fm.s1 &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;soil1 ~ &quot;</span>, <span class="kw">paste</span>(<span class="kw">names</span>(grid.dist0), <span class="dt">collapse=</span><span class="st">&quot;+&quot;</span>), 
                         <span class="st">&quot; + SW_occurrence + dist&quot;</span>))
rm.s1 &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">list</span>(meuse<span class="op">@</span>data[<span class="st">&quot;soil1&quot;</span>], 
                             <span class="kw">over</span>(meuse[<span class="st">&quot;soil1&quot;</span>], meuse.grid), 
                             <span class="kw">over</span>(meuse[<span class="st">&quot;soil1&quot;</span>], grid.dist0)))
m1.s1 &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm.s1, rm.s1, <span class="dt">mtry=</span><span class="dv">22</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>, <span class="dt">quantreg=</span><span class="ot">TRUE</span>)
m1.s1
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm.s1, rm.s1, mtry = 22, num.trees = 150, seed = 1, quantreg = TRUE) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Regression </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  157 </span>
<span class="co">#&gt; Mtry:                             22 </span>
<span class="co">#&gt; Target node size:                 5 </span>
<span class="co">#&gt; Variable importance mode:         none </span>
<span class="co">#&gt; Splitrule:                        variance </span>
<span class="co">#&gt; OOB prediction error (MSE):       0.0579 </span>
<span class="co">#&gt; R squared (OOB):                  0.754</span></code></pre>
<p>which results in a model that explains about 75% of variability in the <code>soil1</code> values.
We set <code>quantreg=TRUE</code> so that we can also derive lower and upper prediction
intervals following the quantile regression random forest <span class="citation">(Meinshausen <a href="#ref-meinshausen2006quantile">2006</a>)</span>.</p>
<p>In the case of Option 2, we treat the binomial variable as a factor variable:</p>
<pre class="sourceCode r"><code class="sourceCode r">fm.s1c &lt;-<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;soil1c ~ &quot;</span>, 
                           <span class="kw">paste</span>(<span class="kw">names</span>(grid.dist0), <span class="dt">collapse=</span><span class="st">&quot;+&quot;</span>), 
                           <span class="st">&quot; + SW_occurrence + dist&quot;</span>))
rm.s1<span class="op">$</span>soil1c =<span class="st"> </span><span class="kw">as.factor</span>(rm.s1<span class="op">$</span>soil1)
m2.s1 &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm.s1c, rm.s1, <span class="dt">mtry=</span><span class="dv">22</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>, 
                <span class="dt">probability=</span><span class="ot">TRUE</span>, <span class="dt">keep.inbag=</span><span class="ot">TRUE</span>)
m2.s1
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm.s1c, rm.s1, mtry = 22, num.trees = 150, seed = 1, probability = TRUE,      keep.inbag = TRUE) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Probability estimation </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  157 </span>
<span class="co">#&gt; Mtry:                             22 </span>
<span class="co">#&gt; Target node size:                 10 </span>
<span class="co">#&gt; Variable importance mode:         none </span>
<span class="co">#&gt; Splitrule:                        gini </span>
<span class="co">#&gt; OOB prediction error (Brier s.):  0.0586</span></code></pre>
<p>which shows that the Out of Bag prediction error (classification error) is (only)
0.06 (in the probability scale). Note that, it is not easy to compare the results
of the regression and classification OOB errors as these are conceptually different.
Also note that we turn on <code>keep.inbag = TRUE</code> so that ranger can estimate the
classification errors using the Jackknife-after-Bootstrap method <span class="citation">(Wager, Hastie, and Efron <a href="#ref-wager2014confidence">2014</a>)</span>.
<code>quantreg=TRUE</code> obviously would not work here since it is a classification and not a regression problem.</p>
<p>To produce predictions using the two options we use:</p>
<pre class="sourceCode r"><code class="sourceCode r">pred.regr &lt;-<span class="st"> </span><span class="kw">predict</span>(m1.s1, <span class="kw">cbind</span>(meuse.grid<span class="op">@</span>data, grid.dist0<span class="op">@</span>data), <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)
pred.clas &lt;-<span class="st"> </span><span class="kw">predict</span>(m2.s1, <span class="kw">cbind</span>(meuse.grid<span class="op">@</span>data, grid.dist0<span class="op">@</span>data), <span class="dt">type=</span><span class="st">&quot;se&quot;</span>)</code></pre>
<p>in principle, the two options to predicting the distribution of the binomial variable are mathematically equivalent and should lead to the same predictions (also shown in the map below). In practice, there can be some small differences in numbers, due to rounding effect or random start effects.</p>
<div class="figure" style="text-align: center"><span id="fig:comparison-uncertainty-Binomial"></span>
<img src="figures/Fig_comparison_uncertainty_Binomial_variables_meuse.png" alt="Comparison of predictions for soil class “1” produced using (left) regression and prediction of the median value, (middle) regression and prediction of response value, and (right) classification with probabilities." width="90%" />
<p class="caption">
Figure 6.16: Comparison of predictions for soil class “1” produced using (left) regression and prediction of the median value, (middle) regression and prediction of response value, and (right) classification with probabilities.
</p>
</div>
<p>This shows that predicting binomial variables using RFsp can be implemented both as a classification and a regression problem and both are possible to implement using the ranger package and both should lead to the same results.</p>
</div>
<div id="spatial-prediction-of-soil-types" class="section level3">
<h3><span class="header-section-number">6.2.6</span> Spatial prediction of soil types</h3>
<p>Spatial prediction of a categorical variable using ranger is a form of classification problem. The target variable contains multiple states (3 in this case), but the model still follows the same formulation:</p>
<pre class="sourceCode r"><code class="sourceCode r">fm.s =<span class="st"> </span><span class="kw">as.formula</span>(<span class="kw">paste</span>(<span class="st">&quot;soil ~ &quot;</span>, <span class="kw">paste</span>(<span class="kw">names</span>(grid.dist0), <span class="dt">collapse=</span><span class="st">&quot;+&quot;</span>), 
                        <span class="st">&quot; + SW_occurrence + dist&quot;</span>))
fm.s
<span class="co">#&gt; soil ~ layer.1 + layer.2 + layer.3 + layer.4 + layer.5 + layer.6 + </span>
<span class="co">#&gt;     layer.7 + layer.8 + layer.9 + layer.10 + layer.11 + layer.12 + </span>
<span class="co">#&gt;     layer.13 + layer.14 + layer.15 + layer.16 + layer.17 + layer.18 + </span>
<span class="co">#&gt;     layer.19 + layer.20 + layer.21 + layer.22 + layer.23 + layer.24 + </span>
<span class="co">#&gt;     layer.25 + layer.26 + layer.27 + layer.28 + layer.29 + layer.30 + </span>
<span class="co">#&gt;     layer.31 + layer.32 + layer.33 + layer.34 + layer.35 + layer.36 + </span>
<span class="co">#&gt;     layer.37 + layer.38 + layer.39 + layer.40 + layer.41 + layer.42 + </span>
<span class="co">#&gt;     layer.43 + layer.44 + layer.45 + layer.46 + layer.47 + layer.48 + </span>
<span class="co">#&gt;     layer.49 + layer.50 + layer.51 + layer.52 + layer.53 + layer.54 + </span>
<span class="co">#&gt;     layer.55 + layer.56 + layer.57 + layer.58 + layer.59 + layer.60 + </span>
<span class="co">#&gt;     layer.61 + layer.62 + layer.63 + layer.64 + layer.65 + layer.66 + </span>
<span class="co">#&gt;     layer.67 + layer.68 + layer.69 + layer.70 + layer.71 + layer.72 + </span>
<span class="co">#&gt;     layer.73 + layer.74 + layer.75 + layer.76 + layer.77 + layer.78 + </span>
<span class="co">#&gt;     layer.79 + layer.80 + layer.81 + layer.82 + layer.83 + layer.84 + </span>
<span class="co">#&gt;     layer.85 + layer.86 + layer.87 + layer.88 + layer.89 + layer.90 + </span>
<span class="co">#&gt;     layer.91 + layer.92 + layer.93 + layer.94 + layer.95 + layer.96 + </span>
<span class="co">#&gt;     layer.97 + layer.98 + layer.99 + layer.100 + layer.101 + </span>
<span class="co">#&gt;     layer.102 + layer.103 + layer.104 + layer.105 + layer.106 + </span>
<span class="co">#&gt;     layer.107 + layer.108 + layer.109 + layer.110 + layer.111 + </span>
<span class="co">#&gt;     layer.112 + layer.113 + layer.114 + layer.115 + layer.116 + </span>
<span class="co">#&gt;     layer.117 + layer.118 + layer.119 + layer.120 + layer.121 + </span>
<span class="co">#&gt;     layer.122 + layer.123 + layer.124 + layer.125 + layer.126 + </span>
<span class="co">#&gt;     layer.127 + layer.128 + layer.129 + layer.130 + layer.131 + </span>
<span class="co">#&gt;     layer.132 + layer.133 + layer.134 + layer.135 + layer.136 + </span>
<span class="co">#&gt;     layer.137 + layer.138 + layer.139 + layer.140 + layer.141 + </span>
<span class="co">#&gt;     layer.142 + layer.143 + layer.144 + layer.145 + layer.146 + </span>
<span class="co">#&gt;     layer.147 + layer.148 + layer.149 + layer.150 + layer.151 + </span>
<span class="co">#&gt;     layer.152 + layer.153 + layer.154 + layer.155 + SW_occurrence + </span>
<span class="co">#&gt;     dist</span></code></pre>
<p>to produce probability maps per soil class, we need to turn on the <code>probability=TRUE</code> option:</p>
<pre class="sourceCode r"><code class="sourceCode r">rm.s &lt;-<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">list</span>(meuse<span class="op">@</span>data[<span class="st">&quot;soil&quot;</span>], 
                            <span class="kw">over</span>(meuse[<span class="st">&quot;soil&quot;</span>], meuse.grid), 
                            <span class="kw">over</span>(meuse[<span class="st">&quot;soil&quot;</span>], grid.dist0)))
m.s &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm.s, rm.s, <span class="dt">mtry=</span><span class="dv">22</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>, 
              <span class="dt">probability=</span><span class="ot">TRUE</span>, <span class="dt">keep.inbag=</span><span class="ot">TRUE</span>)
m.s
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm.s, rm.s, mtry = 22, num.trees = 150, seed = 1, probability = TRUE,      keep.inbag = TRUE) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Probability estimation </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  157 </span>
<span class="co">#&gt; Mtry:                             22 </span>
<span class="co">#&gt; Target node size:                 10 </span>
<span class="co">#&gt; Variable importance mode:         none </span>
<span class="co">#&gt; Splitrule:                        gini </span>
<span class="co">#&gt; OOB prediction error (Brier s.):  0.0922</span></code></pre>
<p>this shows that the model is successful with an OOB prediction error of about 0.09. This number is rather abstract so we can also check the actual classification accuracy using hard classes:</p>
<pre class="sourceCode r"><code class="sourceCode r">m.s0 &lt;-<span class="st"> </span><span class="kw">ranger</span>(fm.s, rm.s, <span class="dt">mtry=</span><span class="dv">22</span>, <span class="dt">num.trees=</span><span class="dv">150</span>, <span class="dt">seed=</span><span class="dv">1</span>)
m.s0
<span class="co">#&gt; Ranger result</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt;  ranger(fm.s, rm.s, mtry = 22, num.trees = 150, seed = 1) </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Type:                             Classification </span>
<span class="co">#&gt; Number of trees:                  150 </span>
<span class="co">#&gt; Sample size:                      155 </span>
<span class="co">#&gt; Number of independent variables:  157 </span>
<span class="co">#&gt; Mtry:                             22 </span>
<span class="co">#&gt; Target node size:                 1 </span>
<span class="co">#&gt; Variable importance mode:         none </span>
<span class="co">#&gt; Splitrule:                        gini </span>
<span class="co">#&gt; OOB prediction error:             10.32 %</span></code></pre>
<p>which shows that the classification or mapping accuracy for hard classes is about 90%. We can produce predictions of probabilities per class by running:</p>
<pre class="sourceCode r"><code class="sourceCode r">pred.soil_rfc =<span class="st"> </span><span class="kw">predict</span>(m.s, <span class="kw">cbind</span>(meuse.grid<span class="op">@</span>data, grid.dist0<span class="op">@</span>data), <span class="dt">type=</span><span class="st">&quot;se&quot;</span>)
pred.grids =<span class="st"> </span>meuse.grid[<span class="st">&quot;soil&quot;</span>]
pred.grids<span class="op">@</span>data =<span class="st"> </span><span class="kw">do.call</span>(cbind, <span class="kw">list</span>(pred.grids<span class="op">@</span>data, 
                                      <span class="kw">data.frame</span>(pred.soil_rfc<span class="op">$</span>predictions),
                                      <span class="kw">data.frame</span>(pred.soil_rfc<span class="op">$</span>se)))
<span class="kw">names</span>(pred.grids) =<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;soil&quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;pred_soil&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>), <span class="kw">paste0</span>(<span class="st">&quot;se_soil&quot;</span>, <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>))
<span class="kw">str</span>(pred.grids<span class="op">@</span>data)
<span class="co">#&gt; &#39;data.frame&#39;:    3103 obs. of  7 variables:</span>
<span class="co">#&gt;  $ soil      : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 1 1 1 1 1 1 ...</span>
<span class="co">#&gt;  $ pred_soil1: num  0.716 0.713 0.713 0.693 0.713 ...</span>
<span class="co">#&gt;  $ pred_soil2: num  0.246 0.256 0.256 0.27 0.256 ...</span>
<span class="co">#&gt;  $ pred_soil3: num  0.0374 0.0307 0.0307 0.0374 0.0307 ...</span>
<span class="co">#&gt;  $ se_soil1  : num  0.1798 0.1684 0.1684 0.0903 0.1684 ...</span>
<span class="co">#&gt;  $ se_soil2  : num  0.1446 0.0808 0.0808 0.0796 0.0808 ...</span>
<span class="co">#&gt;  $ se_soil3  : num  0.0414 0.0413 0.0413 0.0414 0.0413 ...</span></code></pre>
<p>where <code>pred_soil1</code> is the probability of occurrence of class 1 and <code>se_soil1</code> is the standard error of prediction for the <code>pred_soil1</code> based on the Jackknife-after-Bootstrap method <span class="citation">(Wager, Hastie, and Efron <a href="#ref-wager2014confidence">2014</a>)</span>. The first column in <code>pred.grids</code> contains the existing map of <code>soil</code> with hard classes only.</p>
<div class="figure" style="text-align: center"><span id="fig:comparison-uncertainty-Factor"></span>
<img src="figures/Fig_comparison_uncertainty_Factor_variables_meuse.png" alt="Predictions of soil types for the meuse data set based on the RFsp: (above) probability for three soil classes, and (below) derived standard errors per class." width="90%" />
<p class="caption">
Figure 6.17: Predictions of soil types for the meuse data set based on the RFsp: (above) probability for three soil classes, and (below) derived standard errors per class.
</p>
</div>
<p>Spatial prediction of binomial and factor-type variables is straight forward with ranger / RFsp: buffer distance and spatial-autocorrelation can be incorporated simultaneously as opposed to geostatistical packages, where link functions and/or indicator kriging would need to be used, and which require that variograms are fitted per class.</p>
</div>
</div>
<div id="summary-points-3" class="section level2">
<h2><span class="header-section-number">6.3</span> Summary points</h2>
<p>In summary, MLA’s are fairly attractive for soil mapping and soil modelling problems in general, as they often perform better than standard linear models (as previously recognized by <span class="citation">Moran and Bui (<a href="#ref-moran2002spatial">2002</a>)</span> and <span class="citation">Henderson et al. (<a href="#ref-Henderson2004Geoderma">2004</a>)</span>) Some recent comparisons of MLA’s performance for operational soil mapping can be found in <span class="citation">Nussbaum et al. (<a href="#ref-nussbaum2018evaluation">2018</a>)</span>). MLA’s often perform better than linear techniques for soil mapping; possibly for the following three reasons:</p>
<ol style="list-style-type: decimal">
<li>Non-linear relationships between soil forming factors and soil properties can be more efficiently modeled using MLA’s,</li>
<li>Tree-based MLA’s (random forest, gradient boosting, cubist) are suitable for representing <em>local</em> soil-landscape relationships, nested within larger areas, which is often important for achieving accuracy of spatial prediction models,</li>
<li>In the case of MLA, statistical properties such as multicolinearity and non-Gaussian distribution are dealt with inside the models, which simplifies statistical modeling steps,</li>
</ol>
<p>On the other hand, MLA’s can be computationally very intensive and consequently require careful planning, especially as the number of points goes beyond a few thousand and the number of covariates beyond a dozen. Note also that some MLA’s, such as for example Support Vector Machines (<code>svm</code>), are computationally very intensive and are probably not well suited for large data sets.</p>
<p>Within PSM, there is increasing interest in doing ensemble predictions,
model averages or model stacks. Stacking models can improve upon
individual best techniques, achieving improvements of up to 30%, with
the additional demands consistinf of only higher computation loads
<span class="citation">(Michailidis <a href="#ref-michailidis2017investigating">2017</a>)</span>. In the example above, the extensive
computational load from derivation of models and product predictions
already achieved improved accuracies, making increasing computing loads
further a matter of diminishing returns. Some interesting Machine Learning Algorithms for soil mapping based on regression include: Random Forest <span class="citation">(Biau and Scornet <a href="#ref-Biau2016">2016</a>)</span>,
Gradient Boosting Machine (GBM) <span class="citation">(Hastie, Tibshirani, and Friedman <a href="#ref-hastie2009elements">2009</a>)</span>, Cubist <span class="citation">(Kuhn et al. <a href="#ref-kuhn2014cubist">2014</a>)</span>,
Generalized Boosted Regression Models <span class="citation">(Ridgeway <a href="#ref-ridgeway2010gbm">2018</a>)</span>, Support Vector Machines <span class="citation">(Chang and Lin <a href="#ref-chang2011libsvm">2011</a>)</span>,
and the Extreme Gradient Boosting approach available via the xgboost package <span class="citation">(Chen and Guestrin <a href="#ref-2016arXiv160302754C">2016</a>)</span>.
None of these techniques is universally recognized as the best spatial predictor for all soil variables.
Instead, we recommend comparing MLA’s using robust cross-validation methods as explained above.
Also combining MLA’s into ensemble predictions might not be beneficial in all situations.
Less is better sometimes.</p>
<p>The RFsp method seems to be suitable for generating spatial and spatiotemporal predictions.
Computing time, however, can be demanding and working with data sets with &gt;1000
point locations (hence 1000+ buffer distance maps) is probably not yet feasible or recommended.
Also cross-validation of accuracy of predictions produced using RFsp needs to be
implemented using leave-location-out CV to account for spatial autocorrelation in data.
The key to the success of the RFsp framework might be the training data quality —
especially quality of spatial sampling (to minimize extrapolation problems and any
type of bias in data), and quality of model validation (to ensure that accuracy is
not effected by over-fitting). For all other details about RFsp refer to <span class="citation">T. Hengl, Nussbaum, et al. (<a href="#ref-Hengl2018RFsp">2018</a>)</span>.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-richter2015multi">
<p>Richter, Aaron N, Taghi M Khoshgoftaar, Sara Landset, and Tawfiq Hasanin. 2015. “A Multi-Dimensional Comparison of Toolkits for Machine Learning with Big Data.” In <em>Information Reuse and Integration (Iri), 2015 Ieee International Conference</em>, 1–8. IEEE.</p>
</div>
<div id="ref-krogh1996learning">
<p>Sollich, Peter, and Anders Krogh. 1996. “Learning with Ensembles: How over-Fitting Can Be Useful.” In <em>Advances in Neural Information Processing Systems</em>, 8:190.</p>
</div>
<div id="ref-kuhn2012cubist">
<p>Kuhn, Max, Steve Weston, Chris Keefer, and Nathan Coulter. 2012. <em>Cubist Models for Regression</em>. <a href="https://cran.r-project.org/package=cubist" class="uri">https://cran.r-project.org/package=cubist</a>.</p>
</div>
<div id="ref-kuhn2013applied">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Vol. 810. Springer.</p>
</div>
<div id="ref-2016arXiv160302754C">
<p>Chen, T., and C. Guestrin. 2016. “XGBoost: A Scalable Tree Boosting System.” <em>ArXiv E-Prints</em>, March.</p>
</div>
<div id="ref-Malone2009Geoderma">
<p>Malone, B.P., A. B. McBratney, B. Minasny, and G.M. Laslett. 2009. “Mapping Continuous Depth Functions of Soil Carbon Storage and Available Water Capacity.” <em>Geoderma</em> 154 (1-2): 138–52. <a href="https://doi.org/10.1016/j.geoderma.2009.10.007" class="uri">https://doi.org/10.1016/j.geoderma.2009.10.007</a>.</p>
</div>
<div id="ref-ledell2015scalable">
<p>LeDell, Erin E. 2015. <em>Scalable Ensemble Learning and Computationally Efficient Variance Estimation</em>. University of California, Berkeley.</p>
</div>
<div id="ref-Gasch2015SPASTA">
<p>Gasch, Caley, Tomislav Hengl, Benedikt Gräler, Hanna Meyer, Troy Magney, and David Brown. 2015. “Spatio-temporal interpolation of soil water, temperature, and electrical conductivity in 3D+T: The Cook Agronomy Farm data set.” <em>Spatial Statistics</em> 14 (Part A): 70–90. <a href="https://doi.org/10.1016/j.spasta.2015.04.001" class="uri">https://doi.org/10.1016/j.spasta.2015.04.001</a>.</p>
</div>
<div id="ref-polley2010super">
<p>Polley, Eric C, and Mark J Van Der Laan. 2010. <em>Super Learner in Prediction</em>. Working Paper Series. U.C. Berkeley Division of Biostatistics.</p>
</div>
<div id="ref-Hengl2018RFsp">
<p>Hengl, Tomislav, Madlene Nussbaum, Marvin N Wright, Gerard B.M. Heuvelink, and Benedikt Gräler. 2018. “Random Forest as a Generic Framework for Predictive Modeling of Spatial and Spatio-Temporal Variables.” <em>PeerJ</em> 6 (August): e5518. <a href="https://doi.org/10.7717/peerj.5518" class="uri">https://doi.org/10.7717/peerj.5518</a>.</p>
</div>
<div id="ref-miller2004tobler">
<p>Miller, Harvey J. 2004. “Tobler’s First Law and Spatial Analysis.” <em>Annals of the Association of American Geographers</em> 94 (2). Wiley Online Library: 284–89.</p>
</div>
<div id="ref-GRUBER2009171">
<p>Gruber, S., and S. Peckham. 2009. “Chapter 7 Land-Surface Parameters and Objects in Hydrology.” In <em>Geomorphometry</em>, edited by Tomislav Hengl and Hannes I. Reuter, 33:171–94. Developments in Soil Science. Elsevier. <a href="https://doi.org/10.1016/S0166-2481(08)00007-X" class="uri">https://doi.org/10.1016/S0166-2481(08)00007-X</a>.</p>
</div>
<div id="ref-vanEtten2017r">
<p>van Etten, Jacob. 2017. “R Package gdistance: Distances and Routes on Geographical Grids.” <em>Journal of Statistical Software</em> 76 (13): 1–21.</p>
</div>
<div id="ref-gmd-8-1991-2015">
<p>Conrad, O., B. Bechtel, M. Bock, H. Dietrich, E. Fischer, L. Gerlitz, J. Wehberg, V. Wichmann, and J. Böhner. 2015. “System for Automated Geoscientific Analyses (Saga) V. 2.1.4.” <em>Geoscientific Model Development</em> 8 (7). Copernicus GmbH: 1991–2007. <a href="https://doi.org/10.5194/gmd-8-1991-2015" class="uri">https://doi.org/10.5194/gmd-8-1991-2015</a>.</p>
</div>
<div id="ref-Biau2016">
<p>Biau, Gérard, and Erwan Scornet. 2016. “A Random Forest Guided Tour.” <em>TEST</em> 25 (2). Springer: 197–227. <a href="https://doi.org/10.1007/s11749-016-0481-7" class="uri">https://doi.org/10.1007/s11749-016-0481-7</a>.</p>
</div>
<div id="ref-wright2017ranger">
<p>Wright, Marvin N, and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” <em>Journal of Statistical Software</em> 77 (1): 1–17.</p>
</div>
<div id="ref-raster">
<p>Hijmans, Robert J., and Jacob van Etten. 2017. <em>Raster: Geographic Data Analysis and Modeling</em>. <a href="http://CRAN.R-project.org/package=raster" class="uri">http://CRAN.R-project.org/package=raster</a>.</p>
</div>
<div id="ref-meinshausen2006quantile">
<p>Meinshausen, Nicolai. 2006. “Quantile Regression Forests.” <em>The Journal of Machine Learning Research</em> 7 (Jun). JMLR.org: 983–99.</p>
</div>
<div id="ref-Diggle2007Springer">
<p>Diggle, P. J., and P. J. Ribeiro Jr. 2007. <em>Model-based Geostatistics</em>. Springer Series in Statistics. Springer.</p>
</div>
<div id="ref-Brown2014JSS">
<p>Brown, Patrick E. 2015. “Model-Based Geostatistics the Easy Way.” <em>Journal of Statistical Software</em> 63 (12). <a href="http://www.jstatsoft.org/v63/i12" class="uri">http://www.jstatsoft.org/v63/i12</a>.</p>
</div>
<div id="ref-pekel2016high">
<p>Pekel, Jean-François, Andrew Cottam, Noel Gorelick, and Alan S Belward. 2016. “High-Resolution Mapping of Global Surface Water and Its Long-Term Changes.” <em>Nature</em> 504. Nature Research: 418–22.</p>
</div>
<div id="ref-wager2014confidence">
<p>Wager, Stefan, Trevor Hastie, and Bradley Efron. 2014. “Confidence Intervals for Random Forests: The Jackknife and the Infinitesimal Jackknife.” <em>Journal of Machine Learning Research</em> 15 (1): 1625–51.</p>
</div>
<div id="ref-moran2002spatial">
<p>Moran, C.J., and E.N. Bui. 2002. “Spatial Data Mining for Enhanced Soil Map Modelling.” <em>International Journal of Geographical Information Science</em> 16 (6). Taylor &amp; Francis: 533–49.</p>
</div>
<div id="ref-Henderson2004Geoderma">
<p>Henderson, B. L., E. N. Bui, C. J. Moran, and D. A. P. Simon. 2004. “Australia-wide predictions of soil properties using decision trees.” <em>Geoderma</em> 124 (3-4): 383–98.</p>
</div>
<div id="ref-nussbaum2018evaluation">
<p>Nussbaum, Madlene, Kay Spiess, Andri Baltensweiler, Urs Grob, Armin Keller, Lucie Greiner, Michael E Schaepman, and Andreas Papritz. 2018. “Evaluation of Digital Soil Mapping Approaches with Large Sets of Environmental Covariates.” <em>Soil</em> 4 (1): 1.</p>
</div>
<div id="ref-michailidis2017investigating">
<p>Michailidis, Marios. 2017. “Investigating Machine Learning Methods in Recommender Systems.” PhD thesis, UCL (University College London).</p>
</div>
<div id="ref-hastie2009elements">
<p>Hastie, T.J., R.J. Tibshirani, and J.J.H. Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Springer Series in Statistics. Springer-Verlag New York.</p>
</div>
<div id="ref-kuhn2014cubist">
<p>Kuhn, Max, Steve Weston, Chris Keefer, Nathan Coulter, and R Quinlan. 2014. <em>Cubist: Rule-and Instance-Based Regression Modeling</em>. <a href="http://CRAN.R-project.org/package=Cubist" class="uri">http://CRAN.R-project.org/package=Cubist</a>.</p>
</div>
<div id="ref-ridgeway2010gbm">
<p>Ridgeway, G. 2018. <em>Gbm: Generalized Boosted Regression Models</em>. <a href="http://CRAN.R-project.org/package=gbm" class="uri">http://CRAN.R-project.org/package=gbm</a>.</p>
</div>
<div id="ref-chang2011libsvm">
<p>Chang, Chih-Chung, and Chih-Jen Lin. 2011. “LIBSVM: a library for support vector machines.” <em>ACM Transactions on Intelligent Systems and Technology (TIST)</em> 2 (3). Acm: 27.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://https-envirometrix-github-io-predictivesoilmapping.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="statistical-theory.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="SOC-chapter.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/envirometrix/PredictiveSoilMapping/edit/master/06-Soilmapping_using_mla.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["PSMwR_UStrade.pdf", "PSMwR_UStrade.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
